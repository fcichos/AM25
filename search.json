[
  {
    "objectID": "lecture04/lecture04.html",
    "href": "lecture04/lecture04.html",
    "title": "Microscopic Models of Self-propulsion",
    "section": "",
    "text": "Lecture 4: Continuum Theories\n\nHydrodynamic theories and coarse-graining\nActive liquid crystals\nToner-Tu model for flocking\nActive field theories\nLinear stability analysis in active systems"
  },
  {
    "objectID": "lecture02/lecture02.html",
    "href": "lecture02/lecture02.html",
    "title": "Statistical Mechanics Terms",
    "section": "",
    "text": "Equilibrium statistical mechanics may seem like a contradictory starting point for understanding fundamentally non-equilibrium phenomena in active matter. However, we begin with these concepts precisely because understanding how and why active systems violate equilibrium principles illuminates their unique properties. In this section, we review key equilibrium concepts that provide a crucial reference frame against which we can measure and characterize the non-equilibrium nature of active systems.\n\n\nFor a system in thermal equilibrium with a heat bath at temperature \\(T\\) not exchanging particles with the environment, the probability of finding the system in a microstate with phase space coordinates \\(\\Gamma = \\{\\mathbf{q}, \\mathbf{p}\\}\\) is given by the Boltzmann distribution:\n\\[P(\\Gamma) = \\frac{1}{Z} e^{-\\beta H(\\Gamma)}\\]\nwhere \\(\\beta = 1/(k_B T)\\), \\(k_B\\) is Boltzmann’s constant, \\(H(\\Gamma)\\) is the Hamiltonian of the system, and \\(Z\\) is the partition function:\n\\[Z = \\frac{1}{h^{3N}N!}\\int e^{-\\beta H(\\Gamma)} d\\Gamma\\]\nIn this expression, \\(h\\) is Planck’s constant, \\(N\\) is the number of particles, and the factors \\(h^{3N}\\) and \\(N!\\) account for the quantum uncertainty principle and the indistinguishability of identical particles, respectively. This normalization ensures that the partition function is dimensionless.\nIn physical terms, the Boltzmann distribution reflects how energy is partitioned among the available states at thermal equilibrium. States with lower energy are exponentially more likely to be occupied than states with higher energy. For active matter systems, this distribution is significantly altered because energy is continuously injected at the microscopic level, driving the system away from this equilibrium distribution. Indeed, active systems generally cannot be described by a time-independent Hamiltonian at all, as they involve non-conservative forces.\nThe partition function is central to statistical mechanics as it connects microscopic properties to macroscopic observables. For instance, the average energy is:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\\]\nThis relationship highlights how the partition function serves as a generating function for thermodynamic quantities. When studying active matter, we’ll see that traditional partition functions often cannot be defined because these systems don’t explore phase space according to Boltzmann statistics.\n\n\n\n\n\n\nSedimentation Example\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Perrin’s sedimentation experiments. The exponential decay in the number density of colloidal particles with height directly confirmed the Boltzmann distribution and provided key evidence for the atomic theory of matter.\n\n\n\nA clear demonstration of the Boltzmann distribution’s power can be derived from the canonical partition function using the barometric distribution of particles in a gravitational field. Consider colloidal particles suspended in a fluid in a gravitational field \\(g\\).\nThe Hamiltonian for a particle at height \\(h\\) with momentum \\(p\\) is:\n\\[H(h, p) = \\frac{p^2}{2m} + mgh\\]\nwhere the first term represents the kinetic energy and the second term is the gravitational potential energy. For this system, we can construct the partition function by integrating over all possible heights and momenta:\n\\[Z = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(h,p)} dp dh = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp dh\\]\nThis can be separated into:\n\\[Z = \\int_{-\\infty}^{\\infty} e^{-\\beta\\frac{p^2}{2m}} dp \\cdot \\int_0^{\\infty} e^{-\\beta mgh} dh\\]\nThe momentum integral gives \\(\\sqrt{\\frac{2\\pi m}{\\beta}}\\), while the height integral yields \\(\\frac{1}{\\beta mg}\\), resulting in:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg} = \\sqrt{\\frac{2\\pi m}{\\beta^3 m^2 g^2}}\\]\nThe probability density for finding a particle at height \\(h\\) (integrating over all momenta) is:\n\\[P(h) = \\frac{\\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp}{Z} = \\frac{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot e^{-\\beta mgh}}{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg}} = \\beta mg e^{-\\beta mgh}\\]\nFrom this, we can derive the number density \\(n(h)\\) by multiplying by the total number of particles \\(N\\):\n\\[n(h) = N \\cdot P(h) = N \\beta mg e^{-\\beta mgh}\\]\nIf we define \\(n_0\\) as the density at \\(h=0\\), then \\(n_0 = N \\beta mg\\), and we obtain:\n\\[n(h) = n_0 e^{-\\beta mgh} = n_0 e^{-\\frac{mgh}{k_B T}}\\]\nTaking the logarithm of both sides:\n\\[\\ln\\left(\\frac{n(h)}{n_0}\\right) = -\\beta mgh = -\\frac{mgh}{k_B T}\\]\nThis direct connection between the Hamiltonian, partition function, and the observable barometric distribution provides a compelling experimental verification of statistical mechanics. Jean Perrin used this relationship in 1908 to experimentally determine Avogadro’s number and provide crucial evidence for the atomic theory of matter. Today, similar experiments with colloidal particles serve as textbook demonstrations of statistical mechanics in action.\n\n\n\n\n\n\nThe Helmholtz free energy is a thermodynamic potential that determines the maximum useful work obtainable from a closed system at constant temperature and volume. Named after German physicist Hermann von Helmholtz, it represents the amount of energy available to do non-expansion work. The Helmholtz free energy is particularly relevant in statistical mechanics because it serves as the fundamental bridge between microscopic properties (encoded in the partition function) and macroscopic thermodynamic behavior. For systems in the canonical ensemble—where the number of particles, volume, and temperature are fixed—the Helmholtz free energy provides the appropriate thermodynamic potential whose minimum determines the equilibrium state.\nThe Helmholtz free energy \\(F\\) is related to the partition function by:\n\\[F = -k_B T \\ln Z = -k_B T \\ln \\left(\\frac{1}{h^{3N}N!}\\int e^{-\\beta H(\\Gamma)} d\\Gamma\\right)\\]\nwhere the normalization factor \\(\\frac{1}{h^{3N}N!}\\) ensures proper dimensionless units in the partition function, with \\(h\\) being Planck’s constant and \\(N\\) the number of particles.\nWe can rewrite this as \\(F = E - TS\\), explicitly showing the competition between the enthalpic (energy) and entropic contributions:\n\\[F = \\langle H \\rangle - TS\\]\nwhere \\(\\langle H \\rangle\\) is the average energy:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta} = \\frac{\\int H(\\Gamma) e^{-\\beta H(\\Gamma)} d\\Gamma}{\\int e^{-\\beta H(\\Gamma)} d\\Gamma}\\]\nand \\(S\\) is the entropy:\n\\[S = -\\left(\\frac{\\partial F}{\\partial T}\\right)_V = k_B \\ln Z + \\frac{\\langle H \\rangle}{T}\\]\nAt equilibrium, minimizing the free energy involves a fundamental competition between:\n\nEnergy minimization: The system tends to occupy low-energy states to minimize \\(\\langle H \\rangle\\)\nEntropy maximization: The system tends to spread over many accessible states to maximize \\(S\\)\n\nThe Boltzmann distribution \\(P(\\Gamma) = \\frac{1}{Z}e^{-\\beta H(\\Gamma)}\\) represents the optimal compromise between these competing tendencies. For systems with fixed particle number, volume, and temperature (canonical ensemble), this distribution precisely minimizes the free energy subject to the constraints of the canonical ensemble.\nThe principle of free energy minimization is particularly important for understanding the contrast with active systems. In active matter, free energy is constantly being pumped into the system through microscopic driving mechanisms (e.g., molecular motors in cell cytoskeleton, metabolic processes in bacteria, or artificial propulsion mechanisms in synthetic swimmers). These systems involve non-conservative forces that cannot be derived from a Hamiltonian, so they cannot be described by a minimum free energy principle, which is a fundamental departure from equilibrium thermodynamics.\n\n\n\n\n\n\nHarmonic Oscillator Example\n\n\n\n\n\nThe harmonic oscillator provides another illuminating example of equilibrium statistical mechanics. Consider a Brownian particle in a harmonic potential \\(U(x) = \\frac{1}{2}kx^2\\) provided by some highly focused light beam. Here \\(k\\) is the spring constant.\n\n\n\n\n\n\nFigure 2: Sketch of a colloidal particle trapped in the focus of a microscopy lens due to electromagnetic forces. source\n\n\n\nThe particle experiences both a restoring force and random thermal kicks from the surrounding fluid.\nThe Hamiltonian for this system is:\n\\[H(x,p) = \\frac{p^2}{2m} + \\frac{1}{2}kx^2\\]\nwhere \\(m\\) is the particle mass, \\(x\\) is position, and \\(p\\) is momentum. The partition function is:\n\\[Z = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(x,p)} dx dp = \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{p^2}{2m}} dp \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{1}{2}kx^2} dx\\]\nEvaluating these Gaussian integrals:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\sqrt{\\frac{2\\pi}{\\beta k}} = \\frac{2\\pi}{\\beta\\omega_0}\\]\nwhere \\(\\omega_0 = \\sqrt{k/m}\\) is the natural frequency of the oscillator.\nThe probability density for finding the particle at position \\(x\\) is:\n\\[P(x) = \\sqrt{\\frac{\\beta k}{2\\pi}} e^{-\\beta \\frac{1}{2}kx^2}\\]\nThis Gaussian distribution has variance \\(\\sigma^2 = \\frac{1}{\\beta k} = \\frac{k_B T}{k}\\).\nThe equipartition theorem states that each quadratic term in the Hamiltonian contributes \\(\\frac{1}{2}k_B T\\) to the average energy:\n\\[\\left \\langle \\frac{p^2}{2m} \\right \\rangle = \\left \\langle \\frac{1}{2}kx^2 \\right \\rangle = \\frac{1}{2}k_B T\\]\nTherefore, the mean-square displacement of the particle is:\n\\[\\langle x^2 \\rangle = \\frac{k_B T}{k}\\]\nThis simple relation demonstrates how thermal energy causes the particle to explore the potential well, with the stiffness of the spring determining the confinement. Stiffer springs (larger \\(k\\)) lead to smaller position fluctuations.\n\n\n\n\n\n\nA key assumption in equilibrium statistical mechanics is ergodicity—the equivalence between time averages and ensemble averages:\n\\[\\langle A \\rangle_{\\text{time}} = \\lim_{T\\to\\infty} \\frac{1}{T} \\int_0^T A(t) dt = \\langle A \\rangle_{\\text{ensemble}}\\]\nIn practical terms, ergodicity means that if you observe a single system for a sufficiently long time, it will eventually visit all microscopic states consistent with its macroscopic constraints, allowing time averages to equal ensemble averages. Active matter systems often violate ergodicity by persistently exploring only a subset of the available phase space due to their self-propulsion mechanisms. This has profound implications for both experimental measurements and theoretical descriptions of active systems.\nEquilibrium dynamics satisfies detailed balance, a microscopic time-reversal symmetry condition. For transitions between states \\(i\\) and \\(j\\) with rates \\(W_{i\\to j}\\) and \\(W_{j\\to i}\\):\n\\[\\frac{W_{i\\to j}}{W_{j\\to i}} = \\frac{P_j^{\\text{eq}}}{P_i^{\\text{eq}}} = e^{-\\beta(E_j-E_i)}\\]\nDetailed balance ensures that there are no net probability currents in equilibrium.\n\n\nIn the sedimentation example, we can apply detailed balance to particles moving between different heights in a gravitational field. Consider transitions between heights \\(h_i\\) and \\(h_j\\):\n\nThe equilibrium probability to find a particle at height \\(h\\) is \\(P(h) \\propto e^{-\\beta mgh}\\)\nFor a particle moving from height \\(h_i\\) to a higher position \\(h_j\\), the energy difference is \\(\\Delta E = mg(h_j - h_i)\\)\n\nBy detailed balance, the transition rates must satisfy:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis reveals that upward transitions (against gravity) are exponentially suppressed compared to downward transitions. If we observe the system over time, we would see particles moving both up and down, but with precisely balanced rates that maintain the exponential density profile.\nThis balance has profound implications for trajectory reversibility. In equilibrium systems, detailed balance ensures that for any specific trajectory \\(\\gamma\\) a particle takes from height \\(h_i\\) to \\(h_j\\) over a time interval \\([0,t]\\), the time-reversed trajectory \\(\\bar{\\gamma}\\) (the same path followed backward in time) from \\(h_j\\) to \\(h_i\\) occurs with a probability that differs only by the Boltzmann factor:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\]\nThis microscopic reversibility means that if we filmed the motion of an equilibrium system and played the recording backward, the reversed motion would be statistically indistinguishable from the forward motion (when properly weighted by the equilibrium probabilities). For particles in sedimentation, this time-reversal symmetry ensures that no systematic currents exist in the steady state—particles may diffuse up and down, but any apparent “uphill” motion is precisely balanced by “downhill” motion, maintaining the exponential density profile without net circulation in phase space.\n\n\n\n\n\n\nConnecting to Fluctuation Theorems\n\n\n\n\n\nThe relationship between detailed balance, trajectory reversibility, and sedimentation connects directly to fluctuation theorems, which provide a broader framework for understanding non-equilibrium systems:\n\n\nThe trajectory reversibility we described for equilibrium systems (where \\(\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\)) is actually a special case of more general fluctuation theorems that apply even to non-equilibrium systems. These theorems quantify the probability of observing trajectories that appear to violate the second law of thermodynamics.\nFor the sedimentation example, the key connections are:\n\nCrooks Fluctuation Theorem: This relates the probability of forward and reverse trajectories to the entropy production:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta(W-\\Delta F)} = e^{\\Delta S_{tot}/k_B}\\]\nWhere \\(W\\) is the work done, \\(\\Delta F\\) is the free energy difference, and \\(\\Delta S_{tot}\\) is the total entropy production.\nEquilibrium Special Case: When detailed balance is satisfied (as in passive sedimentation), \\(W = \\Delta F = mg(h_j-h_i)\\) and \\(\\Delta S_{tot} = 0\\), recovering our earlier result.\nActive Systems: For active particles in sedimentation, we have additional work from active forces, leading to:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta mg(h_j-h_i) + \\Delta S_{act}/k_B}\\]\nWhere \\(\\Delta S_{act} &gt; 0\\) is the entropy production due to activity.\n\n\n\n\n\n\n\n\n\n\n\nMaster Equation Formulation\n\n\n\n\n\nDetailed balance can be elegantly formulated in terms of a master equation, which provides a powerful framework for understanding the time evolution of probability distributions.The master equation describes how the probability \\(P_i(t)\\) of finding the system in state \\(i\\) evolves over time:\n\\[\\frac{dP_i(t)}{dt} = \\sum_j [W_{j \\to i} P_j(t) - W_{i \\to j} P_i(t)]\\]\nwhere \\(W_{j→i}\\) is the transition rate from state \\(j\\) to state \\(i\\).\nThe first term represents probability flowing into state \\(i\\) from all other states \\(j\\), while the second term represents probability flowing out of state \\(i\\) to all other states \\(j\\).\n\n\nAt steady state, the left-hand side of the master equation equals zero, meaning:\n\\[\\sum_j [W_{j \\to i} P_j - W_{i \\to j} P_i] = 0\\]\nHowever, detailed balance imposes a much stronger condition - that each term in this sum must individually equal zero:\n\\[W_{j \\to i} P_j^{eq} = W_{i \\to j} P_i^{eq} \\quad \\text{for all pairs } i,j\\]\nThis is equivalent to requiring that the net probability current between any two states vanishes at equilibrium.\n\n\n\nFor sedimentation, we can discretize the height into levels \\({h_i}\\). The master equation becomes:\n\\[\\frac{dP(h_i,t)}{dt} = \\sum_j [W_{h_j \\to h_i} P(h_j,t) - W_{h_i \\to h_j} P(h_i,t)]\\]\nDetailed balance requires:\n\\[W_{h_j \\to h_i} P^{eq}(h_j) = W_{h_i \\to h_j} P^{eq}(h_i)\\]\nSubstituting the Boltzmann distribution \\(P^{eq}(h) \\propto e^{-\\beta mgh}\\):\n\\[W_{h_j \\to h_i} e^{-\\beta mgh_j} = W_{h_i \\to h_j} e^{-\\beta mgh_i}\\]\nRearranging:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis recovers our previous expression for detailed balance in sedimentation.\n\n\n\nFor active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:\n\\[W_{h_j \\to h_i}^{act} P^{ss}(h_j) \\neq W_{h_i \\to h_j}^{act} P^{ss}(h_i)\\]\nwhere \\(P^ss\\) denotes the non-equilibrium steady state distribution.\n\n\n\n\n\n\n\n\n\nBrownian motion provides a simple yet powerful model for understanding thermal fluctuations. The Langevin equation describes the motion of a Brownian particle:\n\\[m\\frac{d^2x}{dt^2} = -\\gamma\\frac{dx}{dt} - \\frac{dU(x)}{dx} + \\xi(t)\\]\nwhere \\(\\gamma\\) is the friction coefficient, \\(U(x)\\) is the potential energy, and \\(\\xi(t)\\) is Gaussian white noise with:\n\\[\\langle\\xi(t)\\rangle = 0, \\quad \\langle\\xi(t)\\xi(t')\\rangle = 2\\gamma k_B T \\delta(t-t')\\]\nThe noise amplitude is related to the friction coefficient through the fluctuation-dissipation relation, a consequence of thermal equilibrium. This relation embodies a deep physical principle: the same microscopic processes that cause energy dissipation (friction) also generate fluctuations (noise), with temperature determining their relative strength.\nUnderstanding the Langevin equation is crucial as it serves as a conceptual bridge between equilibrium and non-equilibrium physics. When modeling active particles, we extend this framework by adding a self-propulsion term. The simplest model of an active Brownian particle (ABP) incorporates a propulsion force of constant magnitude but with a direction that changes through rotational diffusion:\n\\[\\gamma\\frac{d\\mathbf{r}}{dt} = -\\nabla U(\\mathbf{r}) + \\gamma v_0 \\mathbf{n}(t) + \\boldsymbol{\\xi}(t)\\]\nwhere \\(v_0\\) represents the swimming speed and \\(\\mathbf{n}(t)\\) is a unit vector undergoing rotational diffusion. This seemingly simple modification profoundly transforms the physics, leading to enhanced diffusion, boundary accumulation, and novel collective behaviors unlike anything seen in passive systems.\nIn many situations relevant to colloidal systems and active matter, inertial effects can be neglected, leading to the overdamped limit of the Langevin equation:\n\\[\\gamma\\frac{dx}{dt} = -\\frac{dU(x)}{dx} + \\xi(t)\\]\nThis overdamped approximation accurately describes microscopic active systems such as bacterial suspensions, catalytic Janus particles, and colloidal rollers. In these systems, the Reynolds number is extremely low (typically \\(10^-5\\) to \\(10^-2\\)), meaning viscous forces dominate over inertial forces. Consequently, particles stop moving almost instantaneously when propulsion ceases—a counterintuitive behavior compared to our macroscopic experience where objects continue moving due to inertia.\nThe Langevin framework will serve as our starting point for understanding how active systems systematically violate equilibrium principles. As we explore further, we’ll see that active matter requires expanding our theoretical tools beyond equilibrium statistical mechanics to account for the continuous energy input that drives these fascinating systems far from equilibrium.\n\n\n\nThe Fluctuation-Dissipation Theorem (FDT) is a cornerstone principle in equilibrium statistical mechanics that connects two seemingly different phenomena:\n\nThe random thermal fluctuations that naturally occur in a system at equilibrium\nHow that same system responds when deliberately disturbed by an external force\n\nMathematically, the FDT is often most elegantly expressed in frequency space:\n\\[\\chi''(\\omega) = \\frac{\\omega}{2k_B T}S(\\omega)\\]\nwhere \\(\\chi''(\\omega)\\) is the imaginary part of the frequency-dependent susceptibility (describing the dissipative response to perturbations), and \\(S(\\omega)\\) is the power spectral density of the equilibrium fluctuations.\nAlternatively, using the full complex susceptibility:\n\\[\\chi(\\omega) = \\frac{1}{k_B T}\\int_0^{\\infty} C(t)e^{i\\omega t}dt\\]\nThe FDT tells us that for systems in thermal equilibrium, these two behaviors are directly linked through temperature. This means we can learn how a system will respond to an external force simply by observing how it naturally fluctuates when left alone—a profound connection that becomes particularly transparent in the frequency domain.\n\n\n\n\n\n\nTrapped Brownian particle\n\n\n\n\n\nConsider a microscopic particle trapped in an optical tweezer (essentially a harmonic potential created by focused laser light). The particle jiggles around randomly due to collisions with surrounding fluid molecules - these are its natural thermal fluctuations.\nThe FDT tells us that by simply measuring how much this particle naturally jiggles (its position fluctuations), we can predict exactly how far it would move if we applied a small external force to it.\nLet’s examine this for a colloidal particle in a one-dimensional harmonic trap, described by the overdamped Langevin equation:\n\\[\\gamma \\frac{dx}{dt} = -kx + \\xi(t) + F_{ext}(t)\\]\nwhere:\n\n\\(\\gamma\\) is the friction coefficient (resistance to motion)\n\\(k\\) is the trap stiffness (strength of the restoring force)\n\\(\\xi(t)\\) is thermal noise from random molecular collisions\n\\(F_{ext}(t)\\) is any external force we might apply\n\nThe FDT connects two important quantities:\n\nThe position autocorrelation function \\(C(t-t')\\), which tells us how the particle’s random motions are correlated across time:\n\n\\[C(t-t') = \\langle x(t)x(t') \\rangle - \\langle x(t) \\rangle \\langle x(t') \\rangle\\]\nIn equilibrium with no external force, this equals:\n\\[C(t-t') = \\frac{k_B T}{k}e^{-\\frac{k}{\\gamma}|t-t'|}\\]\n\nThe response function \\(\\chi(t-t')\\), which measures how the particle’s position responds to a small external force:\n\n\\[\\chi(t-t') = \\frac{\\delta \\langle x(t) \\rangle}{\\delta F_{ext}(t')}\\]\nFor our harmonic trap:\n\\[\\chi(t-t') = \\frac{1}{\\gamma}e^{-\\frac{k}{\\gamma}(t-t')} \\Theta(t-t')\\]\nwhere \\(\\Theta(t-t')\\) is the Heaviside step function (ensuring causality - the system can’t respond before the force is applied).\nThe FDT directly relates these quantities through temperature:\n\\[\\chi(t-t') = -\\frac{1}{k_B T}\\frac{d}{dt}C(t-t') \\quad \\text{for } t &gt; t'\\]\nThis equation embodies the profound insight that the same microscopic mechanisms responsible for dissipation (friction) also generate fluctuations, with temperature determining their relative strength.\n\n\n\nThe FDT is a powerful tool in equilibrium systems, but it breaks down in active matter. In active systems, energy is continuously injected at the microscopic level through self-propulsion mechanisms. This additional energy input means that fluctuations can be much larger than what would be predicted from the system’s response properties using the equilibrium FDT.\nThe violation of the FDT in active systems provides a quantitative measure of how far these systems operate from equilibrium, making it a valuable tool for characterizing active matter.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lecture02/lecture02.html#brief-review-of-equilibrium-statistical-mechanics",
    "href": "lecture02/lecture02.html#brief-review-of-equilibrium-statistical-mechanics",
    "title": "Statistical Mechanics Terms",
    "section": "",
    "text": "Equilibrium statistical mechanics may seem like a contradictory starting point for understanding fundamentally non-equilibrium phenomena in active matter. However, we begin with these concepts precisely because understanding how and why active systems violate equilibrium principles illuminates their unique properties. In this section, we review key equilibrium concepts that provide a crucial reference frame against which we can measure and characterize the non-equilibrium nature of active systems.\n\n\nFor a system in thermal equilibrium with a heat bath at temperature \\(T\\) not exchanging particles with the environment, the probability of finding the system in a microstate with phase space coordinates \\(\\Gamma = \\{\\mathbf{q}, \\mathbf{p}\\}\\) is given by the Boltzmann distribution:\n\\[P(\\Gamma) = \\frac{1}{Z} e^{-\\beta H(\\Gamma)}\\]\nwhere \\(\\beta = 1/(k_B T)\\), \\(k_B\\) is Boltzmann’s constant, \\(H(\\Gamma)\\) is the Hamiltonian of the system, and \\(Z\\) is the partition function:\n\\[Z = \\frac{1}{h^{3N}N!}\\int e^{-\\beta H(\\Gamma)} d\\Gamma\\]\nIn this expression, \\(h\\) is Planck’s constant, \\(N\\) is the number of particles, and the factors \\(h^{3N}\\) and \\(N!\\) account for the quantum uncertainty principle and the indistinguishability of identical particles, respectively. This normalization ensures that the partition function is dimensionless.\nIn physical terms, the Boltzmann distribution reflects how energy is partitioned among the available states at thermal equilibrium. States with lower energy are exponentially more likely to be occupied than states with higher energy. For active matter systems, this distribution is significantly altered because energy is continuously injected at the microscopic level, driving the system away from this equilibrium distribution. Indeed, active systems generally cannot be described by a time-independent Hamiltonian at all, as they involve non-conservative forces.\nThe partition function is central to statistical mechanics as it connects microscopic properties to macroscopic observables. For instance, the average energy is:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\\]\nThis relationship highlights how the partition function serves as a generating function for thermodynamic quantities. When studying active matter, we’ll see that traditional partition functions often cannot be defined because these systems don’t explore phase space according to Boltzmann statistics.\n\n\n\n\n\n\nSedimentation Example\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Perrin’s sedimentation experiments. The exponential decay in the number density of colloidal particles with height directly confirmed the Boltzmann distribution and provided key evidence for the atomic theory of matter.\n\n\n\nA clear demonstration of the Boltzmann distribution’s power can be derived from the canonical partition function using the barometric distribution of particles in a gravitational field. Consider colloidal particles suspended in a fluid in a gravitational field \\(g\\).\nThe Hamiltonian for a particle at height \\(h\\) with momentum \\(p\\) is:\n\\[H(h, p) = \\frac{p^2}{2m} + mgh\\]\nwhere the first term represents the kinetic energy and the second term is the gravitational potential energy. For this system, we can construct the partition function by integrating over all possible heights and momenta:\n\\[Z = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(h,p)} dp dh = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp dh\\]\nThis can be separated into:\n\\[Z = \\int_{-\\infty}^{\\infty} e^{-\\beta\\frac{p^2}{2m}} dp \\cdot \\int_0^{\\infty} e^{-\\beta mgh} dh\\]\nThe momentum integral gives \\(\\sqrt{\\frac{2\\pi m}{\\beta}}\\), while the height integral yields \\(\\frac{1}{\\beta mg}\\), resulting in:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg} = \\sqrt{\\frac{2\\pi m}{\\beta^3 m^2 g^2}}\\]\nThe probability density for finding a particle at height \\(h\\) (integrating over all momenta) is:\n\\[P(h) = \\frac{\\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp}{Z} = \\frac{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot e^{-\\beta mgh}}{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg}} = \\beta mg e^{-\\beta mgh}\\]\nFrom this, we can derive the number density \\(n(h)\\) by multiplying by the total number of particles \\(N\\):\n\\[n(h) = N \\cdot P(h) = N \\beta mg e^{-\\beta mgh}\\]\nIf we define \\(n_0\\) as the density at \\(h=0\\), then \\(n_0 = N \\beta mg\\), and we obtain:\n\\[n(h) = n_0 e^{-\\beta mgh} = n_0 e^{-\\frac{mgh}{k_B T}}\\]\nTaking the logarithm of both sides:\n\\[\\ln\\left(\\frac{n(h)}{n_0}\\right) = -\\beta mgh = -\\frac{mgh}{k_B T}\\]\nThis direct connection between the Hamiltonian, partition function, and the observable barometric distribution provides a compelling experimental verification of statistical mechanics. Jean Perrin used this relationship in 1908 to experimentally determine Avogadro’s number and provide crucial evidence for the atomic theory of matter. Today, similar experiments with colloidal particles serve as textbook demonstrations of statistical mechanics in action.\n\n\n\n\n\n\nThe Helmholtz free energy is a thermodynamic potential that determines the maximum useful work obtainable from a closed system at constant temperature and volume. Named after German physicist Hermann von Helmholtz, it represents the amount of energy available to do non-expansion work. The Helmholtz free energy is particularly relevant in statistical mechanics because it serves as the fundamental bridge between microscopic properties (encoded in the partition function) and macroscopic thermodynamic behavior. For systems in the canonical ensemble—where the number of particles, volume, and temperature are fixed—the Helmholtz free energy provides the appropriate thermodynamic potential whose minimum determines the equilibrium state.\nThe Helmholtz free energy \\(F\\) is related to the partition function by:\n\\[F = -k_B T \\ln Z = -k_B T \\ln \\left(\\frac{1}{h^{3N}N!}\\int e^{-\\beta H(\\Gamma)} d\\Gamma\\right)\\]\nwhere the normalization factor \\(\\frac{1}{h^{3N}N!}\\) ensures proper dimensionless units in the partition function, with \\(h\\) being Planck’s constant and \\(N\\) the number of particles.\nWe can rewrite this as \\(F = E - TS\\), explicitly showing the competition between the enthalpic (energy) and entropic contributions:\n\\[F = \\langle H \\rangle - TS\\]\nwhere \\(\\langle H \\rangle\\) is the average energy:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta} = \\frac{\\int H(\\Gamma) e^{-\\beta H(\\Gamma)} d\\Gamma}{\\int e^{-\\beta H(\\Gamma)} d\\Gamma}\\]\nand \\(S\\) is the entropy:\n\\[S = -\\left(\\frac{\\partial F}{\\partial T}\\right)_V = k_B \\ln Z + \\frac{\\langle H \\rangle}{T}\\]\nAt equilibrium, minimizing the free energy involves a fundamental competition between:\n\nEnergy minimization: The system tends to occupy low-energy states to minimize \\(\\langle H \\rangle\\)\nEntropy maximization: The system tends to spread over many accessible states to maximize \\(S\\)\n\nThe Boltzmann distribution \\(P(\\Gamma) = \\frac{1}{Z}e^{-\\beta H(\\Gamma)}\\) represents the optimal compromise between these competing tendencies. For systems with fixed particle number, volume, and temperature (canonical ensemble), this distribution precisely minimizes the free energy subject to the constraints of the canonical ensemble.\nThe principle of free energy minimization is particularly important for understanding the contrast with active systems. In active matter, free energy is constantly being pumped into the system through microscopic driving mechanisms (e.g., molecular motors in cell cytoskeleton, metabolic processes in bacteria, or artificial propulsion mechanisms in synthetic swimmers). These systems involve non-conservative forces that cannot be derived from a Hamiltonian, so they cannot be described by a minimum free energy principle, which is a fundamental departure from equilibrium thermodynamics.\n\n\n\n\n\n\nHarmonic Oscillator Example\n\n\n\n\n\nThe harmonic oscillator provides another illuminating example of equilibrium statistical mechanics. Consider a Brownian particle in a harmonic potential \\(U(x) = \\frac{1}{2}kx^2\\) provided by some highly focused light beam. Here \\(k\\) is the spring constant.\n\n\n\n\n\n\nFigure 2: Sketch of a colloidal particle trapped in the focus of a microscopy lens due to electromagnetic forces. source\n\n\n\nThe particle experiences both a restoring force and random thermal kicks from the surrounding fluid.\nThe Hamiltonian for this system is:\n\\[H(x,p) = \\frac{p^2}{2m} + \\frac{1}{2}kx^2\\]\nwhere \\(m\\) is the particle mass, \\(x\\) is position, and \\(p\\) is momentum. The partition function is:\n\\[Z = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(x,p)} dx dp = \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{p^2}{2m}} dp \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{1}{2}kx^2} dx\\]\nEvaluating these Gaussian integrals:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\sqrt{\\frac{2\\pi}{\\beta k}} = \\frac{2\\pi}{\\beta\\omega_0}\\]\nwhere \\(\\omega_0 = \\sqrt{k/m}\\) is the natural frequency of the oscillator.\nThe probability density for finding the particle at position \\(x\\) is:\n\\[P(x) = \\sqrt{\\frac{\\beta k}{2\\pi}} e^{-\\beta \\frac{1}{2}kx^2}\\]\nThis Gaussian distribution has variance \\(\\sigma^2 = \\frac{1}{\\beta k} = \\frac{k_B T}{k}\\).\nThe equipartition theorem states that each quadratic term in the Hamiltonian contributes \\(\\frac{1}{2}k_B T\\) to the average energy:\n\\[\\left \\langle \\frac{p^2}{2m} \\right \\rangle = \\left \\langle \\frac{1}{2}kx^2 \\right \\rangle = \\frac{1}{2}k_B T\\]\nTherefore, the mean-square displacement of the particle is:\n\\[\\langle x^2 \\rangle = \\frac{k_B T}{k}\\]\nThis simple relation demonstrates how thermal energy causes the particle to explore the potential well, with the stiffness of the spring determining the confinement. Stiffer springs (larger \\(k\\)) lead to smaller position fluctuations.\n\n\n\n\n\n\nA key assumption in equilibrium statistical mechanics is ergodicity—the equivalence between time averages and ensemble averages:\n\\[\\langle A \\rangle_{\\text{time}} = \\lim_{T\\to\\infty} \\frac{1}{T} \\int_0^T A(t) dt = \\langle A \\rangle_{\\text{ensemble}}\\]\nIn practical terms, ergodicity means that if you observe a single system for a sufficiently long time, it will eventually visit all microscopic states consistent with its macroscopic constraints, allowing time averages to equal ensemble averages. Active matter systems often violate ergodicity by persistently exploring only a subset of the available phase space due to their self-propulsion mechanisms. This has profound implications for both experimental measurements and theoretical descriptions of active systems.\nEquilibrium dynamics satisfies detailed balance, a microscopic time-reversal symmetry condition. For transitions between states \\(i\\) and \\(j\\) with rates \\(W_{i\\to j}\\) and \\(W_{j\\to i}\\):\n\\[\\frac{W_{i\\to j}}{W_{j\\to i}} = \\frac{P_j^{\\text{eq}}}{P_i^{\\text{eq}}} = e^{-\\beta(E_j-E_i)}\\]\nDetailed balance ensures that there are no net probability currents in equilibrium.\n\n\nIn the sedimentation example, we can apply detailed balance to particles moving between different heights in a gravitational field. Consider transitions between heights \\(h_i\\) and \\(h_j\\):\n\nThe equilibrium probability to find a particle at height \\(h\\) is \\(P(h) \\propto e^{-\\beta mgh}\\)\nFor a particle moving from height \\(h_i\\) to a higher position \\(h_j\\), the energy difference is \\(\\Delta E = mg(h_j - h_i)\\)\n\nBy detailed balance, the transition rates must satisfy:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis reveals that upward transitions (against gravity) are exponentially suppressed compared to downward transitions. If we observe the system over time, we would see particles moving both up and down, but with precisely balanced rates that maintain the exponential density profile.\nThis balance has profound implications for trajectory reversibility. In equilibrium systems, detailed balance ensures that for any specific trajectory \\(\\gamma\\) a particle takes from height \\(h_i\\) to \\(h_j\\) over a time interval \\([0,t]\\), the time-reversed trajectory \\(\\bar{\\gamma}\\) (the same path followed backward in time) from \\(h_j\\) to \\(h_i\\) occurs with a probability that differs only by the Boltzmann factor:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\]\nThis microscopic reversibility means that if we filmed the motion of an equilibrium system and played the recording backward, the reversed motion would be statistically indistinguishable from the forward motion (when properly weighted by the equilibrium probabilities). For particles in sedimentation, this time-reversal symmetry ensures that no systematic currents exist in the steady state—particles may diffuse up and down, but any apparent “uphill” motion is precisely balanced by “downhill” motion, maintaining the exponential density profile without net circulation in phase space.\n\n\n\n\n\n\nConnecting to Fluctuation Theorems\n\n\n\n\n\nThe relationship between detailed balance, trajectory reversibility, and sedimentation connects directly to fluctuation theorems, which provide a broader framework for understanding non-equilibrium systems:\n\n\nThe trajectory reversibility we described for equilibrium systems (where \\(\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\)) is actually a special case of more general fluctuation theorems that apply even to non-equilibrium systems. These theorems quantify the probability of observing trajectories that appear to violate the second law of thermodynamics.\nFor the sedimentation example, the key connections are:\n\nCrooks Fluctuation Theorem: This relates the probability of forward and reverse trajectories to the entropy production:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta(W-\\Delta F)} = e^{\\Delta S_{tot}/k_B}\\]\nWhere \\(W\\) is the work done, \\(\\Delta F\\) is the free energy difference, and \\(\\Delta S_{tot}\\) is the total entropy production.\nEquilibrium Special Case: When detailed balance is satisfied (as in passive sedimentation), \\(W = \\Delta F = mg(h_j-h_i)\\) and \\(\\Delta S_{tot} = 0\\), recovering our earlier result.\nActive Systems: For active particles in sedimentation, we have additional work from active forces, leading to:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta mg(h_j-h_i) + \\Delta S_{act}/k_B}\\]\nWhere \\(\\Delta S_{act} &gt; 0\\) is the entropy production due to activity.\n\n\n\n\n\n\n\n\n\n\n\nMaster Equation Formulation\n\n\n\n\n\nDetailed balance can be elegantly formulated in terms of a master equation, which provides a powerful framework for understanding the time evolution of probability distributions.The master equation describes how the probability \\(P_i(t)\\) of finding the system in state \\(i\\) evolves over time:\n\\[\\frac{dP_i(t)}{dt} = \\sum_j [W_{j \\to i} P_j(t) - W_{i \\to j} P_i(t)]\\]\nwhere \\(W_{j→i}\\) is the transition rate from state \\(j\\) to state \\(i\\).\nThe first term represents probability flowing into state \\(i\\) from all other states \\(j\\), while the second term represents probability flowing out of state \\(i\\) to all other states \\(j\\).\n\n\nAt steady state, the left-hand side of the master equation equals zero, meaning:\n\\[\\sum_j [W_{j \\to i} P_j - W_{i \\to j} P_i] = 0\\]\nHowever, detailed balance imposes a much stronger condition - that each term in this sum must individually equal zero:\n\\[W_{j \\to i} P_j^{eq} = W_{i \\to j} P_i^{eq} \\quad \\text{for all pairs } i,j\\]\nThis is equivalent to requiring that the net probability current between any two states vanishes at equilibrium.\n\n\n\nFor sedimentation, we can discretize the height into levels \\({h_i}\\). The master equation becomes:\n\\[\\frac{dP(h_i,t)}{dt} = \\sum_j [W_{h_j \\to h_i} P(h_j,t) - W_{h_i \\to h_j} P(h_i,t)]\\]\nDetailed balance requires:\n\\[W_{h_j \\to h_i} P^{eq}(h_j) = W_{h_i \\to h_j} P^{eq}(h_i)\\]\nSubstituting the Boltzmann distribution \\(P^{eq}(h) \\propto e^{-\\beta mgh}\\):\n\\[W_{h_j \\to h_i} e^{-\\beta mgh_j} = W_{h_i \\to h_j} e^{-\\beta mgh_i}\\]\nRearranging:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis recovers our previous expression for detailed balance in sedimentation.\n\n\n\nFor active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:\n\\[W_{h_j \\to h_i}^{act} P^{ss}(h_j) \\neq W_{h_i \\to h_j}^{act} P^{ss}(h_i)\\]\nwhere \\(P^ss\\) denotes the non-equilibrium steady state distribution.\n\n\n\n\n\n\n\n\n\nBrownian motion provides a simple yet powerful model for understanding thermal fluctuations. The Langevin equation describes the motion of a Brownian particle:\n\\[m\\frac{d^2x}{dt^2} = -\\gamma\\frac{dx}{dt} - \\frac{dU(x)}{dx} + \\xi(t)\\]\nwhere \\(\\gamma\\) is the friction coefficient, \\(U(x)\\) is the potential energy, and \\(\\xi(t)\\) is Gaussian white noise with:\n\\[\\langle\\xi(t)\\rangle = 0, \\quad \\langle\\xi(t)\\xi(t')\\rangle = 2\\gamma k_B T \\delta(t-t')\\]\nThe noise amplitude is related to the friction coefficient through the fluctuation-dissipation relation, a consequence of thermal equilibrium. This relation embodies a deep physical principle: the same microscopic processes that cause energy dissipation (friction) also generate fluctuations (noise), with temperature determining their relative strength.\nUnderstanding the Langevin equation is crucial as it serves as a conceptual bridge between equilibrium and non-equilibrium physics. When modeling active particles, we extend this framework by adding a self-propulsion term. The simplest model of an active Brownian particle (ABP) incorporates a propulsion force of constant magnitude but with a direction that changes through rotational diffusion:\n\\[\\gamma\\frac{d\\mathbf{r}}{dt} = -\\nabla U(\\mathbf{r}) + \\gamma v_0 \\mathbf{n}(t) + \\boldsymbol{\\xi}(t)\\]\nwhere \\(v_0\\) represents the swimming speed and \\(\\mathbf{n}(t)\\) is a unit vector undergoing rotational diffusion. This seemingly simple modification profoundly transforms the physics, leading to enhanced diffusion, boundary accumulation, and novel collective behaviors unlike anything seen in passive systems.\nIn many situations relevant to colloidal systems and active matter, inertial effects can be neglected, leading to the overdamped limit of the Langevin equation:\n\\[\\gamma\\frac{dx}{dt} = -\\frac{dU(x)}{dx} + \\xi(t)\\]\nThis overdamped approximation accurately describes microscopic active systems such as bacterial suspensions, catalytic Janus particles, and colloidal rollers. In these systems, the Reynolds number is extremely low (typically \\(10^-5\\) to \\(10^-2\\)), meaning viscous forces dominate over inertial forces. Consequently, particles stop moving almost instantaneously when propulsion ceases—a counterintuitive behavior compared to our macroscopic experience where objects continue moving due to inertia.\nThe Langevin framework will serve as our starting point for understanding how active systems systematically violate equilibrium principles. As we explore further, we’ll see that active matter requires expanding our theoretical tools beyond equilibrium statistical mechanics to account for the continuous energy input that drives these fascinating systems far from equilibrium.\n\n\n\nThe Fluctuation-Dissipation Theorem (FDT) is a cornerstone principle in equilibrium statistical mechanics that connects two seemingly different phenomena:\n\nThe random thermal fluctuations that naturally occur in a system at equilibrium\nHow that same system responds when deliberately disturbed by an external force\n\nMathematically, the FDT is often most elegantly expressed in frequency space:\n\\[\\chi''(\\omega) = \\frac{\\omega}{2k_B T}S(\\omega)\\]\nwhere \\(\\chi''(\\omega)\\) is the imaginary part of the frequency-dependent susceptibility (describing the dissipative response to perturbations), and \\(S(\\omega)\\) is the power spectral density of the equilibrium fluctuations.\nAlternatively, using the full complex susceptibility:\n\\[\\chi(\\omega) = \\frac{1}{k_B T}\\int_0^{\\infty} C(t)e^{i\\omega t}dt\\]\nThe FDT tells us that for systems in thermal equilibrium, these two behaviors are directly linked through temperature. This means we can learn how a system will respond to an external force simply by observing how it naturally fluctuates when left alone—a profound connection that becomes particularly transparent in the frequency domain.\n\n\n\n\n\n\nTrapped Brownian particle\n\n\n\n\n\nConsider a microscopic particle trapped in an optical tweezer (essentially a harmonic potential created by focused laser light). The particle jiggles around randomly due to collisions with surrounding fluid molecules - these are its natural thermal fluctuations.\nThe FDT tells us that by simply measuring how much this particle naturally jiggles (its position fluctuations), we can predict exactly how far it would move if we applied a small external force to it.\nLet’s examine this for a colloidal particle in a one-dimensional harmonic trap, described by the overdamped Langevin equation:\n\\[\\gamma \\frac{dx}{dt} = -kx + \\xi(t) + F_{ext}(t)\\]\nwhere:\n\n\\(\\gamma\\) is the friction coefficient (resistance to motion)\n\\(k\\) is the trap stiffness (strength of the restoring force)\n\\(\\xi(t)\\) is thermal noise from random molecular collisions\n\\(F_{ext}(t)\\) is any external force we might apply\n\nThe FDT connects two important quantities:\n\nThe position autocorrelation function \\(C(t-t')\\), which tells us how the particle’s random motions are correlated across time:\n\n\\[C(t-t') = \\langle x(t)x(t') \\rangle - \\langle x(t) \\rangle \\langle x(t') \\rangle\\]\nIn equilibrium with no external force, this equals:\n\\[C(t-t') = \\frac{k_B T}{k}e^{-\\frac{k}{\\gamma}|t-t'|}\\]\n\nThe response function \\(\\chi(t-t')\\), which measures how the particle’s position responds to a small external force:\n\n\\[\\chi(t-t') = \\frac{\\delta \\langle x(t) \\rangle}{\\delta F_{ext}(t')}\\]\nFor our harmonic trap:\n\\[\\chi(t-t') = \\frac{1}{\\gamma}e^{-\\frac{k}{\\gamma}(t-t')} \\Theta(t-t')\\]\nwhere \\(\\Theta(t-t')\\) is the Heaviside step function (ensuring causality - the system can’t respond before the force is applied).\nThe FDT directly relates these quantities through temperature:\n\\[\\chi(t-t') = -\\frac{1}{k_B T}\\frac{d}{dt}C(t-t') \\quad \\text{for } t &gt; t'\\]\nThis equation embodies the profound insight that the same microscopic mechanisms responsible for dissipation (friction) also generate fluctuations, with temperature determining their relative strength.\n\n\n\nThe FDT is a powerful tool in equilibrium systems, but it breaks down in active matter. In active systems, energy is continuously injected at the microscopic level through self-propulsion mechanisms. This additional energy input means that fluctuations can be much larger than what would be predicted from the system’s response properties using the equilibrium FDT.\nThe violation of the FDT in active systems provides a quantitative measure of how far these systems operate from equilibrium, making it a valuable tool for characterizing active matter.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lecture02/lecture02.html#violation-in-active-systems",
    "href": "lecture02/lecture02.html#violation-in-active-systems",
    "title": "Statistical Mechanics Terms",
    "section": "",
    "text": "For active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:\n\\[W_{h_j \\to h_i}^{act} P^{ss}(h_j) \\neq W_{h_i \\to h_j}^{act} P^{ss}(h_i)\\]\nwhere \\(P^ss\\) denotes the non-equilibrium steady state distribution.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lecture02/lecture02.html#examples",
    "href": "lecture02/lecture02.html#examples",
    "title": "Statistical Mechanics Terms",
    "section": "Examples",
    "text": "Examples\n\nTwo Brownian particles with non-uniform temperatures\nTo concretely illustrate how equilibrium concepts apply to coupled systems and how they break down when thermal equilibrium is violated, let’s consider a simple model: two Brownian particles connected by springs, with different temperatures.\nConsider the following system: - Two Brownian particles with positions \\(x_1\\) and \\(x_2\\) - Particle 1 is connected to a fixed wall by a spring with constant \\(k_1\\) - The two particles are connected to each other by a spring with constant \\(k_2\\) - Particle 2 is connected to a fixed wall by a spring with constant \\(k_3\\) - Particle 1 experiences thermal fluctuations at temperature \\(T_1\\) - Particle 2 experiences thermal fluctuations at temperature \\(T_2\\)\nThe Langevin equations for this system are:\n\\[\\gamma_1 \\frac{dx_1}{dt} = -k_1 x_1 - k_2(x_1 - x_2) + \\xi_1(t)\\] \\[\\gamma_2 \\frac{dx_2}{dt} = -k_3 x_2 - k_2(x_2 - x_1) + \\xi_2(t)\\]\nwhere \\(\\gamma_i\\) are the friction coefficients and \\(\\xi_i(t)\\) are Gaussian white noises with:\n\\[\\langle \\xi_i(t) \\rangle = 0, \\quad \\langle \\xi_i(t) \\xi_i(t') \\rangle = 2\\gamma_i k_B T_i \\delta(t-t')\\]\nWhen \\(T_1 = T_2\\), this system is in thermal equilibrium, and the probability distribution for the positions follows the Boltzmann distribution:\n\\[P(x_1, x_2) \\propto \\exp\\left(-\\frac{1}{k_B T}[k_1 x_1^2/2 + k_2(x_1-x_2)^2/2 + k_3 x_2^2/2]\\right)\\]\nHowever, when \\(T_1 \\neq T_2\\), the system is driven out of equilibrium, leading to a non-Boltzmann stationary distribution. The correlation between \\(x_1\\) and \\(x_2\\) encodes information about the non-equilibrium nature of the system.\n\n\n\n\n\n\nFigure 3: Brownian-dynamics simulation of 1D bead-spring model. (A) Model schematic. (B) Time series of the bead positions for T2 = 1.5T1 and equal spring constants. See figs. S4 and S5 for the general case (18). (C and D) Probability distribution (color) and flux map (white arrows) in CGPS spanned by x1 and x2 for the simulation in panel B (C) and for a simulation with T2 = T1 (D). Translucent disks represent a 2s confidence interval for fluxes. source\n\n\n\nIn this non-equilibrium scenario, energy flows from the hotter to the colder particle, driving the system away from equilibrium. The stationary state represents a balance between this energy flow and dissipation, rather than a state of maximum entropy as in equilibrium systems. The detailed balance condition is violated, and the system exhibits persistent probability currents in phase space - a hallmark of non-equilibrium behavior.\n\n\nChlamydomonas Swimming\nThe violation of detailed balance is perhaps the most direct signature of non-equilibrium behavior in active matter. The microalgae Chlamydomonas Reinhardtii provides an exemplary demonstration of this principle.\n\n\n\n\n\n\nFigure 4: Light microscopy image of Chlamydomonas Reinhardtii, a single-celled green alga with two flagella used for swimming and sensing. source\n\n\n\nChlamydomonas Reinhardtii propels itself through fluid by coordinated beating of its two flagella. This motion requires continuous energy consumption, as each flagellum hydrolyzes ATP to power molecular motors that generate rhythmic beating patterns. Unlike passive Brownian particles, where motion arises from random thermal fluctuations, the flagellar beating represents a driven, non-equilibrium process.\nAs shown in the figures below, researchers have characterized this non-equilibrium behavior by analyzing the flagellar dynamics in a coarse-grained phase space (CGPS) constructed from the principal bending modes. The beating patterns can be decomposed into these fundamental modes (similar to Fourier components), allowing quantitative tracking of the flagellar configuration over time.\nThe phase space probability distribution and corresponding flux maps reveal a striking signature of non-equilibrium dynamics: coherent probability currents that form closed loops. These directed cyclic trajectories through configuration space explicitly violate detailed balance, which would require all microscopic transitions to be pairwise-balanced with no net probability flux between states. In an equilibrium system, transitions between any two states would occur with equal frequency in both directions when properly weighted by their equilibrium probabilities.\n\n\n\n\n\n\nFigure 5: Detailed balance and actively beating Chlamydomonas flagella. (A) In thermodynamic equilibrium, transitions between microscopic states are pairwise-balanced, precluding net flux among states. (B) Nonequilibrium steady states can break detailed balance and exhibit flux loops. (C) Snapshots separated by 24 (orange-yellow), 7, and 10 ms in an isolated Chlamydomonas flagellum’s beat cycle (movie S1). Arrows on the central circle indicate the direction of time. Color corresponds to position in (E). (D) The first three bending modes for a freely suspended flexible rod. (E) A three-dimensional (3D) probability flux map of flagellar dynamics in the CGPS spanned by the first three modes.source\n\n\n\nThe flux maps in panels F and G below show clear rotational currents in the phase space of bending modes. These currents represent the flagellum cycling through configurations in a specific sequence rather than randomly exploring available states as would occur in thermal equilibrium. The directed nature of these probability currents directly quantifies the system’s departure from equilibrium.\n\n\n\n\n\n\nFigure 6: (F and G) Probability distribution (color) and flux map (white arrows) of flagellar dynamics in CGPS spanned by first and second modes (F), and first and third modes (G). The white legend indicates the flux scale. source\n\n\n\nThese probability flux loops are fundamental to biological function, enabling directed motion and mechanical work that would be thermodynamically prohibited under equilibrium constraints. Similar non-equilibrium dynamics appear in many biological systems, from molecular motors and cell migration to collective tissue behaviors, where energy consumption drives the system away from equilibrium to perform essential biological functions.\n\n\nPrimary cilia in epithelial cells\nPrimary cilia represent another biological system that exhibits non-equilibrium dynamics, but in a more subtle manner than the flagella of Chlamydomonas. These hairlike organelles project from many eukaryotic cells and transduce mechanical and chemical stimuli into intracellular signals. Unlike flagella, primary cilia often lack the dynein machinery necessary for active beating, causing them to fluctuate in what appears to be a random manner.\nWhen analyzed in the phase space defined by their deflection angle and curvature, primary cilia of MDCK (Madin-Darby canine kidney) epithelial cells reveal clockwise circulation patterns in their probability flux maps. These patterns indicate broken detailed balance, providing direct evidence of non-equilibrium dynamics in these seemingly passive structures. The statistical significance of these flux loops can be quantified, confirming that these cilia indeed operate far from equilibrium despite their apparently random motion.\n\n\n\n\n\n\nFigure 7: Left: Schematic of primary cilium and anchoring of the basal body in the cell cortex with angle q and curvature, k, defined positive as shown. Right: Snapshots of cilium, from differential interference contrast microscopy, taken at time points marked in (B). Scale bar: 2 mm.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Header",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Active Matter Physics",
    "section": "Course Overview",
    "text": "Course Overview\nThe course will examine both natural and synthetic active matter systems across multiple scales:\n\nBiological active matter: From the cytoskeleton and subcellular structures to bacterial suspensions, cell tissues, and animal groups\nSynthetic active matter: Including artificial microswimmers, active colloids, and engineered systems that mimic biological functionality\n\nStudents will gain a fundamental understanding of how local energy consumption at the individual unit level drives remarkable collective behaviors like self-organization, pattern formation, and spontaneous flows through non-equilibrium processes.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#key-concepts-and-topics",
    "href": "index.html#key-concepts-and-topics",
    "title": "Active Matter Physics",
    "section": "Key Concepts and Topics",
    "text": "Key Concepts and Topics\n\nFoundations of non-equilibrium statistical physics\nMicroscopic and continuum theoretical frameworks\nExperimental techniques and model systems\nSelf-propulsion mechanisms and motility\nPhase transitions specific to active systems\nEmergence of collective motion and flocking\nActive turbulence and topological defects\nMechanical properties of active materials\nBiological applications and biomimetic engineering\n\nThe course will balance theoretical principles with experimental observations, emphasizing the universal physical mechanisms that govern these diverse systems despite their different microscopic details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Active Matter Physics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nUpon completion, students will be able to: - Identify and analyze active matter systems across disciplines - Apply theoretical models to predict behavior in active systems - Understand the key differences between equilibrium and non-equilibrium phenomena - Connect fundamental physical principles to biological functions - Appreciate the potential applications in materials science, robotics, and biomedicine\nThis course is suitable for advanced undergraduate and graduate students with backgrounds in physics, engineering, biophysics, or related fields.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "course-info/exam.html",
    "href": "course-info/exam.html",
    "title": "Exam",
    "section": "",
    "text": "Exam Format\n\n\n\nThis course will end with an oral exam of 30 minutes duration. The exams will be held at after the end of the course during the reading period and the week after.\n\n\n\n\n\n\n\n\nExam Eligibility\n\n\n\nThere are no preconditions for taking the exam.",
    "crumbs": [
      "Course Info",
      "Exam"
    ]
  },
  {
    "objectID": "course-info/intructors.html",
    "href": "course-info/intructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructors"
    ]
  },
  {
    "objectID": "course-info/intructors.html#lectures",
    "href": "course-info/intructors.html#lectures",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructors"
    ]
  },
  {
    "objectID": "course-info/intructors.html#seminars",
    "href": "course-info/intructors.html#seminars",
    "title": "Instructors",
    "section": "Seminars",
    "text": "Seminars\n\nDr. Xiangzun Wang\n\nLinnéstr. 5, 04103 Leipzig\nOffice: 333a\nPhone: +49 341 97 32570\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructors"
    ]
  },
  {
    "objectID": "lecture01/examples.html",
    "href": "lecture01/examples.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Key examples across biological and synthetic systems\nActive matter encompasses a diverse range of systems spanning biological and synthetic domains:\n\n\nBiological active matter\n\nCytoskeletal networks: Actin filaments and microtubules with molecular motors that drive cell division, motility, and shape changes\nBacterial suspensions: Dense colonies of swimming bacteria like E. coli that exhibit collective motion and turbulent-like flows\nCell sheets and tissues: Epithelial monolayers that display collective migration during wound healing and morphogenesis\nAnimal collectives: Flocking birds, schooling fish, and insect swarms demonstrating emergent group behaviors\nSubcellular organelles: Active droplets and membrane-less organelles that undergo phase separation driven by metabolic activity\n\nSynthetic active matter\n\nJanus particles: Colloids with asymmetric surface properties that enable self-propulsion through chemical or thermal gradients\nLight-activated swimmers: Particles containing photosensitive materials that convert light energy into directed motion\nMagnetically driven systems: Artificial swimmers controlled by external magnetic fields\nActive liquid crystals: Nematic liquid crystals with embedded energy-consuming components that create topological defects and flow patterns\nVibration-powered granular matter: Macroscopic particles energized by mechanical vibrations exhibiting fluidization and pattern formation\nChemically-powered colloids: Particles utilizing catalytic reactions (e.g., platinum-catalyzed hydrogen peroxide decomposition) for propulsion"
  },
  {
    "objectID": "lecture03/hydrodynamics.html",
    "href": "lecture03/hydrodynamics.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "When microorganisms swim at low Reynolds numbers, they don’t just move themselves - they also generate complex flow fields in the surrounding fluid. These flow fields arise directly from the swimming mechanisms we’ve just explored and have profound implications for how microswimmers interact with their environment and each other.\n\n\nTo understand how swimming generates flow fields, we need to distinguish between two fundamental types of hydrodynamic singularities:\n\nSource/sink dipoles: These represent the displacement of fluid due to a body moving through it. For a simple model, imagine a sphere moving through fluid - it pushes fluid ahead of it (source) and leaves a vacancy behind it that fluid rushes to fill (sink). These source dipoles:\n\nDecay rapidly with distance as \\(1/r^3\\)\nAre responsible for the actual propulsion of the swimmer\nArise from the swimmer’s shape changes and boundary motion\n\nForce dipoles: These represent the balance of thrust and drag forces that the swimmer exerts on the fluid. Since microswimmers are force-free (no external forces act on them), the thrust forces must be balanced by drag forces, creating a dipole. These force dipoles:\n\nDecay more slowly with distance as \\(1/r^2\\)\nDo not contribute to the swimmer’s self-propulsion\nDominate the long-range hydrodynamic interactions\nClassify swimmers as “pushers” or “pullers” based on their swimming mechanism\n\n\nThis distinction is crucial: while source dipoles enable swimming, it’s the force dipoles that mediate most of the interesting long-range interactions between microswimmers."
  },
  {
    "objectID": "lecture03/hydrodynamics.html#from-swimming-to-hydrodynamic-interactions",
    "href": "lecture03/hydrodynamics.html#from-swimming-to-hydrodynamic-interactions",
    "title": "Active Matter Physics",
    "section": "",
    "text": "When microorganisms swim at low Reynolds numbers, they don’t just move themselves - they also generate complex flow fields in the surrounding fluid. These flow fields arise directly from the swimming mechanisms we’ve just explored and have profound implications for how microswimmers interact with their environment and each other.\n\n\nTo understand how swimming generates flow fields, we need to distinguish between two fundamental types of hydrodynamic singularities:\n\nSource/sink dipoles: These represent the displacement of fluid due to a body moving through it. For a simple model, imagine a sphere moving through fluid - it pushes fluid ahead of it (source) and leaves a vacancy behind it that fluid rushes to fill (sink). These source dipoles:\n\nDecay rapidly with distance as \\(1/r^3\\)\nAre responsible for the actual propulsion of the swimmer\nArise from the swimmer’s shape changes and boundary motion\n\nForce dipoles: These represent the balance of thrust and drag forces that the swimmer exerts on the fluid. Since microswimmers are force-free (no external forces act on them), the thrust forces must be balanced by drag forces, creating a dipole. These force dipoles:\n\nDecay more slowly with distance as \\(1/r^2\\)\nDo not contribute to the swimmer’s self-propulsion\nDominate the long-range hydrodynamic interactions\nClassify swimmers as “pushers” or “pullers” based on their swimming mechanism\n\n\nThis distinction is crucial: while source dipoles enable swimming, it’s the force dipoles that mediate most of the interesting long-range interactions between microswimmers."
  },
  {
    "objectID": "lecture03/hydrodynamics.html#hydrodynamic-interactions",
    "href": "lecture03/hydrodynamics.html#hydrodynamic-interactions",
    "title": "Active Matter Physics",
    "section": "Hydrodynamic Interactions",
    "text": "Hydrodynamic Interactions\nMicroswimmers not only propel themselves through fluid but also generate these long-range fluid flows that affect the motion of nearby objects and other swimmers. These hydrodynamic interactions play a crucial role in the collective behavior of active matter.\n\nThe Stokes Equation and Green’s Function\nThe flow field generated by a point force (Stokeslet) in an unbounded fluid is described by the Green’s function of the Stokes equation:\n\\[\\mathbf{v}(\\mathbf{r}) = \\frac{1}{8\\pi\\eta}\\left(\\frac{\\mathbf{f}}{r} + \\frac{(\\mathbf{f} \\cdot \\mathbf{r})\\mathbf{r}}{r^3}\\right)\\]\nwhere \\(\\mathbf{f}\\) is the point force and \\(\\mathbf{r}\\) is the position relative to the force application point.\nThis fundamental solution decays as \\(1/r\\), making hydrodynamic interactions long-ranged. This contrasts with equilibrium systems where interactions typically decay exponentially or as power laws with higher exponents.\n\n\nMultipole Expansion\nThe flow field generated by a microswimmer can be described using a multipole expansion:\n\\[\\mathbf{v}(\\mathbf{r}) = \\mathbf{G}(\\mathbf{r}) \\cdot \\mathbf{F} + \\nabla \\cdot [\\mathbf{G}(\\mathbf{r}) \\cdot \\mathbf{D}] + \\ldots\\]\nwhere \\(\\mathbf{G}(\\mathbf{r})\\) is the Oseen tensor (the Green’s function), \\(\\mathbf{F}\\) is the monopole moment (net force, which vanishes for a force-free swimmer), \\(\\mathbf{D}\\) is the dipole moment, and higher-order terms are neglected.\nFor a force-free swimmer, the leading contribution comes from the force dipole, which decays as \\(1/r^2\\). The symmetry of the dipole classifies swimmers into:\n\nPushers: Organisms that generate thrust behind their body, like most bacteria. Their dipole moment is negative.\nPullers: Organisms that generate thrust in front of their body, like Chlamydomonas (discussed in Lecture 2). Their dipole moment is positive.\n\n\n\nHydrodynamic Mobility\nThe hydrodynamic mobility tensor \\(\\mathbf{M}\\) relates the velocity of a particle to the forces acting on it:\n\\[\\mathbf{v}_i = \\sum_j \\mathbf{M}_{ij} \\cdot \\mathbf{F}_j\\]\nFor two spherical particles of radius \\(a\\) in an unbounded fluid, the mobility tensor has the form:\n\\[\\mathbf{M}_{ii} = \\frac{1}{6\\pi\\eta a}\\mathbf{I}\\]\n\\[\\mathbf{M}_{ij} = \\frac{1}{8\\pi\\eta r_{ij}}\\left(\\mathbf{I} + \\frac{\\mathbf{r}_{ij}\\mathbf{r}_{ij}}{r_{ij}^2}\\right) \\quad (i \\neq j)\\]\nwhere \\(\\mathbf{r}_{ij}\\) is the vector from particle \\(j\\) to particle \\(i\\).\nSimilar to how temperature couples fluctuations and dissipation in equilibrium systems (as we saw with the FDT in Lecture 2), the mobility tensor in hydrodynamics connects the deterministic response to forces and the correlations in thermal fluctuations:\n\\[\\langle \\boldsymbol{\\xi}_i(t) \\boldsymbol{\\xi}_j(t') \\rangle = 2k_B T \\mathbf{M}_{ij} \\delta(t-t')\\]\nFor active particles, this equilibrium relation is violated, providing another manifestation of the non-equilibrium nature of active matter."
  },
  {
    "objectID": "lecture03/hydrodynamics.html#microswimmer-force-dipoles",
    "href": "lecture03/hydrodynamics.html#microswimmer-force-dipoles",
    "title": "Active Matter Physics",
    "section": "Microswimmer Force Dipoles",
    "text": "Microswimmer Force Dipoles\nBuilding on the hydrodynamic framework, let’s examine more closely how microswimmers generate and are affected by force dipole fields. This fundamental characteristic shapes their interactions and collective behavior.\n\nForce Dipole Characterization\nThe force dipole moment of a swimmer can be written as:\n\\[\\mathbf{D} = \\int (\\mathbf{r} - \\mathbf{r}_0) \\otimes \\mathbf{f}(\\mathbf{r}) d\\mathbf{r}\\]\nwhere \\(\\mathbf{r}_0\\) is the swimmer’s center, \\(\\mathbf{f}(\\mathbf{r})\\) is the force density exerted by the swimmer on the fluid, and \\(\\otimes\\) denotes the tensor product.\nFor a simple model of a swimmer with thrust force \\(F\\) separated by distance \\(l\\) from a balancing drag force, the dipole strength is \\(p = Fl\\), with \\(p &lt; 0\\) for pushers and \\(p &gt; 0\\) for pullers.\n\n\nFar-Field Flow Velocity\nThe far-field flow velocity generated by a force dipole aligned with the z-axis is:\n\\[\\mathbf{v}(\\mathbf{r}) = \\frac{p}{8\\pi\\eta r^3}(3\\cos^2\\theta - 1)\\mathbf{r}\\]\nwhere \\(\\theta\\) is the angle between \\(\\mathbf{r}\\) and the dipole axis.\nThis flow field has regions of outward flow and inward flow, creating characteristic “pusher” or “puller” signatures that can be visualized experimentally and detected by neighboring particles.\n\n\nInduced Interactions\nThe dipolar flow fields generate effective interactions between swimmers and with boundaries. The interaction energy between two force dipoles separated by distance \\(r\\) with orientations \\(\\mathbf{p}_1\\) and \\(\\mathbf{p}_2\\) scales as:\n\\[E_{\\text{int}} \\sim \\frac{p_1 p_2}{r^3}(3(\\hat{\\mathbf{p}}_1 \\cdot \\hat{\\mathbf{r}})(\\hat{\\mathbf{p}}_2 \\cdot \\hat{\\mathbf{r}}) - \\hat{\\mathbf{p}}_1 \\cdot \\hat{\\mathbf{p}}_2)\\]\nThis leads to orientation-dependent attractions and repulsions between swimmers, driving complex collective behaviors:\n\nPusher-pusher interactions: Tend to align swimmers parallel when side-by-side and perpendicular when one is behind the other.\nPuller-puller interactions: Tend to align swimmers perpendicular when side-by-side and parallel when one is behind the other.\nMixed interactions: Create complex alignment patterns depending on relative positions.\n\n\n\nBoundary Effects\nThe presence of boundaries significantly alters the hydrodynamic interactions. Near a no-slip wall, the force dipole interaction is modified by image singularities, leading to phenomena such as:\n\nSurface accumulation: Microswimmers tend to accumulate near surfaces, with different mechanisms for pushers and pullers.\nCircular motion: Pushers and pullers display circular trajectories near boundaries with opposite handedness.\nHydrodynamic capture: Certain configurations of surface curvature can trap swimmers for extended periods.\n\nThese boundary effects have no analogs in equilibrium systems and represent another manifestation of the active, non-equilibrium nature of microswimmers.\n\n\nExperimental Techniques\nExperimentally, force dipoles can be characterized through:\n\nParticle Image Velocimetry (PIV): Measures flow fields around swimming microorganisms, revealing their dipolar nature.\nTracer particle dynamics: The motion of passive tracers in the vicinity of a swimmer follows the dipolar flow fields.\nOptical tweezers: Can directly measure the forces exerted by microswimmers.\n\nThese techniques provide direct evidence for the non-equilibrium nature of microswimmer-generated flows, connecting to the broader theme of detailed balance violation that we discussed in Lecture 2 for flagellar beating patterns."
  },
  {
    "objectID": "lecture03/lecture03.html",
    "href": "lecture03/lecture03.html",
    "title": "Microscopic Models of Self-propulsion",
    "section": "",
    "text": "In the previous lecture, we explored the fundamental concepts of equilibrium statistical mechanics and how active biological systems violate these principles. We examined detailed balance and the fluctuation-dissipation theorem (FDT), discovering that active systems consistently break these equilibrium constraints.\nOne of the key examples we studied was sedimentation, where colloidal particles in thermal equilibrium form an exponential density profile according to the Boltzmann distribution:\n\\[n(h) = n_0 e^{-\\frac{mgh}{k_B T}}\\]\nThis distribution arises directly from equilibrium statistical mechanics and represents a balance between gravitational forces and thermal fluctuations.\nBut what happens when particles are active - consuming energy to propel themselves? This lecture begins by exploring one of the simplest active matter models: the run-and-tumble particle (RTP). We’ll first examine this model in 1D with sedimentation to directly contrast with our equilibrium example from lecture 2, demonstrating how active particles violate equilibrium principles even in this simplified scenario.\nFrom there, we’ll extend to more sophisticated microscopic models that can capture the essential features of self-propelled particles in three dimensions:\n\nRun-and-Tumble Particles (RTPs) - inspired by bacterial motion patterns like E. coli\nActive Brownian Particles (ABPs) - which combine random diffusion with persistent self-propulsion\nSwimming at Low Reynolds Number - examining the physics that governs locomotion at the microscale\nHydrodynamic Interactions - understanding how active particles influence their surroundings and each other\nMicroswimmer Force Dipoles - characterizing the flow fields generated by different types of swimmers\n\nThese models will provide us with the tools to analyze collective behaviors, pattern formation, and non-equilibrium dynamics in active biological systems.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 3"
    ]
  },
  {
    "objectID": "lecture03/lecture03.html#introduction-from-equilibrium-violations-to-microscopic-models",
    "href": "lecture03/lecture03.html#introduction-from-equilibrium-violations-to-microscopic-models",
    "title": "Microscopic Models of Self-propulsion",
    "section": "",
    "text": "In the previous lecture, we explored the fundamental concepts of equilibrium statistical mechanics and how active biological systems violate these principles. We examined detailed balance and the fluctuation-dissipation theorem (FDT), discovering that active systems consistently break these equilibrium constraints.\nOne of the key examples we studied was sedimentation, where colloidal particles in thermal equilibrium form an exponential density profile according to the Boltzmann distribution:\n\\[n(h) = n_0 e^{-\\frac{mgh}{k_B T}}\\]\nThis distribution arises directly from equilibrium statistical mechanics and represents a balance between gravitational forces and thermal fluctuations.\nBut what happens when particles are active - consuming energy to propel themselves? This lecture begins by exploring one of the simplest active matter models: the run-and-tumble particle (RTP). We’ll first examine this model in 1D with sedimentation to directly contrast with our equilibrium example from lecture 2, demonstrating how active particles violate equilibrium principles even in this simplified scenario.\nFrom there, we’ll extend to more sophisticated microscopic models that can capture the essential features of self-propelled particles in three dimensions:\n\nRun-and-Tumble Particles (RTPs) - inspired by bacterial motion patterns like E. coli\nActive Brownian Particles (ABPs) - which combine random diffusion with persistent self-propulsion\nSwimming at Low Reynolds Number - examining the physics that governs locomotion at the microscale\nHydrodynamic Interactions - understanding how active particles influence their surroundings and each other\nMicroswimmer Force Dipoles - characterizing the flow fields generated by different types of swimmers\n\nThese models will provide us with the tools to analyze collective behaviors, pattern formation, and non-equilibrium dynamics in active biological systems.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 3"
    ]
  },
  {
    "objectID": "lecture03/lecture03.html#run-and-tumble-particles-rtps",
    "href": "lecture03/lecture03.html#run-and-tumble-particles-rtps",
    "title": "Microscopic Models of Self-propulsion",
    "section": "Run-and-Tumble Particles (RTPs)",
    "text": "Run-and-Tumble Particles (RTPs)\nRun-and-tumble dynamics represent an important class of active motion, inspired by the swimming behavior of bacteria like E. coli. Unlike passive Brownian motion, run-and-tumble particles alternate between straight-line “runs” and random reorientation “tumbles.”\n\n\n\nVideo\n\n\nFigure 1— Run-and-reverse motion of Pseudomonas Taiwanensis bacteria (move by Desmond Quinn, MONA group).\n\n\n\nThis run-and-tumble motion, which comes in different flavors (e.g. a run-and revserse motion as displayed in the movie above) has even some functionality. It allows bacteria to move in gradients of chemical species concentrations without measuring even the gradient directly.\n\n1D Run-and-Tumble with Sedimentation\nWe can make a simple model for this run-and-tumble motion in one dimension. Let’s start with the master equations for the probabilities \\(P_+(x,t)\\) and \\(P_-(x,t)\\) of finding a particle at position \\(x\\) moving in the positive or negative direction, respectively. In the simplest case without gravity or diffusion:\n\\[\\frac{\\partial P_+}{\\partial t} = -\\frac{\\partial}{\\partial x}(v_0(x)P_+) - \\lambda P_+ + \\lambda P_-\\]\n\\[\\frac{\\partial P_-}{\\partial t} = \\frac{\\partial}{\\partial x}(v_0(x)P_-) + \\lambda P_+ - \\lambda P_-\\]\nThese equations describe how probabilities change due to advection at position-dependent speed \\(v_0(x)\\) and flipping of the swimming direction with rate \\(\\lambda\\).\nWe can rewrite these equations in terms of the total probability density \\(P(x,t) = P_+(x,t) + P_-(x,t)\\) and the polarization \\(\\sigma(x,t) = P_+(x,t) - P_-(x,t)\\). After adding and subtracting the equations:\n\\[\\frac{\\partial P}{\\partial t} = -\\frac{\\partial}{\\partial x}(v_0(x)\\sigma)\\]\n\\[\\frac{\\partial \\sigma}{\\partial t} = -\\frac{\\partial}{\\partial x}(v_0(x)P) - 2\\lambda \\sigma\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nFrom the first equation, we can identify the probability current as \\(J(x,t) = v_0(x) \\sigma(x,t)\\). In the steady state, \\(\\frac{\\partial \\sigma}{\\partial t} = 0\\), which gives:\n\\[\\frac{\\partial}{\\partial x}(v_0(x)P) = -2\\lambda \\sigma\\]\n\\[v_0(x)\\frac{\\partial P}{\\partial x} + P\\frac{dv_0(x)}{dx} = -2\\lambda \\sigma\\]\nSolving for \\(\\sigma\\):\n\\[\\sigma(x) = -\\frac{v_0(x)}{2\\lambda}\\frac{\\partial P}{\\partial x} - \\frac{P}{2\\lambda}\\frac{dv_0(x)}{dx}\\]\n\n\n\nThis then yields the current:\n\\[J(x) = v_0(x) \\sigma(x) = -\\frac{v_0^2(x)}{2\\lambda}\\frac{\\partial P}{\\partial x} - \\frac{v_0(x)P}{2\\lambda}\\frac{dv_0(x)}{dx}\\]\nThis has the form of a drift-diffusion current \\(J = -D_{\\text{eff}}\\frac{\\partial P}{\\partial x} + V_{\\text{eff}}P\\) with a position-dependent effective diffusion coefficient \\(D_{\\text{eff}}(x) = \\frac{v_0^2(x)}{2\\lambda}\\) and an effective drift velocity \\(V_{\\text{eff}}(x) = -\\frac{v_0(x)}{2\\lambda}\\frac{dv_0(x)}{dx}\\).\n\nDensity Distributions in Different Regimes\nOne can find out now the steady state distribution of run-and-tumble swimmers for different cases. Two interesting ones are:\n\nPosition-dependent tumble rate, constant speed: When the speed \\(v_0\\) is constant but the tumble rate \\(\\lambda(x)\\) varies with position, the steady-state current is:\n\n\\[J(x) = -\\frac{v_0^2}{2\\lambda(x)}\\frac{\\partial P}{\\partial x}\\]\nSetting J(x) = 0 for the steady state yields:\n\\[\\frac{\\partial P}{\\partial x} = 0\\]\nThis gives a uniform density distribution:\n\\[P(x) = \\text{constant}\\]\nInterestingly, spatial variation in tumble rate alone (\\(\\lambda(x)\\)) cannot create population gradients when the swimming speed is constant. However, in bacterial chemotaxis, the tumble rate depends not just on position but also on the bacterium’s orientation relative to the chemical gradient: \\(\\lambda(\\mathbf{r}, \\mathbf{n}) = \\lambda_0(1 - \\mathbf{n} \\cdot \\nabla c(\\mathbf{r})/|\\nabla c(\\mathbf{r})|)\\). This directional dependence allows bacteria to effectively navigate chemical landscapes, creating population gradients despite constant swimming speed. (see for example 1)\n\n\n\n\n\n\nChemotaxis\n\n\n\nChemotaxis is the directed movement of organisms in response to chemical gradients in their environment. This behavior allows cells to move toward favorable chemical conditions (positive chemotaxis) or away from harmful ones (negative chemotaxis). In bacteria like E. coli, chemotaxis works through a biased random walk: rather than directly sensing gradient directions, bacteria adjust their tumbling frequency based on whether they’re moving toward or away from attractive chemicals. This elegant mechanism enables even simple single-celled organisms to effectively navigate complex chemical landscapes without sophisticated sensory apparatus.\n\n\n\nPosition-dependent speed, constant tumble rate: When the swimming speed depends on position \\(v_0(x)\\) while the tumble rate \\(\\lambda\\) remains constant, we can find the steady-state density distribution by setting \\(J(x) = 0\\) (no flux condition) and solving:\n\n\\[-\\frac{v_0^2(x)}{2\\lambda}\\frac{\\partial P}{\\partial x} - \\frac{v_0(x)P}{2\\lambda}\\frac{dv_0(x)}{dx} = 0\\]\nThis simplifies to:\n\\[\\frac{\\partial P}{\\partial x} = -\\frac{1}{v_0(x)}\\frac{dv_0(x)}{dx}P\\]\nThe solution gives the steady-state density distribution:\n\\[P(x) \\propto \\frac{1}{v_0(x)}\\]\nThis reveals that bacteria naturally accumulate in regions of lower swimming speed. Looking at the effective drift velocity \\(V_{\\text{eff}}(x) = -\\frac{v_0(x)}{2\\lambda}\\frac{dv_0(x)}{dx} = -\\frac{1}{4\\lambda}\\frac{d(v_0^2(x))}{dx}\\), we see bacteria will move toward regions where swimming speed decreases. This provides a mechanism for chemotaxis without directly modulating the tumbling rate. In fact this overwrites the detailed balance equation we obtained earlier for equilibrium.\n\n\nSedimentation of Run-and-tumeble particles\nWith a little bit of effort, one can modify this simple model to include an additional sedimentation drift velocity which is given by \\(mg/\\gamma\\), where \\(\\gamma\\) is the friction coefficient. Including further thermal diffusion yields:\n\\[\\frac{\\partial P_+}{\\partial t} = -\\frac{\\partial}{\\partial x}\\left[(v_0(x)-\\frac{mg}{\\gamma})P_+\\right] - \\lambda P_+ + \\lambda P_- + D\\frac{\\partial^2 P_+}{\\partial x^2}\\]\n\\[\\frac{\\partial P_-}{\\partial t} = -\\frac{\\partial}{\\partial x}\\left[(-v_0(x)-\\frac{mg}{\\gamma})P_-\\right] + \\lambda P_+ - \\lambda P_- + D\\frac{\\partial^2 P_-}{\\partial x^2}\\]\nIn the steady state, when thermal diffusion is small (\\(D \\approx 0\\)), we obtain:\n\\[P(x) = P_+(x) + P_-(x) \\propto e^{-\\frac{x}{\\delta}}\\]\nwhere \\(\\delta\\) is the sedimentation length\n\\[\\delta = \\frac{v_0^2-(mg/\\gamma)^2}{2\\lambda mg/\\gamma}\\]\nThis is strikingly different from the equilibrium result! When sedimentation speed and active particle speed are comparable the sedimentation length is zero. The bacteria would completely collapse to a layer on the surface.\nIf the speed is now bigger than the sedimentation speed, the sedimentation length becomes positive.\nSince the sedimentation length in equilibrium is\n\\[\\delta = \\frac{k_B T}{mg}\\]\nit is tempting to say that\n\\[\\frac{k_B T_\\mathrm{eff}}{mg}=\\frac{v_0^2-(mg/\\gamma)^2}{2\\lambda mg/\\gamma}\\]\nwhich yields an effective temperature\n\\[T_\\mathrm{eff} = \\frac{v_0^2-(mg/\\gamma)^2}{2\\lambda k_B}\\]\nwhich is not the temperature of the surrounding medium. This effective temperature accounts for the active motion of the particle and its interaction with the surrounding medium.\n\n\nCode\n# Parameters\nx = np.linspace(0, 10, 1000)  # height above surface\nv_sed = 1                    # sedimentation velocity mg/γ\nlambda_tumble = 0.6            # tumble rate\n\n# Three different active velocities\nv0_values = [1.01, 2, 3]       # self-propulsion speeds\n\n# Calculate density profiles\nplt.figure(figsize=get_size(10, 8))\n\nfor v0 in v0_values:\n    # Calculate sedimentation length\n    delta = (v0**2 - v_sed**2) / (2 * lambda_tumble * v_sed)\n\n    density = np.exp(-x / delta)\n\n    density = density / density[0]\n\n    plt.plot(x, density, '-', linewidth=1, label=f'$v_0 = {v0}$')\n\nplt.xlabel('height $z$')\nplt.ylabel('$P(x)/P(0)$')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2— Sedimentation profiles for three different activity levels. As the speed \\(v_0\\) increases relative to the sedimentation velocity \\(mg/γ=1\\), the density profile extends further from the bottom surface.\n\n\n\n\n\n\n\n\nMathematical Formulation in Higher Dimensions\nExtending to higher dimensions, the equations of motion for a run-and-tumble particle can be written as:\n\\[\\frac{d\\mathbf{r}}{dt} = v_0 \\mathbf{n}(t) - \\frac{1}{\\gamma}\\nabla U(\\mathbf{r}) + \\boldsymbol{\\xi}(t)/\\gamma\\]\nwhere \\(\\mathbf{n}(t)\\) represents the orientation vector that changes discontinuously according to a Poisson process. This stochastic process models tumbling events as memory-less, random occurrences with the fundamental property:\n\\[P(\\text{tumble in interval } [t, t+dt]) = \\lambda \\, dt + o(dt)\\]\nwhere \\(\\lambda\\) is the tumbling rate and \\(o(dt)\\) represents higher-order terms that become negligible for small \\(dt\\). This formulation has several important implications:\n\nThe probability of a tumble occurring in any small time interval \\(dt\\) is proportional to the length of that interval, with \\(\\lambda\\) being the proportionality constant.\nTumbling events are statistically independent - the probability of a tumble occurring is unaffected by when the previous tumble occurred, giving the process its “memory-less” property.\nThe waiting times between consecutive tumbles follow an exponential distribution with mean \\(1/\\lambda\\): \\[P(\\text{time between tumbles} &gt; \\tau) = e^{-\\lambda\\tau}\\]\nThe number of tumbles \\(N(t)\\) occurring within a time interval \\([0, t]\\) follows a Poisson distribution: \\[P(N(t) = k) = \\frac{(\\lambda t)^k e^{-\\lambda t}}{k!}\\]\n\nA critical aspect of the run-and-tumble model is how the new orientation is determined after each tumbling event. In the standard model, the new orientation vector \\(\\mathbf{n}(t^+)\\) immediately after a tumble at time \\(t\\) is chosen from a uniform probability distribution on the unit circle (in 2D) or sphere (in 3D), completely independent of the previous orientation \\(\\mathbf{n}(t^-)\\). This means:\n\nIn 2D: The new angle \\(\\theta_{new}\\) is drawn uniformly from \\([0, 2\\pi)\\)\nIn 3D: The new direction is uniformly distributed on the unit sphere, typically generated by choosing \\(\\phi\\) uniformly from \\([0, 2\\pi)\\) and \\(\\cos\\theta\\) uniformly from \\([-1, 1]\\)\n\nThis uniform reorientation distribution is a key feature that distinguishes run-and-tumble motion from other active particle models. For some biological swimmers, variations of this distribution may be more appropriate - for example, some bacteria exhibit a “persistence” in their tumbling, where the new direction maintains some correlation with the previous direction. Other organisms might show “run-and-reverse” behavior, where the new orientation is preferentially opposite to the previous one. These variations can be modeled by modifying the reorientation distribution accordingly.\n\n\nCode\n# Parameters for run-and-tumble motion\nv0 = 1.0            # speed (constant)\nlambda_tumble = 0.4  # tumble rate\ntotal_time = 50      # total simulation time\ndt = 0.1            # time step\n\n# Function to generate a single run-and-tumble trajectory\ndef simulate_run_tumble_2d(v0, lambda_tumble, total_time, dt, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Number of time steps\n    n_steps = int(total_time / dt)\n\n    # Initialize arrays for position and orientation\n    x = np.zeros(n_steps)\n    y = np.zeros(n_steps)\n    theta = np.zeros(n_steps)\n\n    # Set random initial orientation\n    theta[0] = 2 * np.pi * np.random.random()\n\n    # Simulate run-and-tumble motion\n    for i in range(1, n_steps):\n        # Check if tumble occurs (Poisson process)\n        if np.random.random() &lt; lambda_tumble * dt:\n            # New random orientation\n            theta[i] = 2 * np.pi * np.random.random()\n        else:\n            # Keep same orientation\n            theta[i] = theta[i-1]\n\n        # Update position\n        x[i] = x[i-1] + v0 * np.cos(theta[i]) * dt\n        y[i] = y[i-1] + v0 * np.sin(theta[i]) * dt\n\n    return x, y\n\n# Create figure\nplt.figure(figsize=get_size(10, 10))\n\n# Generate and plot 10 trajectories\nfor i in range(10):\n    x, y = simulate_run_tumble_2d(v0, lambda_tumble, total_time, dt, seed=i)\n    plt.plot(x, y, '-', linewidth=1, alpha=0.7)\n\n# Add marker for starting point\nplt.scatter(0, 0, color='red', s=50)\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.axis('equal')\nplt.grid(True, linestyle='--', alpha=0.3)\nplt.xlim(-15, 15)\nplt.ylim(-15, 15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3— Ten trajectories of run-and-tumble particles in 2D, each starting from the origin. The particles move with constant speed v₀ = 1 and randomly change direction according to a Poisson process with rate λ = 0.1.\n\n\n\n\n\n\n\nConnection to ABPs\nInterestingly, in the limit of long observation times, the large-scale dynamics of RTPs become equivalent to those of ABPs. The effective rotational diffusion coefficient for RTPs is:\n\\[D_r^{\\text{eff}} = \\frac{\\lambda}{d-1}\\]\nwhere \\(d\\) is the dimensionality. This equivalence suggests that these seemingly different microscopic mechanisms can lead to similar macroscopic behaviors.\n\n\nNon-equilibrium Aspects\nRTP models demonstrate several non-equilibrium features beyond the effective temperature we observed in sedimentation:\n\nThe steady-state cannot be written as a Boltzmann distribution\nProbability currents exist even in steady state\nThe fluctuation-dissipation theorem is violated\n\nThese features arise from the persistent energy consumption required to maintain the run-and-tumble motion.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 3"
    ]
  },
  {
    "objectID": "lecture03/lecture03.html#active-brownian-particles-abps",
    "href": "lecture03/lecture03.html#active-brownian-particles-abps",
    "title": "Microscopic Models of Self-propulsion",
    "section": "Active Brownian Particles (ABPs)",
    "text": "Active Brownian Particles (ABPs)\nAfter examining Run-and-Tumble Particles, we now turn to Active Brownian Particles (ABPs), which represent another fundamental model of self-propelled agents. Like RTPs, ABPs extend the equilibrium Brownian motion framework we discussed in Lecture 2, but they do so through continuous rotational diffusion rather than discrete tumbling events. This alternative self-propulsion mechanism similarly drives the system out of equilibrium.\n\n\n\nVideo\n\n\nFigure 4— Janus particles performing active Brownian motion. These synthetic microswimmers have two distinct faces with different chemical or physical properties, causing them to self-propel through an asymmetric interaction with their environment while undergoing rotational diffusion. The movie contains not only ABP motion but some additional driving force. (Movie by Lisa Rohde, MONA group.)\n\n\n\n\nMathematical Formulation\nTo understand Active Brownian Particles, we should start from the general underdamped Langevin equation for Brownian motion:\n\\[m\\frac{d^2\\mathbf{r}}{dt^2} = \\underbrace{-\\gamma\\frac{d\\mathbf{r}}{dt}}_{\\text{sink}} - \\nabla U(\\mathbf{r}) + \\underbrace{\\boldsymbol{\\xi}(t)}_{\\text{source}}\\]\nHere, \\(\\mathbf{r}=(x,y)\\) is the particle position, \\(m\\) is the particle mass, and the left side represents inertial forces. On the right side we have a dissipative friction term with coefficient \\(\\gamma\\) that removes energy from the system, a conservative force from the potential \\(U(\\mathbf{r})\\), and a thermal noise term \\(\\boldsymbol{\\xi}(t)\\) that injects energy into the particle motion. The thermal translational noise \\(\\boldsymbol{\\xi}(t)\\) has zero mean (\\(\\langle\\boldsymbol{\\xi}(t)\\rangle = 0\\)) and correlations \\(\\langle\\xi_i(t)\\xi_j(t')\\rangle = 2\\gamma k_B T \\delta_{ij}\\delta(t-t')\\), following the fluctuation-dissipation theorem.\nThe energy dissipation rate due to friction is given by \\(P_{diss} = \\gamma|\\mathbf{v}|^2\\), where \\(\\mathbf{v}=\\frac{d\\mathbf{r}}{dt}\\) is the particle velocity. In equilibrium, the average energy dissipation rate per degree of freedom is \\(\\langle P_{diss} \\rangle = \\frac{2\\gamma k_B T}{m}\\). Meanwhile, the energy injection rate from thermal fluctuations can be calculated from the work done by the random force: \\(P_{inj} = \\boldsymbol{\\xi}(t) \\cdot \\mathbf{v}\\).\nTo determine the average injected power, we need to evaluate \\(\\langle \\boldsymbol{\\xi}(t) \\cdot \\mathbf{v} \\rangle\\). This requires examining the correlation between the noise and velocity, which isn’t immediately obvious since both are stochastic quantities. We can solve this by considering the Langevin equation in the stationary state. From the equipartition theorem, we know that \\(\\langle mv^2 \\rangle = k_B T\\) per degree of freedom, which means \\(\\langle v^2 \\rangle = \\frac{k_B T}{m}\\).\nThe instantaneous velocity can be formally expressed using the Green’s function solution of the Langevin equation:\n\\[\\mathbf{v}(t) = \\frac{1}{\\gamma}\\int_{-\\infty}^{t} \\boldsymbol{\\xi}(t') e^{-(t-t')/\\tau_p} dt'\\]\nwhere \\(\\tau_p = m/\\gamma\\) is the momentum relaxation time. Using this expression and the noise correlation function \\(\\langle \\xi_i(t) \\xi_j(t') \\rangle = 2\\gamma k_B T \\delta_{ij}\\delta(t-t')\\), we can calculate:\n\\[\\begin{eqnarray}\n\\langle \\boldsymbol{\\xi}(t) \\cdot \\mathbf{v}(t) \\rangle &= \\frac{1}{\\gamma}\\sum_i\\int_{-\\infty}^{t} \\langle \\xi_i(t)\\xi_i(t') \\rangle e^{-(t-t')/\\tau_p} dt' \\\\\n&= \\frac{2\\gamma k_B T}{\\gamma} \\int_{-\\infty}^{t} \\delta(t-t') e^{-(t-t')/\\tau_p} dt' = \\frac{2\\gamma k_B T}{m} \\tau_p = \\frac{2\\gamma k_B T}{m}\n\\end{eqnarray}\\]\nThus, the average energy injection rate per degree of freedom is \\(\\langle P_{inj} \\rangle = \\frac{2\\gamma k_B T}{m}\\). The equality between injection and dissipation rates ensures detailed balance in equilibrium systems, maintaining a consistent average kinetic energy of \\(\\frac{k_B T}{2}\\) per degree of freedom in accordance with the equipartition theorem.\nFor microscopic particles in a viscous medium, the inertial term becomes negligible (mass effects disappear on timescales \\(t \\gg m/\\gamma\\)), leading to the overdamped limit.\nIn an ABP, we add a non-equilibrium self-propulsion force, resulting in these overdamped Langevin equations:\n\\[\\gamma\\frac{d\\mathbf{r}}{dt} = \\gamma v_0 \\mathbf{n}(t) - \\nabla U(\\mathbf{r}) + \\boldsymbol{\\xi}(t)\\]\n\\[\\frac{d\\theta}{dt} = \\eta(t)\\]\nThe first equation describes the particle’s translational motion, where \\(v_0\\) is the self-propulsion speed and \\(\\mathbf{n}(t) = (\\cos\\theta(t), \\sin\\theta(t))\\) is a unit vector pointing in the direction of self-propulsion.\nThe second equation governs the particle’s orientation \\(\\theta\\), which evolves through rotational diffusion. The rotational noise \\(\\eta(t)\\) has zero mean (\\(\\langle\\eta(t)\\rangle = 0\\)) and correlations \\(\\langle\\eta(t)\\eta(t')\\rangle = 2D_r\\delta(t-t')\\), where \\(D_r\\) is the rotational diffusion coefficient.\nUnlike passive Brownian motion discussed in Lecture 2, ABPs fundamentally violate detailed balance due to the persistent self-propulsion term, which acts as an additional energy source driving the system out of equilibrium. The particle moves with a characteristic persistence time \\(\\tau_r = 1/D_r\\) before its direction is randomized by rotational diffusion.\n\n\nMean Displacement\nIf we consider an active Brownian particle in two dimension starting at the origin (x=0, y=0) with an initial orientation θ=0 (pointing along the positive x-axis), the mean displacement shows interesting directional behavior:\n\\[\\langle x(t) \\rangle = \\frac{v_0}{D_r}(1-e^{-D_r t})\\]\n\\[\\langle y(t) \\rangle = 0\\]\nThe mean displacement in the y-direction averages to zero due to the symmetry of rotational diffusion. The x-component shows an initial ballistic growth that saturates at the persistence length scale \\(l_p=v_0/D_r\\) for times much larger than the rotational diffusion time \\(\\tau_r=1/D_r\\). This persistence length represents the typical distance traveled before the particle’s direction is randomized.\nUnlike equilibrium Brownian motion where the mean displacement is zero in all directions, the ABP’s mean displacement reflects the persistence of its self-propulsion. As \\(t \\to \\infty\\), the orientation becomes fully randomized, and any further displacement averages to zero, resulting in the saturation of the mean displacement to a finite value.\n\n\n\n\n\n\n\n\nFigure 5— Trajectories of a particle (R=1 µm) starting at the origin with an initial orientation \\(\\theta=0\\). Left: passive Brownian particle (\\(v=0\\) µm/s). Right: Active Brownian Particle (\\(v=10\\) µm/s). (\\(\\tau_r=6 s\\).)\n\n\n\n\n\n\n\nMean Square Displacement\nThe mean square displacement (MSD) of an ABP reveals a rich multi-regime behavior that can be analyzed from the full expression:\n\\[\\langle|\\mathbf{r}(t) - \\mathbf{r}(0)|^2\\rangle = 4D_t t + \\frac{2v_0^2}{D_r^2}(D_r t - 1 + e^{-D_r t})\\]\nwhere \\(D_t = k_BT/\\gamma\\) is the thermal translational diffusion coefficient.\nWe can identify three distinct regimes by examining the limiting behavior at different timescales:\n\nVery short times (\\(t \\ll\\tau_r\\), where \\(\\tau_r = 1/D_r\\) is the rotational diffusion time):\n\nBy expanding the exponential term \\(e^{-D_r t} \\approx 1 - D_r t + \\frac{(D_r t)^2}{2} - ...\\), we obtain:\n\\[\\langle|\\mathbf{r}(t) - \\mathbf{r}(0)|^2\\rangle \\approx 4D_t t + v_0^2 t^2 + ...\\]\nThis reveals a combination of diffusive behavior (\\(\\sim t\\)) from thermal fluctuations and the beginning of ballistic motion (\\(\\sim t^2\\)) from persistent self-propulsion.\n\nIntermediate times (\\(\\tau_t \\ll t \\ll \\tau_r\\)):\n\nThe ballistic term dominates and the MSD scales approximately as:\n\\[\\langle|\\mathbf{r}(t) - \\mathbf{r}(0)|^2\\rangle \\approx v_0^2 t^2\\]\nThis quadratic scaling reflects the persistent directed motion before rotational diffusion randomizes the swimming direction.\n\nLong times (\\(t \\gg \\tau_r\\)):\n\nWhen \\(t \\gg 1/D_r\\), \\(e^{-D_r t} \\approx 0\\), and the MSD becomes:\n\\[\\langle|\\mathbf{r}(t) - \\mathbf{r}(0)|^2\\rangle \\approx 4D_t t + \\frac{2v_0^2}{D_r}t - \\frac{2v_0^2}{D_r^2}\\]\nFor sufficiently long times, the constant term becomes negligible, resulting in diffusive motion with an enhanced effective diffusion coefficient:\n\\[D_{\\text{eff}} = D_t + \\frac{v_0^2}{2dD_r}\\]\nwhere \\(d\\) is the dimensionality. This enhanced diffusion coefficient represents a key signature of the system’s non-equilibrium nature and cannot be explained by equilibrium statistical mechanics.\n\n\nCode\n# Parameters\nD_t = 1.0      # thermal translational diffusion coefficient\nv_0 = 5.0      # self-propulsion speed\nD_r = 0.2      # rotational diffusion coefficient\ntau_r = 1/D_r  # rotational diffusion time\n\n# Calculate theoretical MSD\ndef msd_theory(t, D_t, v_0, D_r):\n    \"\"\"Theoretical mean square displacement for active Brownian particles\"\"\"\n    return 4*D_t*t + (2*v_0**2)/(D_r**2)*(D_r*t - 1 + np.exp(-D_r*t))\n\n# Time range spanning multiple regimes\nt = np.logspace(-2, 2, 1000)  # from 0.01 to 100\nmsd = msd_theory(t, D_t, v_0, D_r)\n\n# Calculate effective diffusion coefficient\nD_eff = D_t + v_0**2/(2*D_r)\n\n# Create figure\nplt.figure(figsize=get_size(10, 8))\n\n# Plot MSD on log-log scale\nplt.loglog(t, msd, 'b-', linewidth=2, label='MSD of ABP')\n\n# Add reference lines for different scaling regimes\nt_ref = np.array([0.05, 50])\nplt.loglog(t_ref, 4*D_t*t_ref, 'k--', label=r'$\\sim 4D_t t$ (thermal diffusion)')\nplt.loglog(t_ref, v_0**2*t_ref**2, 'r--', label=r'$\\sim v_0^2 t^2$ (ballistic)')\nplt.loglog(t_ref, 4*D_eff*t_ref, 'g--', label=r'$\\sim 4D_{eff}t$ (enhanced diffusion)')\n\n# Add vertical line at rotational diffusion time\nplt.axvline(x=tau_r, color='gray', linestyle=':', label=r'$\\tau_r = 1/D_r$')\n\n# Mark the three regimes\n#plt.annotate(\"Short-time regime\", xy=(0.02, 0.3), xytext=(0.02, 0.3), fontsize=9)\n#plt.annotate(\"Intermediate-time regime\", xy=(0.5, 10), xytext=(0.5, 10), fontsize=9)\n#plt.annotate(\"Long-time regime\", xy=(10, 200), xytext=(10, 200), fontsize=9)\n\nplt.xlabel(r'Time $t$')\nplt.ylabel(r'MSD $\\langle|\\mathbf{r}(t) - \\mathbf{r}(0)|^2\\rangle$')\n#plt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6— Mean square displacement (MSD) of an active Brownian particle showing three distinct regimes. At short times (\\(t \\ll \\tau_r\\)), a combination of diffusive and ballistic motion is observed. At intermediate times, ballistic motion dominates (\\(\\text{MSD} \\sim t^2\\)). At long times (\\(t \\gg \\tau_r\\)), enhanced diffusion emerges with an effective diffusion coefficient larger than the thermal value.\n\n\n\n\n\n\n\nProbability Distribution\nThe steady-state probability distribution of ABPs cannot be written in the Boltzmann form, unlike equilibrium systems. Instead, it depends on both position and orientation, and generally has to be obtained numerically or through approximation methods.\nIn homogeneous space, the orientation-averaged probability distribution is uniform. However, in the presence of boundaries or spatially varying potentials, ABPs exhibit phenomena like accumulation at surfaces and trapping in local potential minima that are qualitatively different from equilibrium Brownian particles.\n\n\nTime Reversal Symmetry Breaking\nOne of the hallmarks of equilibrium systems is their invariance under time reversal. For passive Brownian particles, if we were to watch a movie of particle motion and then play it backwards, the reversed trajectories would still be physically plausible and consistent with the laws of equilibrium statistical mechanics.\nFor ABPs, however, time reversal symmetry is explicitly broken. This can be seen directly from the overdamped Langevin equations:\n\\[\\gamma\\frac{d\\mathbf{r}}{dt} = \\gamma v_0 \\mathbf{n}(t) - \\nabla U(\\mathbf{r}) + \\boldsymbol{\\xi}(t)\\]\n\\[\\frac{d\\theta}{dt} = \\eta(t)\\] Under time reversal \\(t \\rightarrow -t\\), the position derivative transforms as \\(\\frac{d\\mathbf{r}}{d(-t)} = -\\frac{d\\mathbf{r}}{dt}\\), meaning the left side of the equation changes sign. The random noise term \\(\\boldsymbol{\\xi}(-t)\\) remains statistically equivalent to \\(\\boldsymbol{\\xi}(t)\\) due to its time-symmetric properties. However, the self-propulsion term \\(v_0 \\mathbf{n}(t)\\) behaves differently: while the orientation vector \\(\\mathbf{n}(t)\\) would evolve backwards in time, the self-propulsion speed \\(v_0\\) maintains its sign because it represents an internal energy conversion process (chemical to mechanical) with a fixed directionality relative to the particle’s orientation. This non-reversing active driving force is fundamentally different from reversible conservative forces, as it continually injects energy into the system. Consequently, the original equation and its time-reversed version describe physically distinct dynamics, demonstrating explicit time-reversal symmetry breaking in active systems.\n\n\n\n\n\n\nFigure 7— Janus particles exhibit physical asymmetry, with different properties on their two faces. This structural asymmetry leads to directional self-propulsion and breaking of time-reversal symmetry. The asymmetric design of Janus particles (e.g., with one catalytic hemisphere) creates directed motion that fundamentally breaks time-reversal symmetry. Under time reversal, the particle would appear to move against its catalytic face—a physically impossible scenario that illustrates the non-equilibrium nature of active particles.\n\n\n\nVisually, this time-reversal asymmetry can be observed in trajectory data: forward trajectories show persistent motion along the instantaneous orientation, while time-reversed trajectories would appear to move persistently against their orientation—a scenario prohibited by the ABP dynamics. This persistence is also evident in the ballistic regime of the mean square displacement, which has no counterpart in equilibrium systems.\n\n\nFDT Violation\nAs we saw in Lecture 2, the fluctuation-dissipation theorem (FDT) connects the spontaneous fluctuations in equilibrium systems to their response to external perturbations. For ABPs, this theorem is violated due to the self-propulsion term that injects energy at the microscopic level.\nThe violation of the FDT can be quantified by introducing an effective temperature:\n\\[T_{\\text{eff}} = T\\left(1 + \\frac{v_0^2}{2D_tD_r}\\right)\\]\nThis effective temperature is higher than the bath temperature, reflecting the enhanced fluctuations due to activity.\n\n\nTaxonomy of Active Particle Models\nBesides the two active particle models there are a number of other ones capturing different aspects of active motion.\n\n\n\n\n\n\n\n\n\n\nModel\nKey Characteristics\nMovement Mechanism\nBiological/Synthetic Examples\nPhysical Limitations\n\n\n\n\nRun-and-Tumble Particles (RTPs)\nAlternates between straight runs and random reorientations\nDiscrete reorientations at Poisson-distributed times\nE. coli bacteria, Salmonella\nAssumes instantaneous reorientations and ignores hydrodynamic interactions; real bacteria have finite tumbling durations and experience fluid resistance\n\n\nActive Brownian Particles (ABPs)\nPersistent propulsion with continuous rotational diffusion\nContinuous rotational diffusion combined with constant propulsion speed\nJanus colloids, synthetic microswimmers\nNeglects hydrodynamic interactions and assumes constant propulsion regardless of environmental conditions; real swimmers may adjust speed based on energy constraints\n\n\nActive Ornstein-Uhlenbeck Particles (AOUPs)\nSelf-propulsion with temporal correlations, colored noise\nVelocity undergoes Ornstein-Uhlenbeck process with persistence time\nCertain synthetic microswimmers, simplified model for biological cells\nLacks clear orientation-propulsion coupling present in real swimmers; statistical process may not accurately represent actual biological propulsion mechanisms\n\n\nChiral Active Particles\nCircular/helical trajectories due to intrinsic torque\nConstant angular velocity combined with self-propulsion\nMagnetotactic bacteria, sperm cells near surfaces\nAssumes constant angular velocity and curvature radius; real organisms often modulate these parameters based on environmental cues and energetic constraints",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 3"
    ]
  },
  {
    "objectID": "lecture03/lecture03.html#swimming-at-low-reynolds-number",
    "href": "lecture03/lecture03.html#swimming-at-low-reynolds-number",
    "title": "Microscopic Models of Self-propulsion",
    "section": "Swimming at Low Reynolds Number",
    "text": "Swimming at Low Reynolds Number\nMicroorganisms and synthetic microswimmers propel themselves in a liquid environment generally described by the Navier-Stokes equation, which governs fluid motion by balancing inertial forces with pressure gradients, viscous forces, and external forces:\n\\[\\rho\\left(\\frac{\\partial \\mathbf{v}}{\\partial t} + \\mathbf{v} \\cdot \\nabla \\mathbf{v}\\right) = -\\nabla p + \\eta\\nabla^2\\mathbf{v} + \\mathbf{f}\\]\nHere, \\(\\rho\\) is fluid density, \\(\\mathbf{v}\\) is velocity, \\(p\\) is pressure, \\(\\eta\\) is dynamic viscosity, and \\(\\mathbf{f}\\) represents external force density. Through dimensional analysis, we can determine the relative importance of the inertial (\\(\\rho\\mathbf{v} \\cdot \\nabla \\mathbf{v}\\)) versus viscous (\\(\\eta\\nabla^2\\mathbf{v}\\)) terms. If we scale length by \\(L\\), velocity by \\(V\\), and time by \\(L/V\\), the inertial term scales as \\(\\rho V^2/L\\) while the viscous term scales as \\(\\eta V/L^2\\). Their ratio yields the dimensionless Reynolds number:\n\\[Re = \\frac{\\rho v L}{\\eta}\\]\nwhere \\(\\rho\\) is the fluid density, \\(v\\) is the characteristic velocity, \\(L\\) is the characteristic length scale, and \\(\\eta\\) is the fluid viscosity.\nFor a swimming bacterium like E. coli:\n\n\\(L \\approx 1 \\, \\mu\\text{m}\\)\n\\(v \\approx 30 \\, \\mu\\text{m/s}\\)\n\\(\\rho \\approx 10^3 \\, \\text{kg/m}^3\\) (water)\n\\(\\eta \\approx 10^{-3} \\, \\text{Pa} \\cdot \\text{s}\\) (water)\n\nThis gives \\(Re \\approx 3 \\times 10^{-5}\\), indicating that viscous forces overwhelmingly dominate inertial forces. This regime presents unique challenges for locomotion that are fundamentally different from our macroscopic experience.\n\nThe Scallop Theorem\nAt low Reynolds numbers, the inertial term in the Navier-Stokes equations can be dropped, leading to the simplified Stokes equations:\n\\[\\eta \\nabla^2 \\mathbf{v} - \\nabla p = 0\\] \\[\\nabla \\cdot \\mathbf{v} = 0\\]\nwhere \\(\\mathbf{v}\\) is the fluid velocity and \\(p\\) is the pressure. These equations are linear and time-independent, which leads to the “scallop theorem”.\n\n\n\n\n\n\nThe Scallop Theorem\n\n\n\nThe Scallop Theorem states that a microswimmer with a single degree of freedom cannot achieve net displacement in a Stokesian fluid (low Reynolds number). A scallop, which can only open and close its shell, represents such a mechanism with a single hinge. When the scallop opens slowly and closes rapidly in water, it generates thrust at the macroscale where inertia matters. However, at the microscale where viscous forces dominate, the time-reversibility of Stokes flow means the scallop would simply trace the same path backward and forward, resulting in no net movement regardless of how asymmetrically it times its opening and closing motions.\n\n\n\n\n\n\nFigure 8— Illustration of the scallop theorem principle: a scallop-like mechanism with a single hinge can generate thrust at high Reynolds numbers (left) but produces no net motion at the microscale (right) where viscous forces dominate, as the motion is fully reversible. Source: [1] Yang, C., Liu, X., Song, X. & Zhang, L. Design and batch fabrication of anisotropic microparticles toward small-scale robots using microfluidics: recent advances. Lab a Chip 24, 4514–4535 (2024).\n\n\n\n\n\nThis theorem, formulated by Edward Purcell, can be understood as follows: if a swimmer changes its shape from A to B and then reverses this change from B to A along exactly the same path in configuration space, the net displacement will be zero. This is in stark contrast to swimming at high Reynolds numbers, where inertia allows for net displacement even with reciprocal motion.\n\n\nBreaking Time-Reversibility\nTo achieve net displacement at low Reynolds numbers, a swimmer must break time-reversibility. This can be done in several ways:\n\nNon-reciprocal deformation: The swimmer changes shape in a way that is not simply the reverse of the previous motion. Examples include Purcell’s three-link swimmer and the flexible oar.\n\n\n\n\n\n\n\nFigure 9— Amoeboid movement represents a classic example of non-reciprocal deformation, where the organism extends pseudopodia (temporary projections of cytoplasm) in a coordinated sequence that cannot be simply reversed. This asymmetric reshaping of the cell body enables locomotion even at low Reynolds numbers by creating a non-time-reversible sequence of configurations.\n\n\n\n\nChiral propellers: Rotating a chiral structure like a bacterial flagellum creates propulsion. The helical shape of the flagellum converts rotational motion into translational thrust.\n\n\n\n\n\n\n\nFigure 10— The helical structure of a bacterial flagellum allows it to convert rotational motion into translational thrust through a process known as the “whirlpool effect.” As the flagellum rotates, it creates a swirling motion in the surrounding fluid, which pushes the cell forward.\n\n\n\n\nMultiple degrees of freedom: Using two or more degrees of freedom with phase differences between them (like the motion of cilia) creates non-reciprocal motion.\n\n\n\n\n\n\n\nFigure 11— Purcell’s three-link swimmer demonstrates how a simple articulated structure with two degrees of freedom (two hinges) can achieve net displacement at low Reynolds numbers. By executing a non-reciprocal sequence of shape changes—moving the links in a way that cannot be reversed by simply retracing the path—this minimal swimmer breaks time-reversibility and generates directed motion in a viscous environment.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 3"
    ]
  },
  {
    "objectID": "lecture03/lecture03.html#from-swimming-to-hydrodynamic-interactions",
    "href": "lecture03/lecture03.html#from-swimming-to-hydrodynamic-interactions",
    "title": "Microscopic Models of Self-propulsion",
    "section": "From Swimming to Hydrodynamic Interactions",
    "text": "From Swimming to Hydrodynamic Interactions\nWhen microorganisms swim at low Reynolds numbers, they don’t just move themselves - they also generate flow fields in the surrounding fluid. These flow fields arise from the force-free swimming mechanisms we’ve explored and significantly influence how microswimmers interact with their environment and each other.\n\nThe Origin of Hydrodynamic Singularities in Swimming\nTo understand how swimming generates flow fields, we need to examine two fundamental types of elementary flow patterns in Stokes flow:\n\nSource/sink dipoles: These represent the displacement of fluid as a body moves through it. Consider a sphere moving through fluid - it pushes fluid ahead (source) and creates a region behind where fluid flows in (sink). These source dipoles:\n\nDecay rapidly with distance as \\(1/r^3\\)\nContribute to the propulsion of the swimmer\nResult from the swimmer’s shape changes and boundary motion\n\nThe flow field generated by a source dipole with dipole moment \\(\\mathbf{p}\\) at a position \\(\\mathbf{r}\\) relative to the dipole center is:\n\\[\\mathbf{u}_{\\text{dipole}}(\\mathbf{r}) = -\\frac{1}{4\\pi}\\nabla \\left(\\frac{\\mathbf{p} \\cdot \\mathbf{r}}{r^3}\\right) = \\frac{1}{4\\pi}\\left[\\frac{3(\\mathbf{p} \\cdot \\mathbf{r})\\mathbf{r}}{r^5} - \\frac{\\mathbf{p}}{r^3}\\right]\\]\nwhere \\(r = |\\mathbf{r}|\\). This is analogous to the electric field of an electric dipole, with the \\(1/r^3\\) decay characteristic of dipole fields.\n\n\n\nCode\n# Set up a grid\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\n\n# Calculate R (distance from origin) for each point\nR = np.sqrt(X**2 + Y**2)\n\n# Define dipole moment vector (along x-axis)\np_x, p_y = 1.0, 0.0\n\n# Calculate dot product p·r\np_dot_r = p_x*X + p_y*Y\n\n# Set up arrays for velocity field components\nu = np.zeros_like(X)\nv = np.zeros_like(Y)\n\n# Apply the dipole equation at each point where R &gt; 0\n# u = (1/4π)[(3(p·r)x/r^5) - (p_x/r^3)]\n# v = (1/4π)[(3(p·r)y/r^5) - (p_y/r^3)]\n\nmask = R &gt; 0.2  # Avoid singularity at origin\n\nu[mask] = (1/(4*np.pi))*(3*p_dot_r[mask]*X[mask]/R[mask]**5 - p_x/R[mask]**3)\nv[mask] = (1/(4*np.pi))*(3*p_dot_r[mask]*Y[mask]/R[mask]**5 - p_y/R[mask]**3)\n\n# Create plot\nplt.figure(figsize=get_size(8, 8))\n\n# Plot streamlines\nplt.streamplot(X, Y, u, v, density=1, color='k', linewidth=1, arrowsize=0.5)\n\n# Add dipole location and moment direction\nplt.scatter(0, 0, color='red', s=50, label='Dipole location')\nplt.arrow(0, 0, p_x*0.5, p_y*0.5, width=0.05, head_width=0.15,\n          head_length=0.2, fc='red', ec='red', label='Dipole moment')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Source Dipole Flow Field')\nplt.axis('equal')\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 12— Flow field generated by a source dipole with dipole moment \\(\\mathbf{p}\\) pointing in the x-direction. The streamlines show the characteristic pattern of fluid being pushed away along the dipole axis and drawn in from the sides, with the flow strength decaying as \\(1/r^3\\).\n\n\n\n\n\n\nForce dipoles: Since microswimmers are force-free (no net external force), the thrust forces they generate must be balanced by drag forces, creating a force dipole configuration. A force dipole is generated by two equal and opposite point forces aligned parallel to the x-axis, either both pointing towards the origin (converging) or both pointing away from the origin (diverging). These force dipoles:\n\nDecay more slowly with distance as \\(1/r^2\\)\nDominate the long-range hydrodynamic interactions\nAllow us to classify swimmers as either “pushers” (forces pointing away from the origin, like E. coli) or “pullers” (forces pointing towards the origin, like Chlamydomonas)\n\nFor a force dipole aligned along unit vector \\(\\mathbf{e}\\), the flow field is:\n\\[\\mathbf{u}_{\\text{stresslet}}(\\mathbf{r}) = \\frac{S}{8\\pi\\eta}\\left[\\frac{3(\\mathbf{e}\\cdot\\mathbf{r})^2\\mathbf{r} - r^2\\mathbf{e}}{r^5}\\right]\\]\nwhere \\(S\\) is the stresslet strength (dipole moment) and \\(\\eta\\) is the fluid viscosity. The sign of \\(S\\) determines the swimmer type: \\(S &lt; 0\\) for pushers and \\(S &gt; 0\\) for pullers. For a swimmer of size \\(a\\) moving at speed \\(v_0\\), we can estimate \\(S \\sim \\eta a^2 v_0\\).\nAt large distances, this simplifies to:\n\\[\\mathbf{u}_{\\text{stresslet}}(\\mathbf{r}) \\approx \\frac{S}{8\\pi\\eta}\\frac{3(\\mathbf{e}\\cdot\\hat{\\mathbf{r}})^2-1}{r^2}\\hat{\\mathbf{r}} \\quad \\text{as } r \\to \\infty\\]\nwhere \\(\\hat{\\mathbf{r}} = \\mathbf{r}/r\\) is the direction vector.\n\n\n\nCode\n# Create figure with two subplots for pusher and puller\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 6))\n\n# Set up a grid\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\n\n# Calculate R (distance from origin) for each point\nR = np.sqrt(X**2 + Y**2)\n\n# For both pusher and puller\nfor ax, S, title in zip([ax1, ax2], [-1.0, 1.0], [\"Puller (S &lt; 0)\", \"Pusher (S &gt; 0)\"]):\n    # Set up arrays for velocity field components\n    u = np.zeros_like(X)\n    v = np.zeros_like(Y)\n\n    # Avoid singularity at origin\n    mask = R &gt; 0.2\n    eta = 1.0  # Normalize viscosity\n    r_sq = X[mask]**2 + Y[mask]**2\n\n    # x-component\n    u[mask] = (S/(8*np.pi*eta)) * (3*(X[mask]**2)*X[mask] - r_sq*X[mask])/R[mask]**5\n\n    # y-component\n    v[mask] = (S/(8*np.pi*eta)) * (3*(X[mask]**2)*Y[mask] - 0)/R[mask]**5\n\n    # Plot streamlines\n    ax.streamplot(X, Y, u, v, density=1.2, color='k', linewidth=0.5, arrowsize=0.5)\n\n    # Add force locations and arrows to visualize the dipole\n    if S &lt; 0:  # Puller: forces pointing outward\n        ax.arrow(-0.4, 0, 0.3, 0, width=0.05, head_width=0.15,\n                head_length=0.2, fc='red', ec='red')\n        ax.arrow(0.4, 0, -0.3, 0, width=0.05, head_width=0.15,\n                head_length=0.2, fc='red', ec='red')\n        ax.scatter([-0.4, 0.4], [0, 0], color='red', s=50)\n    else:  # Puller: forces pointing inward\n        ax.arrow(-0.4, 0, -0.3, 0, width=0.05, head_width=0.15,\n                head_length=0.2, fc='red', ec='red')\n        ax.arrow(0.4, 0, 0.3, 0, width=0.05, head_width=0.15,\n                head_length=0.2, fc='red', ec='red')\n        ax.scatter([-0.4, 0.4], [0, 0], color='red', s=50)\n\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title(title)\n    ax.set_xlim(-3, 3)\n    ax.set_ylim(-3, 3)\n    ax.set_aspect('equal')\n    ax.grid(True, linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 13— Pusher Puller\n\n\n\n\n\nIn the far field, the flow generated by a force dipole (pusher, S &gt; 0) at large distances from the swimmer exhibits a dominant \\(1/r^2\\) decay pattern. Fluid is pulled in from the sides and pushed away along the swimming direction.\n\n\nCode\n# Set up a grid for far-field visualization (larger domain)\nx_far = np.linspace(-10, 10, 100)\ny_far = np.linspace(-10, 10, 100)\nX_far, Y_far = np.meshgrid(x_far, y_far)\n\n# Calculate R (distance from origin) for each point\nR_far = np.sqrt(X_far**2 + Y_far**2)\n\n# Set up arrays for velocity field components\nu_far = np.zeros_like(X_far)\nv_far = np.zeros_like(Y_far)\n\n# Parameters\nS = 1.0  # Positive for pusher\neta = 1.0  # Normalized viscosity\ne_x, e_y = 1.0, 0.0  # Unit vector along x-axis\n\n# Avoid singularity at origin\nmask_far = R_far &gt; 0.5\n\n# Compute unit radial vectors\nr_hat_x = X_far[mask_far] / R_far[mask_far]\nr_hat_y = Y_far[mask_far] / R_far[mask_far]\n\n# Compute e·r̂\ne_dot_r_hat = e_x*r_hat_x + e_y*r_hat_y\n\n# Far-field approximation: u ≈ (S/8πη)[(3(e·r̂)² - 1)/r²]r̂\n# Calculate the scalar coefficient\ncoef = (S/(8*np.pi*eta)) * (3*e_dot_r_hat**2 - 1) / R_far[mask_far]**2\n\n# Apply to get velocity components\nu_far[mask_far] = coef * r_hat_x\nv_far[mask_far] = coef * r_hat_y\n\n# Create plot\nplt.figure(figsize=get_size(10, 8))\n\n# Plot streamlines for far-field approximation\nplt.streamplot(X_far, Y_far, u_far, v_far, density=1.0, color='k',\n               linewidth=0.8, arrowsize=0.8)\n\n\n# Add swimming direction indication\nplt.arrow(0, 0, 2, 0, width=0.2, head_width=0.6,\n          head_length=0.8, fc='blue', ec='blue', alpha=0.7)\nplt.scatter(0, 0, color='blue', s=80, alpha=0.7, label='Swimmer')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Far-field Force Dipole Flow (Pusher)')\nplt.axis('square')\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\n\n# Add a circle to indicate the near-field region\ncircle = plt.Circle((0, 0), 2, fill=False, color='red', linestyle='--', alpha=0.7)\nplt.gca().add_patch(circle)\nplt.text(2.2, 0.5, 'Near-field', color='red', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 14— Far-field approximation of the flow generated by a force dipole (pusher, S &gt; 0) at large distances from the swimmer. The streamlines illustrate how the dominant \\(1/r^2\\) decay pattern emerges, with fluid being pulled in from the sides and pushed away along the swimming direction.\n\n\n\n\n\nThis distinction has important physical consequences: source dipoles enable self-propulsion but decay rapidly, while force dipoles dominate the long-range interactions between swimmers. These flow fields can be derived from the fundamental solution of Stokes flow (the Oseen tensor):\n\\[G_{ij}(\\mathbf{r}) = \\frac{1}{8\\pi\\eta}\\left(\\frac{\\delta_{ij}}{r} + \\frac{r_i r_j}{r^3}\\right)\\]\nwhich gives the velocity field at position \\(\\mathbf{r}\\) due to a point force at the origin.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 3"
    ]
  },
  {
    "objectID": "lecture01/lecture01.html",
    "href": "lecture01/lecture01.html",
    "title": "Introduction to Active Matter",
    "section": "",
    "text": "The study of active matter emerged in the late 20th century at the intersection of soft matter physics, biophysics, and statistical mechanics. An important precursor to the field came from computer graphics, where Craig Reynolds developed the Boids simulation in 1986 - an artificial life program that demonstrated how simple rules governing individual agents could produce realistic flocking behaviors in computer animations. Earlier cellular automata models like Conway’s Game of Life had also shown how simple rules could lead to complex emergent behaviors, helping establish some of the conceptual foundations for understanding collective systems.\n\n\n\n\n\n\n\n\n  \n    Reset Simulation\n  \n  \n    Separation: \n    Alignment: \n    Cohesion: \n  \n\n\n\n\n\n\nFigure 1: Interactive simulation of the Boids model, where you can adjust the three key parameters that govern flocking behavior: separation (avoidance of crowding), alignment (steering towards average heading), and cohesion (steering towards center of mass).\n\n\n\n\n\n\n\n\n\nThe Boids Model Explained\n\n\n\n\n\nThe Boids model, developed by Craig Reynolds in 1986, simulates the flocking behavior of birds using three simple rules:\n\nSeparation: Each boid avoids crowding nearby flockmates, steering away when they get too close.\nAlignment: Each boid aligns its direction of flight with nearby flockmates, matching their average velocity.\nCohesion: Each boid moves toward the center of mass of nearby flockmates, creating a tendency to stick together.\n\nThese local interaction rules, when applied to all individuals simultaneously, produce complex global behaviors that remarkably resemble natural flocking patterns. The simulation above demonstrates how adjusting these three parameters affects the emergent collective motion:\n\nHigh separation, low alignment, low cohesion: Dispersed individuals with minimal coordination\nLow separation, high alignment, medium cohesion: Coherent flocking with directional movement\nBalanced parameters: Natural-looking flocking behaviors with dynamic subgroup formation\n\nThis model illustrates a fundamental principle in active matter physics: complex collective behaviors can emerge from simple local rules without centralized control.\n\n\n\nThis computational model later influenced physical approaches to collective motion. Early foundational work by scientists like T. Vicsek in the 1990s established computational models for collective motion, particularly his 1995 paper introducing what is now known as the Vicsek model for self-propelled particles with alignment interactions. Prior to this, early biological observations of collective behaviors in nature, such as bird flocking and fish schooling, had long fascinated scientists but lacked rigorous physical frameworks. The field gained significant momentum in the late 1990swith seminal papers by John Toner and Yuhai Tu, who published their groundbreaking work on flocking theory in 1995, and later Sriram Ramaswamy who developed continuum theories for active nematics.\nThe theoretical foundations were further strengthened by contributions from European researchers like Michael Cates (Edinburgh), Jean-François Joanny (Paris), and Jacques Prost (Paris), who developed the active gel theory to describe cytoskeletal dynamics in the mid-2000s. Simultaneously, M. Cristina Marchetti and her collaborators formulated comprehensive hydrodynamic theories for active systems across various symmetry classes. Sriram Ramaswamy made fundamental contributions through his work on active liquid crystals and the development of generic hydrodynamic theories for active matter. The pioneering work of John Toner and Yuhai Tu established the theoretical framework for understanding the emergence of long-range order in flocking systems, demonstrating how activity can stabilize orientational order even in two dimensions. Julia Yeomans (Oxford) advanced our understanding of active turbulence and topological defects in active nematics through innovative computational approaches, while Hartmut Löwen (Düsseldorf) developed influential theories for the collective behavior of active Brownian particles and motility-induced phase separation. These theoretical advances were complemented by experimental breakthroughs, notably Howard Berg’s groundbreaking work in the 1970s at Harvard on bacterial chemotaxis and motility, where he developed the tracking microscope to follow individual E. coli bacteria and discovered their run-and-tumble motion patterns. Additional experimental contributions came from Raymond Goldstein (Cambridge) and others who established quantitative measurements of collective motion in bacterial systems.\nExperimental breakthroughs with bacterial suspensions (notably work by Igor Aranson and Raymond Goldstein on Bacillus subtilis), cell tissues (including Xavier Trepat’s research at IBEC in Barcelona on epithelial cell sheets), and synthetic active colloids (pioneered by European researchers like Jérémie Palacci (Lyon/San Diego), Julien Perrin (Paris), and Clemens Bechinger (Konstanz/Stuttgart) with light-activated Janus particles) further propelled the field forward. The development of artificial microswimmers by international collaborations involving European teams led by Roberto Di Leonardo (Rome), Ramin Golestanian (Oxford/Göttingen), and Frank Cichos (Leipzig), alongside US-based researchers like Steve Granick and Ayusman Sen, opened new avenues for creating controllable active systems outside biological contexts.\nBy the 2010s, active matter had developed into a distinct discipline with dedicated conferences and research groups worldwide. The establishment of specialized research centers across Europe such as the Max Planck Institute for Dynamics and Self-Organization in Göttingen, the Physics of Living Matter Group at Cambridge, the Biological Physics and Morphogenesis groups at MPIPKS Dresden, alongside the Syracuse Soft and Living Matter Program, the Center for the Physics of Biological Function at Princeton, and the Active Matter Lab at MIT reflected the field’s growing importance. Major milestones included the observation of motility-induced phase separation by Michael Cates (Edinburgh) and Julien Tailleur (Paris) (2013), the discovery of topological defect motility in active nematics by Zvonimir Dogic and collaborators (2014), and the creation of the first autonomous active material capable of performing work by Daniela Wilson’s group (Nijmegen) (2019). The field continues to expand with increasing interdisciplinary collaborations between physicists, biologists, materials scientists, and engineers, addressing fundamental questions in non-equilibrium physics while developing applications in biomedicine, soft robotics, and smart materials.\n\n\n\nUnderstanding how active matter systems differ from equilibrium systems is crucial for developing new theoretical frameworks and experimental approaches. The continuous energy input and self-driven nature of active matter leads to behaviors that challenge our traditional physics understanding. Consider the following key distinctions between equilibrium and active matter systems:\n\n\n\n\n\n\n\n\nFeature\nEquilibrium Systems\nActive Matter Systems\n\n\n\n\nDetailed Balance\nForward and reverse processes occur at equal rates\nContinuously broken through energy consumption, driving the system away from equilibrium\n\n\nFluctuation-Dissipation Theorem\nValid relationship between spontaneous fluctuations and response to external perturbations\nBreaks down as fluctuations can be driven by internal activity\n\n\nParticle Motion\nRandom Brownian motion\nPersistent directional motion over certain timescales\n\n\nStatistical Distributions\nFollow Boltzmann statistics\nNon-Boltzmann statistics, making standard thermodynamic tools inapplicable\n\n\nMacroscopic Currents\nAbsent in steady states\nCan sustain macroscopic currents and flux cycles even in steady states\n\n\nPhase Behavior\nWell-established equilibrium phases\nUnique phase transitions with no equilibrium counterparts (e.g., motility-induced phase separation, active turbulence)\n\n\nMechanical Pressure\nIndependent of boundary properties\nCan depend on properties of confining walls, violating equilibrium equations of state\n\n\nEnergy and Entropy\nMinimize free energy, maximize entropy\nContinuously dissipate energy and produce entropy even in steady states\n\n\nTime-Reversal Symmetry\nDynamics appear similar when played forward or backward\nDynamics look distinctly different when played forward versus backward\n\n\nForce Characteristics\nDerivable from a potential energy function\nCannot generally be derived from a potential energy function\n\n\n\n\n\n\nActive matter encompasses a diverse range of systems, from biological organisms to synthetic particles, that share the common feature of continuously converting energy into systematic motion. These systems can be organized into several categories based on their energy sources, symmetries, and the nature of their interactions, providing a framework for understanding their distinct behaviors and properties.\n\n\n\n\n\n\nFigure 2: Overview of active matter systems at different scales and domains. The field spans from microscopic biological systems like cellular components to macroscopic collective behaviors and engineered synthetic systems. (source)\n\n\n\nActive matter systems can be categorized based on several key characteristics:\n\nEnergy conversion mechanismSymmetry of motionMedium and interactionsStructural arrangementLength scale and dimensionality\n\n\n\nBiological active matter: Systems that convert chemical energy (ATP, nutrients) into mechanical work (e.g., bacteria, cells, tissues). These systems span multiple scales, from molecular motors like kinesin and myosin that transport cargo along cytoskeletal filaments, to cellular components such as the dynamic cytoskeleton that enables cell shape changes and migration. At multicellular scales, coordinated activity enables tissue morphogenesis during development, wound healing, and collective cell migration. The energy conversion typically involves ATP hydrolysis, which provides approximately 20 kT of energy per molecule, enabling these systems to perform work against thermal fluctuations. Unlike their synthetic counterparts, biological active matter often exhibits adaptive behaviors, feedback regulation, and hierarchical organization that enhances functionality and robustness.\n\n\n\n\n\n\n\n\n\nATP hydrolysis is the primary energy source in most cellular processes\n\n\n\n\n\n\n\nBacteria like E. coli use flagella powered by molecular motors\n\n\n\n\n\n\nFigure 3: ATP hydrolysis and bacterial motility represent key examples of chemical energy conversion in biological active matter\n\n\n\n\nSynthetic active matter: Engineered systems powered by external fields, chemical reactions, or light (e.g., Janus particles, active colloids). These artificial systems represent human-designed analogs to biological active matter, with scientists having precise control over their properties and behaviors. Synthetic active particles typically feature asymmetric structures or surface properties that enable self-propulsion. Common examples include Janus particles with catalyst-coated hemispheres that decompose hydrogen peroxide to create propulsion, light-activated particles that convert photonic energy into motion, and magnetically-actuated microswimmers that respond to oscillating external fields. Unlike biological systems, synthetic active matter can be designed with specific functionalities, such as targeted drug delivery, environmental remediation, or self-assembly into complex structures. Recent advances have produced programmable behaviors through responsive materials, feedback mechanisms, and even rudimentary “communication” between synthetic active agents.\n\n\n\n\n\n\n\nFigure 4: Synthetic active particles can be designed with asymmetric properties to enable self-propulsion through various mechanisms\n\n\n\n\n\n\nPolar active matter: Entities with defined front-back asymmetry and directional motion (e.g., birds, fish). These systems are characterized by particles or organisms that have a clear direction of motion and can align their movement with neighbors. For example, fish schools demonstrate this through their streamlined body shape that defines a clear swimming direction, while their lateral line system helps them align with neighboring fish. Similarly, migratory birds show polar order through their aerodynamic body structure and visual alignment with flock-mates during flight. At the microscopic scale, many bacteria like E. coli exhibit polar motion through their flagellar propulsion system that creates directed swimming. The polar nature of these systems often leads to unique collective phenomena like the emergence of large-scale coherent motion and the formation of traveling bands or density waves.\n\n\n\n\n\n\n\n\n\nFish schools demonstrate collective motion through simple alignment rules\n\n\n\n\n\n\n\nBird flocks exhibit emergent order through local interactions\n\n\n\n\n\n\nFigure 5: Examples of polar active matter: fish schools (source) and bird flocks (source)\n\n\n\n\nApolar active matter: Systems generating motion without a defined direction (e.g., melanocytes, active nematics). These systems exhibit interesting collective behaviors despite lacking a preferred direction of motion at the individual level. For example, melanocytes, the cells responsible for skin pigmentation, extend and retract protrusions in multiple directions as they move and distribute melanin. Similarly, active nematics, such as dense suspensions of microtubules and molecular motors, generate complex flows and defect dynamics without any preferred direction of motion for individual components. The apolar nature of these systems often leads to unique phenomena like the spontaneous formation and annihilation of topological defects, and the emergence of active turbulence in confined geometries.\n\n\n\n\n\n\n\n\n\nMelanocyte cells showing apolar migration patterns\n\n\n\n\n\n\n\nActive nematic liquid crystals with defect patterns\n\n\n\n\n\n\nFigure 6: Examples of apolar active matter: melanocytes (source) and active nematics (source)\n\n\n\n\nChiral active matter: Systems with inherent rotational motion or handedness. These systems exhibit systematic rotational motion in addition to translational movement, often due to structural asymmetry or biased force generation. Examples include bacterial flagella that rotate to create propulsion, sperm cells that swim with helical trajectories, and synthetic microswimmers with chiral shapes that spin as they move through fluid. The interplay between rotational and translational motion in these systems can lead to unique collective behaviors, such as the formation of rotating clusters or vortex arrays. At the microscopic scale, molecular motors like the bacterial flagellar motor demonstrate how nature utilizes chirality to generate motion, while at larger scales, schools of fish can form rotating vortex patterns through their collective swimming behavior.\n\n\n\n\nDry active matter: Systems where momentum dissipates to a substrate (e.g., cells on surfaces). In these systems, the primary interaction between particles occurs through direct contact or short-range forces, as the substrate quickly dampens any long-range hydrodynamic effects. A classic example is cells crawling on a surface, where the friction with the substrate dominates the dynamics. Another example is vibrated granular layers, where energy input causes particle motion but momentum is quickly dissipated through collisions with the base plate and between particles.\nWet active matter: Systems embedded in a fluid where hydrodynamic interactions dominate (e.g., bacterial suspensions). These systems exhibit complex long-range interactions mediated by the fluid, as the motion of each active particle creates flow fields that affect distant particles. Examples include swimming microorganisms in water, where the fluid flows generated by one organism can influence the motion of others several body lengths away. Active colloids in suspension also demonstrate these effects, where the chemical activity or motion of particles creates fluid flows that lead to collective behaviors and pattern formation.\n\n\n\n\nActive crystals: Ordered lattice-like arrangements with activity. These systems maintain crystalline order while individual units remain active, such as in bacterial colonies that form regular spatial patterns while each bacterium continues to move and metabolize. A key example is the formation of living crystals from light-activated colloidal particles, where the particles self-organize into a crystalline lattice while maintaining their individual motility.\nActive glasses: Disordered, jammed configurations with activity. Unlike traditional glasses, these systems combine structural disorder with persistent local motion, leading to unique dynamical behaviors. Examples include dense bacterial suspensions at high concentrations where cells become trapped in disordered configurations but continue to exert active forces on their neighbors, or crowded solutions of motor proteins and filaments where steric constraints create glassy dynamics despite ongoing ATP-driven activity.\nActive fluids/gases: Flowing systems with active components. These systems exhibit fluid-like behavior but with constituents that continuously inject energy at the microscopic scale. Examples range from dilute bacterial suspensions that show enhanced diffusion and collective motion, to dense active liquid crystals where the interplay between flow and orientational order creates complex dynamical patterns like active turbulence. In the gas-like regime, systems like midge swarms demonstrate how active particles can maintain cohesion while exhibiting fluid-like properties.\n\n\n\n\nMicroscopic: Cellular and subcellular systems (cytoskeleton, bacterial colonies). At this scale, active matter emerges from molecular motors like kinesin and dynein walking along cytoskeletal filaments, or the collective motion of bacterial cells in colonies. The cytoskeleton itself is a fascinating example where networks of actin filaments and microtubules, driven by ATP-powered molecular motors, create complex dynamics essential for cell function and division.\nMesoscopic: Tissue and organ-level organizations. At the tissue level, collective cell behavior leads to emergent phenomena like wound healing and morphogenesis during development. Epithelial tissues demonstrate active matter dynamics through coordinated cell migration and mechanical force transmission between neighboring cells. These intermediate scales bridge individual cell behavior with organ-level function.\n\n\n\n\n\n\n\nFigure 7: Time-lapse microscopy of Drosophila embryo development showing gastrulation and tissue folding - a striking example of how active matter principles govern morphogenesis. The coordinated cell shape changes and movements create complex three-dimensional structures from an initially simple tissue sheet. source\n\n\n\n\nMacroscopic: Animal groups, human crowds. Large-scale collective behaviors emerge in systems like bird flocks, fish schools, and human crowds in urban environments. These systems demonstrate how simple interaction rules between individuals can create complex, coordinated motion patterns that span hundreds or thousands of times the size of individual agents. Traffic flow and pedestrian dynamics are particularly relevant examples for urban planning and crowd safety.\nQuasi-2D vs. 3D systems: Systems confined to surfaces vs. fully three-dimensional systems. Many active matter systems are effectively two-dimensional, like bacterial colonies growing on agar plates or cells migrating on substrates. These confined geometries often simplify both experimental observation and theoretical analysis. In contrast, true three-dimensional systems like bacterial suspensions in fluid or cell movement in tissue matrices exhibit additional complexities due to hydrodynamic interactions and the full range of possible motion directions.\n\n\n\n\n\n\n\nThe theoretical description of active matter draws from and extends multiple branches of physics:\n\nKinetic theoriesContinuum field theoriesAgent-based and particle models\n\n\n\nBoltzmann-like approaches: Describing probability distributions of particle positions and orientations in active systems. For example, in bacterial suspensions, this approach tracks how the probability of finding bacteria with specific positions and swimming directions evolves over time. The key difference from classical Boltzmann equations is the inclusion of self-propulsion forces and alignment interactions. These equations have been particularly successful in describing the transition from disordered to ordered states in active systems like bird flocks and fish schools.\nFokker-Planck equations: Capturing the evolution of probability densities in phase space by incorporating both deterministic and stochastic effects. In active matter, these equations describe how probability distributions change due to systematic forces (like self-propulsion), random fluctuations (thermal or active noise), and interactions between particles. For instance, they can model how Janus particles move under the influence of chemical gradients while experiencing rotational diffusion, or how swimming bacteria respond to chemical attractants while subject to tumbling events.\nSmoluchowski equations: Modeling overdamped dynamics common in biological active systems where inertial effects are negligible compared to viscous forces. These equations are particularly relevant for microscopic swimmers like bacteria or colloidal particles where the Reynolds number is very small. They have been successfully applied to describe phenomena like bacterial chemotaxis, the collective motion of cell populations, and the dynamics of motor proteins along cytoskeletal filaments. A classic example is modeling E. coli’s run-and-tumble motion, where the Smoluchowski equation – the overdamped limit of the Fokker-Planck equation – captures the interplay between directed swimming and random reorientations.\n\n\n\n\nToner-Tu theory: A hydrodynamic framework that describes collective motion in flocking systems by incorporating broken continuous symmetry. This theory is particularly powerful for analyzing large systems, where it predicts true long-range order can exist even in two dimensions, in contrast to equilibrium systems. While real flocks are finite, the theory provides insights into large-scale behaviors like the scale-free correlations observed in starling murmurations, where thousands of birds maintain coherent motion despite environmental perturbations.\nActive gel theories: These theories extend traditional liquid crystal physics by incorporating force-generating active stresses. They are particularly successful in describing biological materials like the cell cytoskeleton, where molecular motors generate internal forces. A key example is explaining the spontaneous flows observed in actomyosin networks, where myosin motors walking along actin filaments create large-scale coherent motion.\nActive nematics: Field theories that describe systems with orientational order but no polar direction, driven out of equilibrium by active stresses. These theories have been instrumental in understanding phenomena like the chaotic dynamics of microtubule-kinesin mixtures, where energy input from molecular motors leads to the continuous creation, motion, and annihilation of topological defects, resulting in active turbulence.\nPhase field models: Mathematical frameworks that track the evolution of interfaces and boundaries in active systems without explicitly tracking individual particles. These models have been successfully applied to describe phenomena like cell membrane deformation during motility, tissue morphogenesis, and the dynamics of active droplets. For instance, they can capture how a crawling cell changes shape and moves by coupling chemical signals to mechanical deformations of the cell membrane.\n\n\n\n\nVicsek model: The foundational model for collective motion where particles move at constant speed and align their direction with neighbors within a certain radius, subject to noise. For example, in simulating bird flocks, each bird adjusts its direction to match the average flight direction of nearby birds, plus some random variation. This simple rule produces rich collective behaviors like the transition from disordered motion at high noise to coordinated flocking at low noise.\nActive Brownian particles: Self-propelled particles that maintain constant speed but undergo rotational diffusion, leading to persistent random walks. A classic example is light-activated Janus colloids - microscopic particles with one hemisphere coated in a light-responsive material. Under illumination, these particles swim in a directed manner but gradually change direction due to thermal fluctuations, resulting in motion that is ballistic at short times but diffusive at long times.\nRun-and-tumble models: These models capture the motion pattern of bacteria like E. coli, which alternate between straight “runs” and random “tumbles.” During runs, the bacteria swim in nearly straight lines using their flagella. Tumbles occur when the flagella bundle comes apart, causing the cell to randomly reorient. This mechanism allows bacteria to effectively explore their environment and respond to chemical gradients through biased random walks.\nActive Ornstein-Uhlenbeck particles: A model incorporating temporal correlations in the active propulsion force, leading to more realistic descriptions of biological swimmers. For instance, in modeling the motion of algae like Chlamydomonas, the swimming force isn’t purely random but shows correlations over the time scale of the flagellar beat cycle. This correlation produces more accurate predictions of diffusion and clustering behaviors compared to simpler active particle models.\n\n\n\n\n\n\n\nThe scientific study of active matter presents several key theoretical and experimental challenges that continue to motivate research and technological innovation in the field:\n\nExperimental challengesTheoretical challenges\n\n\n\nDiversity in propulsion mechanisms and functionality: Creating synthetic active particles with diverse propulsion strategies and functional capabilities remains challenging. Current systems are largely limited to chemical catalysis, light activation, or magnetic actuation. Beyond propulsion, developing particles capable of force generation, information processing, and programmable behaviors through compartmentalization and feedback control is crucial. This includes systems that can adapt their behavior based on environmental cues or machine learning algorithms.\nMulti-component systems: Developing heterogeneous active matter systems with different types of particles that can interact and coordinate. For example, combining light-activated and chemically-powered particles, or integrating passive and active components to create hierarchical structures with emergent behaviors.\nMeasurement techniques: Developing methods to track fast dynamics across multiple scales. Active matter systems often exhibit complex spatiotemporal dynamics that require simultaneous tracking of individual particles and collective behaviors. High-speed imaging, particle tracking, and flow visualization techniques must be adapted to capture both the rapid motion of individual active units and the slower evolution of large-scale patterns.\nSystem preparation: Creating synthetic particles with programmable behaviors and functions. The synthesis of active colloids requires careful control over particle size, shape, surface chemistry, and catalyst distribution, as well as the integration of responsive elements that enable specific functionalities. For instance, incorporating multiple catalytic or stimuli-responsive domains to create particles capable of complex tasks remains technically challenging.\nBoundary conditions: Controlling and characterizing interactions with surfaces. Active matter systems are highly sensitive to boundary conditions, which can significantly influence their behavior. Creating well-defined boundaries while maintaining activity and avoiding unwanted surface effects requires careful experimental design and characterization.\nEnergy input: Maintaining steady, uniform activation across synthetic systems. Whether through chemical fuel concentration, light intensity, magnetic fields, or electric fields, ensuring uniform activation throughout the sample volume is crucial. Challenges include maintaining constant H2O2 concentration for catalytic swimmers or uniform illumination for light-activated particles.\nTime limitations: Managing fuel depletion and particle degradation while maintaining function. Synthetic active systems face challenges like catalyst poisoning, fuel consumption, and photobleaching that can impair their ability to perform desired tasks. For chemical swimmers, local fuel depletion can create concentration gradients that affect particle behavior, while light-activated systems may suffer from photodamage over time.\nImaging limitations: Balancing spatial and temporal resolution with field of view. Active matter often requires both high-resolution imaging to track individual particles and wide-field observation to capture collective effects. This creates technical challenges in microscopy and imaging systems, particularly for three-dimensional systems.\nParameter space: Exploring vast parameter spaces with limited resources. Synthetic active matter systems have many tunable parameters including particle size, shape, surface chemistry, fuel concentration, and external field strengths. Systematically exploring these parameters while maintaining experimental consistency requires significant time and resources.\nSystem integration: Incorporating active matter into functional devices or materials while maintaining desired behaviors. Synthetic active matter experiments require careful integration with other components while preserving activity and function. Creating stable, reliable systems that can operate under real-world conditions presents significant engineering challenges.\n\n\n\n\nBridging scales: Connecting microscopic mechanisms to macroscopic behaviors. Active matter systems often exhibit behaviors across many orders of magnitude in length and time scales, making it challenging to track how molecular-level processes give rise to large-scale collective phenomena. For example, in bacterial colonies, individual cell motility and interactions must be connected to population-level dynamics and pattern formation, requiring sophisticated multi-scale modeling approaches.\nNon-equilibrium statistical mechanics: Developing systematic frameworks beyond equilibrium concepts. Traditional statistical mechanics relies heavily on concepts like detailed balance and the fluctuation-dissipation theorem, which break down in active systems due to continuous energy input. The lack of an energy minimum principle or equivalent organizing framework makes it difficult to develop general theories for non-equilibrium steady states.\nTopological effects: Understanding defect nucleation, motion, and interactions. In active systems, topological defects can spontaneously nucleate, move, and interact in ways fundamentally different from their equilibrium counterparts due to the continuous energy input. The coupling between defect dynamics and active stresses creates complex feedback loops that are challenging to describe theoretically.\nCapturing boundary effects: Modeling how boundaries and confinement influence active dynamics. Active matter systems exhibit unique responses to boundaries that can qualitatively change their behavior, such as accumulation at walls or spontaneous circulation in confined geometries. These boundary effects often depend non-trivially on microscopic details of both the active particles and the confining surfaces.\nIncorporating disorder and heterogeneity: Addressing realistic imperfections in theoretical frameworks. Real active matter systems invariably contain disorder and heterogeneity in particle properties, interactions, and environmental conditions. Incorporating these imperfections while maintaining theoretical tractability requires careful balance between complexity and analytical feasibility.\nCoupling to external fields: Describing responses to gradients, flows, and applied fields. Active matter systems show complex and often counterintuitive responses to external fields, such as negative mobility or upstream swimming in flows. The interplay between internal activity and external forcing creates rich dynamics that challenge our theoretical understanding.\nInformation flow: Quantifying information processing in active biological systems. Biological active matter systems process and respond to information in sophisticated ways, from bacterial chemotaxis to collective decision making in animal groups. Developing theoretical frameworks to quantify and model this information processing remains a major challenge.\nPerception-reaction delays: Biological active matter processes information at rates significantly slower than modern computers due to the inherent limitations of biochemical signaling pathways. These delays between perception and response manifest in various active systems, from human driving behavior in daily traffic to collective animal movement patterns. Such temporal gaps between stimulus detection and behavioral adjustment critically influence numerous dynamical states in active matter. To compensate for this inherent slowness, biological systems have evolved predictive mechanisms that anticipate future states and allow for more effective responses despite processing limitations. Dealing with such delays is a considerable challenge for theoretical modelling.\nPredictive power: Developing theories with quantitative predictive capabilities for experiments. The complexity and non-equilibrium nature of active matter systems often leads to theories that are qualitative rather than quantitative in nature. Making precise, testable predictions requires better understanding of the relevant control parameters and their relationships to observable phenomena.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lecture01/lecture01.html#lecture-1",
    "href": "lecture01/lecture01.html#lecture-1",
    "title": "Introduction to Active Matter",
    "section": "",
    "text": "The study of active matter emerged in the late 20th century at the intersection of soft matter physics, biophysics, and statistical mechanics. An important precursor to the field came from computer graphics, where Craig Reynolds developed the Boids simulation in 1986 - an artificial life program that demonstrated how simple rules governing individual agents could produce realistic flocking behaviors in computer animations. Earlier cellular automata models like Conway’s Game of Life had also shown how simple rules could lead to complex emergent behaviors, helping establish some of the conceptual foundations for understanding collective systems.\n\n\n\n\n\n\n\n\n  \n    Reset Simulation\n  \n  \n    Separation: \n    Alignment: \n    Cohesion: \n  \n\n\n\n\n\n\nFigure 1: Interactive simulation of the Boids model, where you can adjust the three key parameters that govern flocking behavior: separation (avoidance of crowding), alignment (steering towards average heading), and cohesion (steering towards center of mass).\n\n\n\n\n\n\n\n\n\nThe Boids Model Explained\n\n\n\n\n\nThe Boids model, developed by Craig Reynolds in 1986, simulates the flocking behavior of birds using three simple rules:\n\nSeparation: Each boid avoids crowding nearby flockmates, steering away when they get too close.\nAlignment: Each boid aligns its direction of flight with nearby flockmates, matching their average velocity.\nCohesion: Each boid moves toward the center of mass of nearby flockmates, creating a tendency to stick together.\n\nThese local interaction rules, when applied to all individuals simultaneously, produce complex global behaviors that remarkably resemble natural flocking patterns. The simulation above demonstrates how adjusting these three parameters affects the emergent collective motion:\n\nHigh separation, low alignment, low cohesion: Dispersed individuals with minimal coordination\nLow separation, high alignment, medium cohesion: Coherent flocking with directional movement\nBalanced parameters: Natural-looking flocking behaviors with dynamic subgroup formation\n\nThis model illustrates a fundamental principle in active matter physics: complex collective behaviors can emerge from simple local rules without centralized control.\n\n\n\nThis computational model later influenced physical approaches to collective motion. Early foundational work by scientists like T. Vicsek in the 1990s established computational models for collective motion, particularly his 1995 paper introducing what is now known as the Vicsek model for self-propelled particles with alignment interactions. Prior to this, early biological observations of collective behaviors in nature, such as bird flocking and fish schooling, had long fascinated scientists but lacked rigorous physical frameworks. The field gained significant momentum in the late 1990swith seminal papers by John Toner and Yuhai Tu, who published their groundbreaking work on flocking theory in 1995, and later Sriram Ramaswamy who developed continuum theories for active nematics.\nThe theoretical foundations were further strengthened by contributions from European researchers like Michael Cates (Edinburgh), Jean-François Joanny (Paris), and Jacques Prost (Paris), who developed the active gel theory to describe cytoskeletal dynamics in the mid-2000s. Simultaneously, M. Cristina Marchetti and her collaborators formulated comprehensive hydrodynamic theories for active systems across various symmetry classes. Sriram Ramaswamy made fundamental contributions through his work on active liquid crystals and the development of generic hydrodynamic theories for active matter. The pioneering work of John Toner and Yuhai Tu established the theoretical framework for understanding the emergence of long-range order in flocking systems, demonstrating how activity can stabilize orientational order even in two dimensions. Julia Yeomans (Oxford) advanced our understanding of active turbulence and topological defects in active nematics through innovative computational approaches, while Hartmut Löwen (Düsseldorf) developed influential theories for the collective behavior of active Brownian particles and motility-induced phase separation. These theoretical advances were complemented by experimental breakthroughs, notably Howard Berg’s groundbreaking work in the 1970s at Harvard on bacterial chemotaxis and motility, where he developed the tracking microscope to follow individual E. coli bacteria and discovered their run-and-tumble motion patterns. Additional experimental contributions came from Raymond Goldstein (Cambridge) and others who established quantitative measurements of collective motion in bacterial systems.\nExperimental breakthroughs with bacterial suspensions (notably work by Igor Aranson and Raymond Goldstein on Bacillus subtilis), cell tissues (including Xavier Trepat’s research at IBEC in Barcelona on epithelial cell sheets), and synthetic active colloids (pioneered by European researchers like Jérémie Palacci (Lyon/San Diego), Julien Perrin (Paris), and Clemens Bechinger (Konstanz/Stuttgart) with light-activated Janus particles) further propelled the field forward. The development of artificial microswimmers by international collaborations involving European teams led by Roberto Di Leonardo (Rome), Ramin Golestanian (Oxford/Göttingen), and Frank Cichos (Leipzig), alongside US-based researchers like Steve Granick and Ayusman Sen, opened new avenues for creating controllable active systems outside biological contexts.\nBy the 2010s, active matter had developed into a distinct discipline with dedicated conferences and research groups worldwide. The establishment of specialized research centers across Europe such as the Max Planck Institute for Dynamics and Self-Organization in Göttingen, the Physics of Living Matter Group at Cambridge, the Biological Physics and Morphogenesis groups at MPIPKS Dresden, alongside the Syracuse Soft and Living Matter Program, the Center for the Physics of Biological Function at Princeton, and the Active Matter Lab at MIT reflected the field’s growing importance. Major milestones included the observation of motility-induced phase separation by Michael Cates (Edinburgh) and Julien Tailleur (Paris) (2013), the discovery of topological defect motility in active nematics by Zvonimir Dogic and collaborators (2014), and the creation of the first autonomous active material capable of performing work by Daniela Wilson’s group (Nijmegen) (2019). The field continues to expand with increasing interdisciplinary collaborations between physicists, biologists, materials scientists, and engineers, addressing fundamental questions in non-equilibrium physics while developing applications in biomedicine, soft robotics, and smart materials.\n\n\n\nUnderstanding how active matter systems differ from equilibrium systems is crucial for developing new theoretical frameworks and experimental approaches. The continuous energy input and self-driven nature of active matter leads to behaviors that challenge our traditional physics understanding. Consider the following key distinctions between equilibrium and active matter systems:\n\n\n\n\n\n\n\n\nFeature\nEquilibrium Systems\nActive Matter Systems\n\n\n\n\nDetailed Balance\nForward and reverse processes occur at equal rates\nContinuously broken through energy consumption, driving the system away from equilibrium\n\n\nFluctuation-Dissipation Theorem\nValid relationship between spontaneous fluctuations and response to external perturbations\nBreaks down as fluctuations can be driven by internal activity\n\n\nParticle Motion\nRandom Brownian motion\nPersistent directional motion over certain timescales\n\n\nStatistical Distributions\nFollow Boltzmann statistics\nNon-Boltzmann statistics, making standard thermodynamic tools inapplicable\n\n\nMacroscopic Currents\nAbsent in steady states\nCan sustain macroscopic currents and flux cycles even in steady states\n\n\nPhase Behavior\nWell-established equilibrium phases\nUnique phase transitions with no equilibrium counterparts (e.g., motility-induced phase separation, active turbulence)\n\n\nMechanical Pressure\nIndependent of boundary properties\nCan depend on properties of confining walls, violating equilibrium equations of state\n\n\nEnergy and Entropy\nMinimize free energy, maximize entropy\nContinuously dissipate energy and produce entropy even in steady states\n\n\nTime-Reversal Symmetry\nDynamics appear similar when played forward or backward\nDynamics look distinctly different when played forward versus backward\n\n\nForce Characteristics\nDerivable from a potential energy function\nCannot generally be derived from a potential energy function\n\n\n\n\n\n\nActive matter encompasses a diverse range of systems, from biological organisms to synthetic particles, that share the common feature of continuously converting energy into systematic motion. These systems can be organized into several categories based on their energy sources, symmetries, and the nature of their interactions, providing a framework for understanding their distinct behaviors and properties.\n\n\n\n\n\n\nFigure 2: Overview of active matter systems at different scales and domains. The field spans from microscopic biological systems like cellular components to macroscopic collective behaviors and engineered synthetic systems. (source)\n\n\n\nActive matter systems can be categorized based on several key characteristics:\n\nEnergy conversion mechanismSymmetry of motionMedium and interactionsStructural arrangementLength scale and dimensionality\n\n\n\nBiological active matter: Systems that convert chemical energy (ATP, nutrients) into mechanical work (e.g., bacteria, cells, tissues). These systems span multiple scales, from molecular motors like kinesin and myosin that transport cargo along cytoskeletal filaments, to cellular components such as the dynamic cytoskeleton that enables cell shape changes and migration. At multicellular scales, coordinated activity enables tissue morphogenesis during development, wound healing, and collective cell migration. The energy conversion typically involves ATP hydrolysis, which provides approximately 20 kT of energy per molecule, enabling these systems to perform work against thermal fluctuations. Unlike their synthetic counterparts, biological active matter often exhibits adaptive behaviors, feedback regulation, and hierarchical organization that enhances functionality and robustness.\n\n\n\n\n\n\n\n\n\nATP hydrolysis is the primary energy source in most cellular processes\n\n\n\n\n\n\n\nBacteria like E. coli use flagella powered by molecular motors\n\n\n\n\n\n\nFigure 3: ATP hydrolysis and bacterial motility represent key examples of chemical energy conversion in biological active matter\n\n\n\n\nSynthetic active matter: Engineered systems powered by external fields, chemical reactions, or light (e.g., Janus particles, active colloids). These artificial systems represent human-designed analogs to biological active matter, with scientists having precise control over their properties and behaviors. Synthetic active particles typically feature asymmetric structures or surface properties that enable self-propulsion. Common examples include Janus particles with catalyst-coated hemispheres that decompose hydrogen peroxide to create propulsion, light-activated particles that convert photonic energy into motion, and magnetically-actuated microswimmers that respond to oscillating external fields. Unlike biological systems, synthetic active matter can be designed with specific functionalities, such as targeted drug delivery, environmental remediation, or self-assembly into complex structures. Recent advances have produced programmable behaviors through responsive materials, feedback mechanisms, and even rudimentary “communication” between synthetic active agents.\n\n\n\n\n\n\n\nFigure 4: Synthetic active particles can be designed with asymmetric properties to enable self-propulsion through various mechanisms\n\n\n\n\n\n\nPolar active matter: Entities with defined front-back asymmetry and directional motion (e.g., birds, fish). These systems are characterized by particles or organisms that have a clear direction of motion and can align their movement with neighbors. For example, fish schools demonstrate this through their streamlined body shape that defines a clear swimming direction, while their lateral line system helps them align with neighboring fish. Similarly, migratory birds show polar order through their aerodynamic body structure and visual alignment with flock-mates during flight. At the microscopic scale, many bacteria like E. coli exhibit polar motion through their flagellar propulsion system that creates directed swimming. The polar nature of these systems often leads to unique collective phenomena like the emergence of large-scale coherent motion and the formation of traveling bands or density waves.\n\n\n\n\n\n\n\n\n\nFish schools demonstrate collective motion through simple alignment rules\n\n\n\n\n\n\n\nBird flocks exhibit emergent order through local interactions\n\n\n\n\n\n\nFigure 5: Examples of polar active matter: fish schools (source) and bird flocks (source)\n\n\n\n\nApolar active matter: Systems generating motion without a defined direction (e.g., melanocytes, active nematics). These systems exhibit interesting collective behaviors despite lacking a preferred direction of motion at the individual level. For example, melanocytes, the cells responsible for skin pigmentation, extend and retract protrusions in multiple directions as they move and distribute melanin. Similarly, active nematics, such as dense suspensions of microtubules and molecular motors, generate complex flows and defect dynamics without any preferred direction of motion for individual components. The apolar nature of these systems often leads to unique phenomena like the spontaneous formation and annihilation of topological defects, and the emergence of active turbulence in confined geometries.\n\n\n\n\n\n\n\n\n\nMelanocyte cells showing apolar migration patterns\n\n\n\n\n\n\n\nActive nematic liquid crystals with defect patterns\n\n\n\n\n\n\nFigure 6: Examples of apolar active matter: melanocytes (source) and active nematics (source)\n\n\n\n\nChiral active matter: Systems with inherent rotational motion or handedness. These systems exhibit systematic rotational motion in addition to translational movement, often due to structural asymmetry or biased force generation. Examples include bacterial flagella that rotate to create propulsion, sperm cells that swim with helical trajectories, and synthetic microswimmers with chiral shapes that spin as they move through fluid. The interplay between rotational and translational motion in these systems can lead to unique collective behaviors, such as the formation of rotating clusters or vortex arrays. At the microscopic scale, molecular motors like the bacterial flagellar motor demonstrate how nature utilizes chirality to generate motion, while at larger scales, schools of fish can form rotating vortex patterns through their collective swimming behavior.\n\n\n\n\nDry active matter: Systems where momentum dissipates to a substrate (e.g., cells on surfaces). In these systems, the primary interaction between particles occurs through direct contact or short-range forces, as the substrate quickly dampens any long-range hydrodynamic effects. A classic example is cells crawling on a surface, where the friction with the substrate dominates the dynamics. Another example is vibrated granular layers, where energy input causes particle motion but momentum is quickly dissipated through collisions with the base plate and between particles.\nWet active matter: Systems embedded in a fluid where hydrodynamic interactions dominate (e.g., bacterial suspensions). These systems exhibit complex long-range interactions mediated by the fluid, as the motion of each active particle creates flow fields that affect distant particles. Examples include swimming microorganisms in water, where the fluid flows generated by one organism can influence the motion of others several body lengths away. Active colloids in suspension also demonstrate these effects, where the chemical activity or motion of particles creates fluid flows that lead to collective behaviors and pattern formation.\n\n\n\n\nActive crystals: Ordered lattice-like arrangements with activity. These systems maintain crystalline order while individual units remain active, such as in bacterial colonies that form regular spatial patterns while each bacterium continues to move and metabolize. A key example is the formation of living crystals from light-activated colloidal particles, where the particles self-organize into a crystalline lattice while maintaining their individual motility.\nActive glasses: Disordered, jammed configurations with activity. Unlike traditional glasses, these systems combine structural disorder with persistent local motion, leading to unique dynamical behaviors. Examples include dense bacterial suspensions at high concentrations where cells become trapped in disordered configurations but continue to exert active forces on their neighbors, or crowded solutions of motor proteins and filaments where steric constraints create glassy dynamics despite ongoing ATP-driven activity.\nActive fluids/gases: Flowing systems with active components. These systems exhibit fluid-like behavior but with constituents that continuously inject energy at the microscopic scale. Examples range from dilute bacterial suspensions that show enhanced diffusion and collective motion, to dense active liquid crystals where the interplay between flow and orientational order creates complex dynamical patterns like active turbulence. In the gas-like regime, systems like midge swarms demonstrate how active particles can maintain cohesion while exhibiting fluid-like properties.\n\n\n\n\nMicroscopic: Cellular and subcellular systems (cytoskeleton, bacterial colonies). At this scale, active matter emerges from molecular motors like kinesin and dynein walking along cytoskeletal filaments, or the collective motion of bacterial cells in colonies. The cytoskeleton itself is a fascinating example where networks of actin filaments and microtubules, driven by ATP-powered molecular motors, create complex dynamics essential for cell function and division.\nMesoscopic: Tissue and organ-level organizations. At the tissue level, collective cell behavior leads to emergent phenomena like wound healing and morphogenesis during development. Epithelial tissues demonstrate active matter dynamics through coordinated cell migration and mechanical force transmission between neighboring cells. These intermediate scales bridge individual cell behavior with organ-level function.\n\n\n\n\n\n\n\nFigure 7: Time-lapse microscopy of Drosophila embryo development showing gastrulation and tissue folding - a striking example of how active matter principles govern morphogenesis. The coordinated cell shape changes and movements create complex three-dimensional structures from an initially simple tissue sheet. source\n\n\n\n\nMacroscopic: Animal groups, human crowds. Large-scale collective behaviors emerge in systems like bird flocks, fish schools, and human crowds in urban environments. These systems demonstrate how simple interaction rules between individuals can create complex, coordinated motion patterns that span hundreds or thousands of times the size of individual agents. Traffic flow and pedestrian dynamics are particularly relevant examples for urban planning and crowd safety.\nQuasi-2D vs. 3D systems: Systems confined to surfaces vs. fully three-dimensional systems. Many active matter systems are effectively two-dimensional, like bacterial colonies growing on agar plates or cells migrating on substrates. These confined geometries often simplify both experimental observation and theoretical analysis. In contrast, true three-dimensional systems like bacterial suspensions in fluid or cell movement in tissue matrices exhibit additional complexities due to hydrodynamic interactions and the full range of possible motion directions.\n\n\n\n\n\n\n\nThe theoretical description of active matter draws from and extends multiple branches of physics:\n\nKinetic theoriesContinuum field theoriesAgent-based and particle models\n\n\n\nBoltzmann-like approaches: Describing probability distributions of particle positions and orientations in active systems. For example, in bacterial suspensions, this approach tracks how the probability of finding bacteria with specific positions and swimming directions evolves over time. The key difference from classical Boltzmann equations is the inclusion of self-propulsion forces and alignment interactions. These equations have been particularly successful in describing the transition from disordered to ordered states in active systems like bird flocks and fish schools.\nFokker-Planck equations: Capturing the evolution of probability densities in phase space by incorporating both deterministic and stochastic effects. In active matter, these equations describe how probability distributions change due to systematic forces (like self-propulsion), random fluctuations (thermal or active noise), and interactions between particles. For instance, they can model how Janus particles move under the influence of chemical gradients while experiencing rotational diffusion, or how swimming bacteria respond to chemical attractants while subject to tumbling events.\nSmoluchowski equations: Modeling overdamped dynamics common in biological active systems where inertial effects are negligible compared to viscous forces. These equations are particularly relevant for microscopic swimmers like bacteria or colloidal particles where the Reynolds number is very small. They have been successfully applied to describe phenomena like bacterial chemotaxis, the collective motion of cell populations, and the dynamics of motor proteins along cytoskeletal filaments. A classic example is modeling E. coli’s run-and-tumble motion, where the Smoluchowski equation – the overdamped limit of the Fokker-Planck equation – captures the interplay between directed swimming and random reorientations.\n\n\n\n\nToner-Tu theory: A hydrodynamic framework that describes collective motion in flocking systems by incorporating broken continuous symmetry. This theory is particularly powerful for analyzing large systems, where it predicts true long-range order can exist even in two dimensions, in contrast to equilibrium systems. While real flocks are finite, the theory provides insights into large-scale behaviors like the scale-free correlations observed in starling murmurations, where thousands of birds maintain coherent motion despite environmental perturbations.\nActive gel theories: These theories extend traditional liquid crystal physics by incorporating force-generating active stresses. They are particularly successful in describing biological materials like the cell cytoskeleton, where molecular motors generate internal forces. A key example is explaining the spontaneous flows observed in actomyosin networks, where myosin motors walking along actin filaments create large-scale coherent motion.\nActive nematics: Field theories that describe systems with orientational order but no polar direction, driven out of equilibrium by active stresses. These theories have been instrumental in understanding phenomena like the chaotic dynamics of microtubule-kinesin mixtures, where energy input from molecular motors leads to the continuous creation, motion, and annihilation of topological defects, resulting in active turbulence.\nPhase field models: Mathematical frameworks that track the evolution of interfaces and boundaries in active systems without explicitly tracking individual particles. These models have been successfully applied to describe phenomena like cell membrane deformation during motility, tissue morphogenesis, and the dynamics of active droplets. For instance, they can capture how a crawling cell changes shape and moves by coupling chemical signals to mechanical deformations of the cell membrane.\n\n\n\n\nVicsek model: The foundational model for collective motion where particles move at constant speed and align their direction with neighbors within a certain radius, subject to noise. For example, in simulating bird flocks, each bird adjusts its direction to match the average flight direction of nearby birds, plus some random variation. This simple rule produces rich collective behaviors like the transition from disordered motion at high noise to coordinated flocking at low noise.\nActive Brownian particles: Self-propelled particles that maintain constant speed but undergo rotational diffusion, leading to persistent random walks. A classic example is light-activated Janus colloids - microscopic particles with one hemisphere coated in a light-responsive material. Under illumination, these particles swim in a directed manner but gradually change direction due to thermal fluctuations, resulting in motion that is ballistic at short times but diffusive at long times.\nRun-and-tumble models: These models capture the motion pattern of bacteria like E. coli, which alternate between straight “runs” and random “tumbles.” During runs, the bacteria swim in nearly straight lines using their flagella. Tumbles occur when the flagella bundle comes apart, causing the cell to randomly reorient. This mechanism allows bacteria to effectively explore their environment and respond to chemical gradients through biased random walks.\nActive Ornstein-Uhlenbeck particles: A model incorporating temporal correlations in the active propulsion force, leading to more realistic descriptions of biological swimmers. For instance, in modeling the motion of algae like Chlamydomonas, the swimming force isn’t purely random but shows correlations over the time scale of the flagellar beat cycle. This correlation produces more accurate predictions of diffusion and clustering behaviors compared to simpler active particle models.\n\n\n\n\n\n\n\nThe scientific study of active matter presents several key theoretical and experimental challenges that continue to motivate research and technological innovation in the field:\n\nExperimental challengesTheoretical challenges\n\n\n\nDiversity in propulsion mechanisms and functionality: Creating synthetic active particles with diverse propulsion strategies and functional capabilities remains challenging. Current systems are largely limited to chemical catalysis, light activation, or magnetic actuation. Beyond propulsion, developing particles capable of force generation, information processing, and programmable behaviors through compartmentalization and feedback control is crucial. This includes systems that can adapt their behavior based on environmental cues or machine learning algorithms.\nMulti-component systems: Developing heterogeneous active matter systems with different types of particles that can interact and coordinate. For example, combining light-activated and chemically-powered particles, or integrating passive and active components to create hierarchical structures with emergent behaviors.\nMeasurement techniques: Developing methods to track fast dynamics across multiple scales. Active matter systems often exhibit complex spatiotemporal dynamics that require simultaneous tracking of individual particles and collective behaviors. High-speed imaging, particle tracking, and flow visualization techniques must be adapted to capture both the rapid motion of individual active units and the slower evolution of large-scale patterns.\nSystem preparation: Creating synthetic particles with programmable behaviors and functions. The synthesis of active colloids requires careful control over particle size, shape, surface chemistry, and catalyst distribution, as well as the integration of responsive elements that enable specific functionalities. For instance, incorporating multiple catalytic or stimuli-responsive domains to create particles capable of complex tasks remains technically challenging.\nBoundary conditions: Controlling and characterizing interactions with surfaces. Active matter systems are highly sensitive to boundary conditions, which can significantly influence their behavior. Creating well-defined boundaries while maintaining activity and avoiding unwanted surface effects requires careful experimental design and characterization.\nEnergy input: Maintaining steady, uniform activation across synthetic systems. Whether through chemical fuel concentration, light intensity, magnetic fields, or electric fields, ensuring uniform activation throughout the sample volume is crucial. Challenges include maintaining constant H2O2 concentration for catalytic swimmers or uniform illumination for light-activated particles.\nTime limitations: Managing fuel depletion and particle degradation while maintaining function. Synthetic active systems face challenges like catalyst poisoning, fuel consumption, and photobleaching that can impair their ability to perform desired tasks. For chemical swimmers, local fuel depletion can create concentration gradients that affect particle behavior, while light-activated systems may suffer from photodamage over time.\nImaging limitations: Balancing spatial and temporal resolution with field of view. Active matter often requires both high-resolution imaging to track individual particles and wide-field observation to capture collective effects. This creates technical challenges in microscopy and imaging systems, particularly for three-dimensional systems.\nParameter space: Exploring vast parameter spaces with limited resources. Synthetic active matter systems have many tunable parameters including particle size, shape, surface chemistry, fuel concentration, and external field strengths. Systematically exploring these parameters while maintaining experimental consistency requires significant time and resources.\nSystem integration: Incorporating active matter into functional devices or materials while maintaining desired behaviors. Synthetic active matter experiments require careful integration with other components while preserving activity and function. Creating stable, reliable systems that can operate under real-world conditions presents significant engineering challenges.\n\n\n\n\nBridging scales: Connecting microscopic mechanisms to macroscopic behaviors. Active matter systems often exhibit behaviors across many orders of magnitude in length and time scales, making it challenging to track how molecular-level processes give rise to large-scale collective phenomena. For example, in bacterial colonies, individual cell motility and interactions must be connected to population-level dynamics and pattern formation, requiring sophisticated multi-scale modeling approaches.\nNon-equilibrium statistical mechanics: Developing systematic frameworks beyond equilibrium concepts. Traditional statistical mechanics relies heavily on concepts like detailed balance and the fluctuation-dissipation theorem, which break down in active systems due to continuous energy input. The lack of an energy minimum principle or equivalent organizing framework makes it difficult to develop general theories for non-equilibrium steady states.\nTopological effects: Understanding defect nucleation, motion, and interactions. In active systems, topological defects can spontaneously nucleate, move, and interact in ways fundamentally different from their equilibrium counterparts due to the continuous energy input. The coupling between defect dynamics and active stresses creates complex feedback loops that are challenging to describe theoretically.\nCapturing boundary effects: Modeling how boundaries and confinement influence active dynamics. Active matter systems exhibit unique responses to boundaries that can qualitatively change their behavior, such as accumulation at walls or spontaneous circulation in confined geometries. These boundary effects often depend non-trivially on microscopic details of both the active particles and the confining surfaces.\nIncorporating disorder and heterogeneity: Addressing realistic imperfections in theoretical frameworks. Real active matter systems invariably contain disorder and heterogeneity in particle properties, interactions, and environmental conditions. Incorporating these imperfections while maintaining theoretical tractability requires careful balance between complexity and analytical feasibility.\nCoupling to external fields: Describing responses to gradients, flows, and applied fields. Active matter systems show complex and often counterintuitive responses to external fields, such as negative mobility or upstream swimming in flows. The interplay between internal activity and external forcing creates rich dynamics that challenge our theoretical understanding.\nInformation flow: Quantifying information processing in active biological systems. Biological active matter systems process and respond to information in sophisticated ways, from bacterial chemotaxis to collective decision making in animal groups. Developing theoretical frameworks to quantify and model this information processing remains a major challenge.\nPerception-reaction delays: Biological active matter processes information at rates significantly slower than modern computers due to the inherent limitations of biochemical signaling pathways. These delays between perception and response manifest in various active systems, from human driving behavior in daily traffic to collective animal movement patterns. Such temporal gaps between stimulus detection and behavioral adjustment critically influence numerous dynamical states in active matter. To compensate for this inherent slowness, biological systems have evolved predictive mechanisms that anticipate future states and allow for more effective responses despite processing limitations. Dealing with such delays is a considerable challenge for theoretical modelling.\nPredictive power: Developing theories with quantitative predictive capabilities for experiments. The complexity and non-equilibrium nature of active matter systems often leads to theories that are qualitative rather than quantitative in nature. Making precise, testable predictions requires better understanding of the relevant control parameters and their relationships to observable phenomena.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 1"
    ]
  },
  {
    "objectID": "course-info/schedule.html",
    "href": "course-info/schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This course is a master course in physics to introduce into the field of active matter. The course is comprising a series of lectures and exercise sessions, which allow students to apply the concepts learned in the lectures to real-world problems.\nThe lectures will take place in person every\nThursday, 9:15 AM SR 224\nstarting April 10th.\nThe seminars will take place in person every\nThursday, 11:00 AM SR 224\nstarting April 1Xth.\nThe exam will be oral and dates witll be provided during the lecture period.",
    "crumbs": [
      "Course Info",
      "Course Schedule"
    ]
  },
  {
    "objectID": "course-info/resources.html",
    "href": "course-info/resources.html",
    "title": "Resources",
    "section": "",
    "text": "Books on Soft Matter\n\nJacob N. Israelachvili: Intermolecular and Surface Forces: With Applications to Colloidal and Biological Systems (Academic Press)\nRob Phillips, Jane Kondev, Julie Theriot: Physical Biology of the Cell (Garland Science)\nRichard A.L. Jones: Soft Condensed Matter (Oxford University Press)\nMichael Rubinstein, Ralph H. Colby: Polymer Physics (Oxford University Press)\nJonathan Howard: Mechanics of Motor Proteins and the Cytoskeleton (Sinauer Associates)\nM. Doi and S.F. Edwards: The Theory of Polymer Dynamics (Oxford Academic Press)\nP.G. de Gennes and J. Prost: The Physics of Liquid Crystals (Oxford Academic Press)\n\n\n\nThe Active Matter Book\n\nActive Matter Book",
    "crumbs": [
      "Course Info",
      "Resources"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is the Active Matter Physics website."
  },
  {
    "objectID": "lecture02/entropy_and_time_reversal.html",
    "href": "lecture02/entropy_and_time_reversal.html",
    "title": "Entropy and Time Reversal",
    "section": "",
    "text": "Entropy production lies at the heart of non-equilibrium thermodynamics and provides a quantitative measure of how far a system is driven from equilibrium. While equilibrium systems maximize their entropy and remain there, active systems continuously produce entropy, reflecting their persistent consumption of energy to maintain non-equilibrium steady states.\n\n\nThe total entropy production rate can be split into two contributions:\n\\[\\dot{S}_{tot} = \\dot{S}_{sys} + \\dot{S}_{env}\\]\nwhere \\(\\dot{S}_{sys}\\) is the rate of change of the system’s Shannon entropy and \\(\\dot{S}_{env}\\) is the entropy production rate in the environment. In a steady state, \\(\\dot{S}_{sys} = 0\\), so \\(\\dot{S}_{tot} = \\dot{S}_{env} &gt; 0\\).\nFor a system described by a probability distribution \\(P(\\mathbf{x},t)\\) over states \\(\\mathbf{x}\\), the entropy production rate can be expressed as:\n\\[\\dot{S}_{tot} = k_B \\int d\\mathbf{x} \\, J(\\mathbf{x},t) \\cdot F(\\mathbf{x},t) \\geq 0\\]\nwhere \\(J(\\mathbf{x},t)\\) is the probability current and \\(F(\\mathbf{x},t)\\) is the thermodynamic force. This formula reveals a profound insight: entropy production occurs when probability currents flow along thermodynamic forces.\n\n\n\nThe probability currents we observed in our examples—the two Brownian particles with different temperatures and the Chlamydomonas flagella—directly contribute to entropy production. In fact, these circulatory flows in phase space are not just signatures of non-equilibrium behavior; they quantify the system’s entropy production rate.\nFor Brownian dynamics in the overdamped regime, the entropy production rate can be written as:\n\\[\\dot{S}_{tot} = \\frac{k_B}{\\gamma} \\int d\\mathbf{x} \\, \\frac{|J(\\mathbf{x})|^2}{P(\\mathbf{x})}\\]\nThis expression makes a remarkable connection: the entropy production rate is proportional to the squared magnitude of the probability current density normalized by the probability distribution. Systems with stronger circulation in probability space produce entropy at a higher rate.\n\n\n\n\n\n\nFigure 1: Entropy production in a non-equilibrium system. Left: Probability distribution and currents in phase space. Right: The local entropy production rate, showing the highest values where currents flow through regions of low probability. [source: schematic representation]\n\n\n\n\n\n\nHow can we actually measure entropy production in experiment? Several approaches have been developed:\n\nCurrent-based methods: By measuring the probability density and current as in our examples with two Brownian particles and Chlamydomonas, we can directly compute the entropy production using the formula above.\nTrajectory-based methods: For single-particle tracking data, the entropy production can be estimated by:\n\\[\\dot{S}_{est} = \\frac{1}{4\\tau} \\sum_i \\left\\langle \\left( \\frac{p(x_i \\to x_{i+1})}{p(x_{i+1} \\to x_i)} \\right) \\right\\rangle\\]\nwhere \\(p(x_i \\to x_{i+1})\\) represents the transition probability between states observed in the trajectory.\nTime asymmetry methods: By quantifying the statistical irreversibility of trajectories:\n\\[\\dot{S}_{est} = \\frac{k_B}{\\tau} D_{KL}(P[X(t)] || P[\\tilde{X}(t)])\\]\nwhere \\(D_{KL}\\) is the Kullback-Leibler divergence between the probability distributions of forward trajectories \\(X(t)\\) and time-reversed trajectories \\(\\tilde{X}(t)\\).\n\n\n\n\nDifferent active systems show distinctive patterns of entropy production:\n\nSelf-propelled particles: For active Brownian particles with persistent motion, entropy production scales with the square of the active force and inversely with the rotational diffusion coefficient:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B v_0^2}{2D_r}\\]\nwhere \\(v_0\\) is the swimming speed and \\(D_r\\) is the rotational diffusion coefficient.\nMolecular motors: For molecular motors like kinesin or myosin, entropy production is directly linked to ATP hydrolysis:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B \\Delta\\mu}{k_B T} r_{ATP}\\]\nwhere \\(\\Delta\\mu\\) is the chemical potential difference from ATP hydrolysis and \\(r_{ATP}\\) is the ATP consumption rate.\nTissue dynamics: In cellular tissues, entropy production has been linked to cell division, death, and migration processes. Recent studies have used optically-driven phase transitions to quantify entropy production in living tissues.\n\n\n\n\nIn contrast to the maximum entropy principle of equilibrium systems, some non-equilibrium steady states follow a principle of minimum entropy production, where the system adopts the configuration that produces entropy at the minimum rate required to maintain its non-equilibrium state.\nHowever, active matter systems typically operate far from the near-equilibrium regime where this principle applies. Instead, they exist in regimes of strong driving where entropy production can be significant and is often channeled into performing useful functions like motility, transport, or pattern formation."
  },
  {
    "objectID": "lecture02/entropy_and_time_reversal.html#entropy-production-in-active-systems",
    "href": "lecture02/entropy_and_time_reversal.html#entropy-production-in-active-systems",
    "title": "Entropy and Time Reversal",
    "section": "",
    "text": "Entropy production lies at the heart of non-equilibrium thermodynamics and provides a quantitative measure of how far a system is driven from equilibrium. While equilibrium systems maximize their entropy and remain there, active systems continuously produce entropy, reflecting their persistent consumption of energy to maintain non-equilibrium steady states.\n\n\nThe total entropy production rate can be split into two contributions:\n\\[\\dot{S}_{tot} = \\dot{S}_{sys} + \\dot{S}_{env}\\]\nwhere \\(\\dot{S}_{sys}\\) is the rate of change of the system’s Shannon entropy and \\(\\dot{S}_{env}\\) is the entropy production rate in the environment. In a steady state, \\(\\dot{S}_{sys} = 0\\), so \\(\\dot{S}_{tot} = \\dot{S}_{env} &gt; 0\\).\nFor a system described by a probability distribution \\(P(\\mathbf{x},t)\\) over states \\(\\mathbf{x}\\), the entropy production rate can be expressed as:\n\\[\\dot{S}_{tot} = k_B \\int d\\mathbf{x} \\, J(\\mathbf{x},t) \\cdot F(\\mathbf{x},t) \\geq 0\\]\nwhere \\(J(\\mathbf{x},t)\\) is the probability current and \\(F(\\mathbf{x},t)\\) is the thermodynamic force. This formula reveals a profound insight: entropy production occurs when probability currents flow along thermodynamic forces.\n\n\n\nThe probability currents we observed in our examples—the two Brownian particles with different temperatures and the Chlamydomonas flagella—directly contribute to entropy production. In fact, these circulatory flows in phase space are not just signatures of non-equilibrium behavior; they quantify the system’s entropy production rate.\nFor Brownian dynamics in the overdamped regime, the entropy production rate can be written as:\n\\[\\dot{S}_{tot} = \\frac{k_B}{\\gamma} \\int d\\mathbf{x} \\, \\frac{|J(\\mathbf{x})|^2}{P(\\mathbf{x})}\\]\nThis expression makes a remarkable connection: the entropy production rate is proportional to the squared magnitude of the probability current density normalized by the probability distribution. Systems with stronger circulation in probability space produce entropy at a higher rate.\n\n\n\n\n\n\nFigure 1: Entropy production in a non-equilibrium system. Left: Probability distribution and currents in phase space. Right: The local entropy production rate, showing the highest values where currents flow through regions of low probability. [source: schematic representation]\n\n\n\n\n\n\nHow can we actually measure entropy production in experiment? Several approaches have been developed:\n\nCurrent-based methods: By measuring the probability density and current as in our examples with two Brownian particles and Chlamydomonas, we can directly compute the entropy production using the formula above.\nTrajectory-based methods: For single-particle tracking data, the entropy production can be estimated by:\n\\[\\dot{S}_{est} = \\frac{1}{4\\tau} \\sum_i \\left\\langle \\left( \\frac{p(x_i \\to x_{i+1})}{p(x_{i+1} \\to x_i)} \\right) \\right\\rangle\\]\nwhere \\(p(x_i \\to x_{i+1})\\) represents the transition probability between states observed in the trajectory.\nTime asymmetry methods: By quantifying the statistical irreversibility of trajectories:\n\\[\\dot{S}_{est} = \\frac{k_B}{\\tau} D_{KL}(P[X(t)] || P[\\tilde{X}(t)])\\]\nwhere \\(D_{KL}\\) is the Kullback-Leibler divergence between the probability distributions of forward trajectories \\(X(t)\\) and time-reversed trajectories \\(\\tilde{X}(t)\\).\n\n\n\n\nDifferent active systems show distinctive patterns of entropy production:\n\nSelf-propelled particles: For active Brownian particles with persistent motion, entropy production scales with the square of the active force and inversely with the rotational diffusion coefficient:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B v_0^2}{2D_r}\\]\nwhere \\(v_0\\) is the swimming speed and \\(D_r\\) is the rotational diffusion coefficient.\nMolecular motors: For molecular motors like kinesin or myosin, entropy production is directly linked to ATP hydrolysis:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B \\Delta\\mu}{k_B T} r_{ATP}\\]\nwhere \\(\\Delta\\mu\\) is the chemical potential difference from ATP hydrolysis and \\(r_{ATP}\\) is the ATP consumption rate.\nTissue dynamics: In cellular tissues, entropy production has been linked to cell division, death, and migration processes. Recent studies have used optically-driven phase transitions to quantify entropy production in living tissues.\n\n\n\n\nIn contrast to the maximum entropy principle of equilibrium systems, some non-equilibrium steady states follow a principle of minimum entropy production, where the system adopts the configuration that produces entropy at the minimum rate required to maintain its non-equilibrium state.\nHowever, active matter systems typically operate far from the near-equilibrium regime where this principle applies. Instead, they exist in regimes of strong driving where entropy production can be significant and is often channeled into performing useful functions like motility, transport, or pattern formation."
  },
  {
    "objectID": "lecture02/entropy_and_time_reversal.html#time-reversal-symmetry-breaking",
    "href": "lecture02/entropy_and_time_reversal.html#time-reversal-symmetry-breaking",
    "title": "Entropy and Time Reversal",
    "section": "Time-reversal symmetry breaking",
    "text": "Time-reversal symmetry breaking\nTime-reversal symmetry is a fundamental concept describing whether the laws governing a system’s dynamics are invariant under the transformation \\(t \\to -t\\). While microscopic physical laws are largely time-reversal invariant, macroscopic behaviors often show a clear arrow of time due to statistical considerations embodied in the second law of thermodynamics.\n\nFormal definition\nA system has time-reversal symmetry if the probability of observing a trajectory \\(\\Gamma = \\{x(t_0), x(t_1), ..., x(t_N)\\}\\) equals the probability of observing the reversed trajectory \\(\\tilde{\\Gamma} = \\{x(t_N), x(t_{N-1}), ..., x(t_0)\\}\\) when appropriately accounting for the initial conditions:\n\\[P[\\Gamma|x(t_0)] = P[\\tilde{\\Gamma}|x(t_N)]\\]\nIn equilibrium systems, this symmetry is guaranteed by detailed balance. However, active systems break this symmetry, leading to trajectories that look fundamentally different when viewed forward versus backward in time.\n\n\nConnection to detailed balance\nAs we saw earlier, detailed balance requires:\n\\[W_{i \\to j} P_i^{eq} = W_{j \\to i} P_j^{eq}\\]\nThis microscopic reversibility ensures that any net flow between states vanishes at equilibrium. When detailed balance is violated—as in all active systems—we observe:\n\\[W_{i \\to j} P_i^{ss} \\neq W_{j \\to i} P_j^{ss}\\]\nwhere \\(P^{ss}\\) represents the non-equilibrium steady state. This inequality manifests as persistent circulation patterns in the probability currents, which we observed in our examples.\n\n\nQuantifying time-reversal symmetry breaking\nTime-reversal symmetry breaking can be quantified using several approaches:\n\nIrreversibility measure: For a stationary process, the degree of irreversibility can be quantified using the Kullback-Leibler divergence:\n\\[I = D_{KL}(P[\\Gamma] || P[\\tilde{\\Gamma}]) = \\left\\langle \\ln \\frac{P[\\Gamma]}{P[\\tilde{\\Gamma}]} \\right\\rangle_\\Gamma\\]\nThis measure quantifies how distinguishable the forward and time-reversed processes are.\nCycling frequencies: In systems that exhibit cyclic behavior (like the Chlamydomonas flagella), the net cycling frequency in phase space provides a direct measure of time-reversal symmetry breaking:\n\\[\\omega_{cycling} = \\frac{1}{2\\pi} \\oint_C \\frac{\\mathbf{J}(\\mathbf{x})}{P(\\mathbf{x})} \\cdot d\\mathbf{l}\\]\nwhere the integral is taken around a closed loop in phase space.\nArea encircled by probability currents: The area enclosed by probability current loops in phase space directly quantifies the magnitude of time-reversal symmetry breaking.\n\n\n\n\n\n\n\nFigure 2: Illustration of time-reversal symmetry breaking. Top: A trajectory in phase space of an equilibrium system looks statistically the same forward and backward in time. Bottom: In a non-equilibrium system, the backward trajectory is statistically distinguishable from the forward trajectory. [source: schematic representation]\n\n\n\n\n\nObservational consequences\nTime-reversal symmetry breaking manifests in various observable phenomena:\n\nEmergent currents: Persistent macroscopic currents can emerge even without external gradients, as seen in active turbulence or bacterial suspensions.\nOdd elasticity: Active materials can exhibit “odd” or non-reciprocal mechanical responses that would be forbidden in equilibrium systems.\nDirected transport: Active systems can perform directed transport against external gradients without violating the second law, as biological molecular motors demonstrate.\nChirality and ratchet effects: Time-reversal symmetry breaking often leads to preferential motion in one direction, which can be leveraged to design molecular ratchets and motors.\n\n\n\nThe arrow of time in active systems\nIn active systems, the arrow of time manifests not just at the macroscopic level (as it does in passive systems through the second law) but also at the mesoscopic level of individual active agents.\nConsider again our Chlamydomonas example: the flagellar beating cycle has a well-defined sequence that breaks time-reversal symmetry at the scale of the individual cell. Playing a video of the flagellar motion backward would immediately reveal that something is “wrong,” even without statistical analysis.\nThis microscopic breaking of time-reversal symmetry distinguishes active matter from passive non-equilibrium systems, where the arrow of time typically emerges only at macroscopic scales or through statistical averages.\nThe magnitude of time-reversal symmetry breaking in active systems is directly related to their energy consumption rate. More energy input generally leads to stronger breaking of time-reversal symmetry, creating systems that are further from equilibrium and capable of more complex emergent behaviors.\nIn conclusion, time-reversal symmetry breaking provides a fundamental lens through which we can understand active matter. By quantifying this symmetry breaking, we gain insight into the essential non-equilibrium character of active systems and the mechanisms through which they harness energy to perform biological functions or create novel material properties."
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Historical context and emergence of the field\nClassification of active systems\nKey examples across biological and synthetic systems\nDistinguishing features from equilibrium systems\nOverview of theoretical approaches\n\n\n\n\n\nBrief review of equilibrium statistical physics\nFluctuation-dissipation theorem and its breakdown\nEntropy production in active systems\nStochastic thermodynamics approach\nTime-reversal symmetry breaking\nExperimental signatures of non-equilibrium behavior\nExperimental methods for characterizing non-equilibrium systems\n\n\n\n\n\nActive Brownian particles\nRun-and-tumble particles\nSwimming at low Reynolds number\nHydrodynamic interactions\nMicroswimmer force dipoles\n\n\n\n\n\nHydrodynamic theories and coarse-graining\nActive liquid crystals\nToner-Tu model for flocking\nActive field theories\nLinear stability analysis in active systems"
  },
  {
    "objectID": "overview.html#part-i-foundations-and-theoretical-framework-4-lectures",
    "href": "overview.html#part-i-foundations-and-theoretical-framework-4-lectures",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Historical context and emergence of the field\nClassification of active systems\nKey examples across biological and synthetic systems\nDistinguishing features from equilibrium systems\nOverview of theoretical approaches\n\n\n\n\n\nBrief review of equilibrium statistical physics\nFluctuation-dissipation theorem and its breakdown\nEntropy production in active systems\nStochastic thermodynamics approach\nTime-reversal symmetry breaking\nExperimental signatures of non-equilibrium behavior\nExperimental methods for characterizing non-equilibrium systems\n\n\n\n\n\nActive Brownian particles\nRun-and-tumble particles\nSwimming at low Reynolds number\nHydrodynamic interactions\nMicroswimmer force dipoles\n\n\n\n\n\nHydrodynamic theories and coarse-graining\nActive liquid crystals\nToner-Tu model for flocking\nActive field theories\nLinear stability analysis in active systems"
  },
  {
    "objectID": "overview.html#part-ii-emergent-phenomena-and-phase-behavior-4-lectures",
    "href": "overview.html#part-ii-emergent-phenomena-and-phase-behavior-4-lectures",
    "title": "Active Matter Physics",
    "section": "Part II: Emergent Phenomena and Phase Behavior (4 lectures)",
    "text": "Part II: Emergent Phenomena and Phase Behavior (4 lectures)\n\nLecture 5: Motility-Induced Phase Separation\n\nMechanisms and theory\nComparison with equilibrium phase separation\nEffective interactions and swim pressure\nCluster formation dynamics\nExperimental realizations\n\n\n\nLecture 6: Collective Motion\n\nVicsek model and flocking transition\nHydrodynamic description of flocks\nInformation transfer in active groups\nAnimal collective behavior\nSynthetic realizations of collective motion\n\n\n\nLecture 7: Active Turbulence and Topological Defects\n\nNature of active turbulence\nTopological defects in nematic systems\n+1/2 and -1/2 defect dynamics\nPattern formation in active nematics\nExperimental systems exhibiting active turbulence\n\n\n\nLecture 8: Mechanical Properties of Active Materials\n\nActive stresses and force transmission\nFluctuations in active systems\nActivity-induced rigidity and softening\nMechanosensing and mechanical feedback\nActive metamaterials"
  },
  {
    "objectID": "overview.html#part-iii-applications-and-advanced-topics-4-lectures",
    "href": "overview.html#part-iii-applications-and-advanced-topics-4-lectures",
    "title": "Active Matter Physics",
    "section": "Part III: Applications and Advanced Topics (4 lectures)",
    "text": "Part III: Applications and Advanced Topics (4 lectures)\n\nLecture 9: Biological Active Matter I - Subcellular Systems\n\nCytoskeletal dynamics and cell motility\nMotor proteins and active transport\nMembrane activity and shape changes\nNuclear organization\nIn vitro reconstitution experiments\n\n\n\nLecture 10: Biological Active Matter II - Multicellular Systems (think about more synthetic and less biological)\n\nBacterial suspensions and biofilms\nCell monolayers and tissue dynamics\nMorphogenesis and developmental biology\nMechanobiology of active tissues\nActive tumor dynamics\n\n\n\nLecture 11: Synthetic Active Matter and Engineering Applications\n\nJanus particles and artificial microswimmers\nLight-activated and chemically powered systems\nActive emulsions and droplets\nProgrammable active matter\nApplications in materials science and microfluidics\n\n\n\nLecture 12: Frontiers in Active Matter Research\n\nActive matter with memory and learning\nInformation processing in active systems\nTopological active matter\nQuantum active matter\nUnsolved problems and future directions\nConcluding discussion and course summary"
  }
]