[
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Historical context and emergence of the field\nClassification of active systems\nKey examples across biological and synthetic systems\nDistinguishing features from equilibrium systems\nOverview of theoretical approaches\n\n\n\n\n\nBrief review of equilibrium statistical physics\nFluctuation-dissipation theorem and its breakdown\nEntropy production in active systems\nStochastic thermodynamics approach\nTime-reversal symmetry breaking\nExperimental signatures of non-equilibrium behavior\nExperimental methods for characterizing non-equilibrium systems\n\n\n\n\n\nActive Brownian particles\nRun-and-tumble particles\nSwimming at low Reynolds number\nHydrodynamic interactions\nMicroswimmer force dipoles\n\n\n\n\n\nHydrodynamic theories and coarse-graining\nActive liquid crystals\nToner-Tu model for flocking\nActive field theories\nLinear stability analysis in active systems"
  },
  {
    "objectID": "overview.html#part-i-foundations-and-theoretical-framework-4-lectures",
    "href": "overview.html#part-i-foundations-and-theoretical-framework-4-lectures",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Historical context and emergence of the field\nClassification of active systems\nKey examples across biological and synthetic systems\nDistinguishing features from equilibrium systems\nOverview of theoretical approaches\n\n\n\n\n\nBrief review of equilibrium statistical physics\nFluctuation-dissipation theorem and its breakdown\nEntropy production in active systems\nStochastic thermodynamics approach\nTime-reversal symmetry breaking\nExperimental signatures of non-equilibrium behavior\nExperimental methods for characterizing non-equilibrium systems\n\n\n\n\n\nActive Brownian particles\nRun-and-tumble particles\nSwimming at low Reynolds number\nHydrodynamic interactions\nMicroswimmer force dipoles\n\n\n\n\n\nHydrodynamic theories and coarse-graining\nActive liquid crystals\nToner-Tu model for flocking\nActive field theories\nLinear stability analysis in active systems"
  },
  {
    "objectID": "overview.html#part-ii-emergent-phenomena-and-phase-behavior-4-lectures",
    "href": "overview.html#part-ii-emergent-phenomena-and-phase-behavior-4-lectures",
    "title": "Active Matter Physics",
    "section": "Part II: Emergent Phenomena and Phase Behavior (4 lectures)",
    "text": "Part II: Emergent Phenomena and Phase Behavior (4 lectures)\n\nLecture 5: Motility-Induced Phase Separation\n\nMechanisms and theory\nComparison with equilibrium phase separation\nEffective interactions and swim pressure\nCluster formation dynamics\nExperimental realizations\n\n\n\nLecture 6: Collective Motion\n\nVicsek model and flocking transition\nHydrodynamic description of flocks\nInformation transfer in active groups\nAnimal collective behavior\nSynthetic realizations of collective motion\n\n\n\nLecture 7: Active Turbulence and Topological Defects\n\nNature of active turbulence\nTopological defects in nematic systems\n+1/2 and -1/2 defect dynamics\nPattern formation in active nematics\nExperimental systems exhibiting active turbulence\n\n\n\nLecture 8: Mechanical Properties of Active Materials\n\nActive stresses and force transmission\nFluctuations in active systems\nActivity-induced rigidity and softening\nMechanosensing and mechanical feedback\nActive metamaterials"
  },
  {
    "objectID": "overview.html#part-iii-applications-and-advanced-topics-4-lectures",
    "href": "overview.html#part-iii-applications-and-advanced-topics-4-lectures",
    "title": "Active Matter Physics",
    "section": "Part III: Applications and Advanced Topics (4 lectures)",
    "text": "Part III: Applications and Advanced Topics (4 lectures)\n\nLecture 9: Biological Active Matter I - Subcellular Systems\n\nCytoskeletal dynamics and cell motility\nMotor proteins and active transport\nMembrane activity and shape changes\nNuclear organization\nIn vitro reconstitution experiments\n\n\n\nLecture 10: Biological Active Matter II - Multicellular Systems (think about more synthetic and less biological)\n\nBacterial suspensions and biofilms\nCell monolayers and tissue dynamics\nMorphogenesis and developmental biology\nMechanobiology of active tissues\nActive tumor dynamics\n\n\n\nLecture 11: Synthetic Active Matter and Engineering Applications\n\nJanus particles and artificial microswimmers\nLight-activated and chemically powered systems\nActive emulsions and droplets\nProgrammable active matter\nApplications in materials science and microfluidics\n\n\n\nLecture 12: Frontiers in Active Matter Research\n\nActive matter with memory and learning\nInformation processing in active systems\nTopological active matter\nQuantum active matter\nUnsolved problems and future directions\nConcluding discussion and course summary"
  },
  {
    "objectID": "lecture01/examples.html",
    "href": "lecture01/examples.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Key examples across biological and synthetic systems\nActive matter encompasses a diverse range of systems spanning biological and synthetic domains:\n\n\nBiological active matter\n\nCytoskeletal networks: Actin filaments and microtubules with molecular motors that drive cell division, motility, and shape changes\nBacterial suspensions: Dense colonies of swimming bacteria like E. coli that exhibit collective motion and turbulent-like flows\nCell sheets and tissues: Epithelial monolayers that display collective migration during wound healing and morphogenesis\nAnimal collectives: Flocking birds, schooling fish, and insect swarms demonstrating emergent group behaviors\nSubcellular organelles: Active droplets and membrane-less organelles that undergo phase separation driven by metabolic activity\n\nSynthetic active matter\n\nJanus particles: Colloids with asymmetric surface properties that enable self-propulsion through chemical or thermal gradients\nLight-activated swimmers: Particles containing photosensitive materials that convert light energy into directed motion\nMagnetically driven systems: Artificial swimmers controlled by external magnetic fields\nActive liquid crystals: Nematic liquid crystals with embedded energy-consuming components that create topological defects and flow patterns\nVibration-powered granular matter: Macroscopic particles energized by mechanical vibrations exhibiting fluidization and pattern formation\nChemically-powered colloids: Particles utilizing catalytic reactions (e.g., platinum-catalyzed hydrogen peroxide decomposition) for propulsion"
  },
  {
    "objectID": "course-info/exam.html",
    "href": "course-info/exam.html",
    "title": "Exam",
    "section": "",
    "text": "Exam Format\n\n\n\nThis course will end with an oral exam of 30 minutes duration. The exams will be held at after the end of the course during the reading period and the week after.\n\n\n\n\n\n\n\n\nExam Eligibility\n\n\n\nThere are no preconditions for taking the exam.",
    "crumbs": [
      "Course Info",
      "Exam"
    ]
  },
  {
    "objectID": "course-info/intructors.html",
    "href": "course-info/intructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructors"
    ]
  },
  {
    "objectID": "course-info/intructors.html#lectures",
    "href": "course-info/intructors.html#lectures",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructors"
    ]
  },
  {
    "objectID": "course-info/intructors.html#seminars",
    "href": "course-info/intructors.html#seminars",
    "title": "Instructors",
    "section": "Seminars",
    "text": "Seminars\n\nDr. Xiangzun Wang\n\nLinnéstr. 5, 04103 Leipzig\nOffice: 333a\nPhone: +49 341 97 32570\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructors"
    ]
  },
  {
    "objectID": "lecture03/lecture03.html",
    "href": "lecture03/lecture03.html",
    "title": "Microscopic Models of Self-propulsion",
    "section": "",
    "text": "Lecture 3: Microscopic Models of Self-propulsion\n\nActive Brownian particles\nRun-and-tumble particles\nSwimming at low Reynolds number\nHydrodynamic interactions\nMicroswimmer force dipoles"
  },
  {
    "objectID": "lecture02/lecture02.html",
    "href": "lecture02/lecture02.html",
    "title": "Non-equilibrium Statistical Mechanics",
    "section": "",
    "text": "Equilibrium statistical mechanics may seem like a contradictory starting point for understanding fundamentally non-equilibrium phenomena in active matter. However, we begin with these concepts precisely because understanding how and why active systems violate equilibrium principles illuminates their unique properties. In this section, we review key equilibrium concepts that provide a crucial reference frame against which we can measure and characterize the non-equilibrium nature of active systems.\n\n\nFor a system in thermal equilibrium with a heat bath at temperature \\(T\\) not exchanging particles with the environment, the probability of finding the system in a microstate with phase space coordinates \\(\\Gamma = \\{\\mathbf{q}, \\mathbf{p}\\}\\) is given by the Boltzmann distribution:\n\\[P(\\Gamma) = \\frac{1}{Z} e^{-\\beta H(\\Gamma)}\\]\nwhere \\(\\beta = 1/(k_B T)\\), \\(k_B\\) is Boltzmann’s constant, \\(H(\\Gamma)\\) is the Hamiltonian of the system, and \\(Z\\) is the partition function:\n\\[Z = \\int e^{-\\beta H(\\Gamma)} d\\Gamma\\]\nIn physical terms, the Boltzmann distribution reflects how energy is partitioned among the available states at thermal equilibrium. States with lower energy are exponentially more likely to be occupied than states with higher energy. For active matter systems, this distribution is significantly altered because energy is continuously injected at the microscopic level, driving the system away from this equilibrium distribution. Indeed, active systems generally cannot be described by a time-independent Hamiltonian at all, as they involve non-conservative forces.\nThe partition function is central to statistical mechanics as it connects microscopic properties to macroscopic observables. For instance, the average energy is:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\\]\nThis relationship highlights how the partition function serves as a generating function for thermodynamic quantities. When studying active matter, we’ll see that traditional partition functions often cannot be defined because these systems don’t explore phase space according to Boltzmann statistics.\n\n\n\n\n\n\nSedimentation Example\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Perrin’s sedimentation experiments. The exponential decay in the number density of colloidal particles with height directly confirmed the Boltzmann distribution and provided key evidence for the atomic theory of matter.\n\n\n\nA clear demonstration of the Boltzmann distribution’s power can be derived from the canonical partition function using the barometric distribution of particles in a gravitational field. Consider colloidal particles suspended in a fluid in a gravitational field \\(g\\).\nThe Hamiltonian for a particle at height \\(h\\) with momentum \\(p\\) is:\n\\[H(h, p) = \\frac{p^2}{2m} + mgh\\]\nwhere the first term represents the kinetic energy and the second term is the gravitational potential energy. For this system, we can construct the partition function by integrating over all possible heights and momenta:\n\\[Z = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(h,p)} dp dh = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp dh\\]\nThis can be separated into:\n\\[Z = \\int_{-\\infty}^{\\infty} e^{-\\beta\\frac{p^2}{2m}} dp \\cdot \\int_0^{\\infty} e^{-\\beta mgh} dh\\]\nThe momentum integral gives \\(\\sqrt{\\frac{2\\pi m}{\\beta}}\\), while the height integral yields \\(\\frac{1}{\\beta mg}\\), resulting in:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg} = \\sqrt{\\frac{2\\pi m}{\\beta^3 m^2 g^2}}\\]\nThe probability density for finding a particle at height \\(h\\) (integrating over all momenta) is:\n\\[P(h) = \\frac{\\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp}{Z} = \\frac{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot e^{-\\beta mgh}}{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg}} = \\beta mg e^{-\\beta mgh}\\]\nFrom this, we can derive the number density \\(n(h)\\) by multiplying by the total number of particles \\(N\\):\n\\[n(h) = N \\cdot P(h) = N \\beta mg e^{-\\beta mgh}\\]\nIf we define \\(n_0\\) as the density at \\(h=0\\), then \\(n_0 = N \\beta mg\\), and we obtain:\n\\[n(h) = n_0 e^{-\\beta mgh} = n_0 e^{-\\frac{mgh}{k_B T}}\\]\nTaking the logarithm of both sides:\n\\[\\ln\\left(\\frac{n(h)}{n_0}\\right) = -\\beta mgh = -\\frac{mgh}{k_B T}\\]\nThis direct connection between the Hamiltonian, partition function, and the observable barometric distribution provides a compelling experimental verification of statistical mechanics. Jean Perrin used this relationship in 1908 to experimentally determine Avogadro’s number and provide crucial evidence for the atomic theory of matter. Today, similar experiments with colloidal particles serve as textbook demonstrations of statistical mechanics in action.\n\n\n\n\n\n\nHere’s how you could introduce the enthalpic and entropic parts in the free energy expression:\nThe Helmholtz free energy \\(F\\) is related to the partition function by:\n\\[F = -k_B T \\ln Z = -k_B T \\ln \\left(\\int e^{-\\beta H(\\Gamma)} d\\Gamma\\right)\\]\nWe can rewrite this as \\(F = E - TS\\), explicitly showing the competition between the enthalpic (energy) and entropic contributions:\n\\[F = \\langle H \\rangle - TS\\]\nwhere \\(\\langle H \\rangle\\) is the average energy:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta} = \\frac{\\int H(\\Gamma) e^{-\\beta H(\\Gamma)} d\\Gamma}{\\int e^{-\\beta H(\\Gamma)} d\\Gamma}\\]\nand \\(S\\) is the entropy:\n\\[S = -\\left(\\frac{\\partial F}{\\partial T}\\right)_V = k_B \\ln Z + \\frac{\\langle H \\rangle}{T}\\]\nAt equilibrium, minimizing the free energy involves a fundamental competition between:\n\nEnergy minimization: The system tends to occupy low-energy states to minimize \\(\\langle H \\rangle\\)\nEntropy maximization: The system tends to spread over many accessible states to maximize \\(S\\)\n\nThe Boltzmann distribution \\(P(\\Gamma) = \\frac{1}{Z}e^{-\\beta H(\\Gamma)}\\) represents the optimal compromise between these competing tendencies. For systems with fixed particle number, volume, and temperature (canonical ensemble), this distribution precisely minimizes the free energy subject to the constraints of the canonical ensemble.\nThe principle of free energy minimization is particularly important for understanding the contrast with active systems. In active matter, free energy is constantly being pumped into the system through microscopic driving mechanisms (e.g., molecular motors in cell cytoskeleton, metabolic processes in bacteria, or artificial propulsion mechanisms in synthetic swimmers). These systems involve non-conservative forces that cannot be derived from a Hamiltonian, so they cannot be described by a minimum free energy principle, which is a fundamental departure from equilibrium thermodynamics.\n\n\n\n\n\n\nHarmonic Oscillator Example\n\n\n\n\n\nThe harmonic oscillator provides another illuminating example of equilibrium statistical mechanics. Consider a Brownian particle in a harmonic potential \\(U(x) = \\frac{1}{2}kx^2\\) provided by some highly focused light beam. Here \\(k\\) is the spring constant.\n\n\n\n\n\n\nFigure 2: Sketch of a colloidal particle trapped in the focus of a microscopy lens due to electromagnetic forces. source\n\n\n\nThe particle experiences both a restoring force and random thermal kicks from the surrounding fluid.\nThe Hamiltonian for this system is:\n\\[H(x,p) = \\frac{p^2}{2m} + \\frac{1}{2}kx^2\\]\nwhere \\(m\\) is the particle mass, \\(x\\) is position, and \\(p\\) is momentum. The partition function is:\n\\[Z = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(x,p)} dx dp = \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{p^2}{2m}} dp \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{1}{2}kx^2} dx\\]\nEvaluating these Gaussian integrals:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\sqrt{\\frac{2\\pi}{\\beta k}} = \\frac{2\\pi}{\\beta\\omega_0}\\]\nwhere \\(\\omega_0 = \\sqrt{k/m}\\) is the natural frequency of the oscillator.\nThe probability density for finding the particle at position \\(x\\) is:\n\\[P(x) = \\sqrt{\\frac{\\beta k}{2\\pi}} e^{-\\beta \\frac{1}{2}kx^2}\\]\nThis Gaussian distribution has variance \\(\\sigma^2 = \\frac{1}{\\beta k} = \\frac{k_B T}{k}\\).\nThe equipartition theorem states that each quadratic term in the Hamiltonian contributes \\(\\frac{1}{2}k_B T\\) to the average energy:\n\\[\\left \\langle \\frac{p^2}{2m} \\right \\rangle = \\left \\langle \\frac{1}{2}kx^2 \\right \\rangle = \\frac{1}{2}k_B T\\]\nTherefore, the mean-square displacement of the particle is:\n\\[\\langle x^2 \\rangle = \\frac{k_B T}{k}\\]\nThis simple relation demonstrates how thermal energy causes the particle to explore the potential well, with the stiffness of the spring determining the confinement. Stiffer springs (larger \\(k\\)) lead to smaller position fluctuations.\n\n\n\n\n\n\nA key assumption in equilibrium statistical mechanics is ergodicity—the equivalence between time averages and ensemble averages:\n\\[\\langle A \\rangle_{\\text{time}} = \\lim_{T\\to\\infty} \\frac{1}{T} \\int_0^T A(t) dt = \\langle A \\rangle_{\\text{ensemble}}\\]\nIn practical terms, ergodicity means that if you observe a single system for a sufficiently long time, it will eventually visit all microscopic states consistent with its macroscopic constraints, allowing time averages to equal ensemble averages. Active matter systems often violate ergodicity by persistently exploring only a subset of the available phase space due to their self-propulsion mechanisms. This has profound implications for both experimental measurements and theoretical descriptions of active systems.\nEquilibrium dynamics satisfies detailed balance, a microscopic time-reversal symmetry condition. For transitions between states \\(i\\) and \\(j\\) with rates \\(W_{i\\to j}\\) and \\(W_{j\\to i}\\):\n\\[\\frac{W_{i\\to j}}{W_{j\\to i}} = \\frac{P_j^{\\text{eq}}}{P_i^{\\text{eq}}} = e^{-\\beta(E_j-E_i)}\\]\nDetailed balance ensures that there are no net probability currents in equilibrium.\n\n\nIn the sedimentation example, we can apply detailed balance to particles moving between different heights in a gravitational field. Consider transitions between heights \\(h_i\\) and \\(h_j\\):\n\nThe equilibrium probability to find a particle at height \\(h\\) is \\(P(h) \\propto e^{-\\beta mgh}\\)\nFor a particle moving from height \\(h_i\\) to a higher position \\(h_j\\), the energy difference is \\(\\Delta E = mg(h_j - h_i)\\)\n\nBy detailed balance, the transition rates must satisfy:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis reveals that upward transitions (against gravity) are exponentially suppressed compared to downward transitions. If we observe the system over time, we would see particles moving both up and down, but with precisely balanced rates that maintain the exponential density profile.\nThis balance has profound implications for trajectory reversibility. In equilibrium systems, detailed balance ensures that for any specific trajectory \\(\\gamma\\) a particle takes from height \\(h_i\\) to \\(h_j\\) over a time interval \\([0,t]\\), the time-reversed trajectory \\(\\bar{\\gamma}\\) (the same path followed backward in time) from \\(h_j\\) to \\(h_i\\) occurs with a probability that differs only by the Boltzmann factor:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\]\nThis microscopic reversibility means that if we filmed the motion of an equilibrium system and played the recording backward, the reversed motion would be statistically indistinguishable from the forward motion (when properly weighted by the equilibrium probabilities). For particles in sedimentation, this time-reversal symmetry ensures that no systematic currents exist in the steady state—particles may diffuse up and down, but any apparent “uphill” motion is precisely balanced by “downhill” motion, maintaining the exponential density profile without net circulation in phase space.\n\n\n\n\n\n\nConnecting to Fluctuation Theorems\n\n\n\n\n\nThe relationship between detailed balance, trajectory reversibility, and sedimentation connects directly to fluctuation theorems, which provide a broader framework for understanding non-equilibrium systems:\n\n\nThe trajectory reversibility we described for equilibrium systems (where \\(\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\)) is actually a special case of more general fluctuation theorems that apply even to non-equilibrium systems. These theorems quantify the probability of observing trajectories that appear to violate the second law of thermodynamics.\nFor the sedimentation example, the key connections are:\n\nCrooks Fluctuation Theorem: This relates the probability of forward and reverse trajectories to the entropy production:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta(W-\\Delta F)} = e^{\\Delta S_{tot}/k_B}\\]\nWhere \\(W\\) is the work done, \\(\\Delta F\\) is the free energy difference, and \\(\\Delta S_{tot}\\) is the total entropy production.\nEquilibrium Special Case: When detailed balance is satisfied (as in passive sedimentation), \\(W = \\Delta F = mg(h_j-h_i)\\) and \\(\\Delta S_{tot} = 0\\), recovering our earlier result.\nActive Systems: For active particles in sedimentation, we have additional work from active forces, leading to:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta mg(h_j-h_i) + \\Delta S_{act}/k_B}\\]\nWhere \\(\\Delta S_{act} &gt; 0\\) is the entropy production due to activity.\n\n\n\n\n\n\n\n\n\n\n\nMaster Equation Formulation\n\n\n\n\n\nDetailed balance can be elegantly formulated in terms of a master equation, which provides a powerful framework for understanding the time evolution of probability distributions.The master equation describes how the probability P_i(t) of finding the system in state i evolves over time:\n\\[\\frac{dP_i(t)}{dt} = \\sum_j [W_{j \\to i} P_j(t) - W_{i \\to j} P_i(t)]\\]\nwhere \\(W_{j→i}\\) is the transition rate from state \\(j\\) to state \\(i\\).\nThe first term represents probability flowing into state \\(i\\) from all other states \\(j\\), while the second term represents probability flowing out of state \\(i\\) to all other states \\(j\\).\n\n\nAt steady state, the left-hand side of the master equation equals zero, meaning:\n\\[\\sum_j [W_{j \\to i} P_j - W_{i \\to j} P_i] = 0\\]\nHowever, detailed balance imposes a much stronger condition - that each term in this sum must individually equal zero:\n\\[W_{j \\to i} P_j^{eq} = W_{i \\to j} P_i^{eq} \\quad \\text{for all pairs } i,j\\]\nThis is equivalent to requiring that the net probability current between any two states vanishes at equilibrium.\n\n\n\nFor sedimentation, we can discretize the height into levels \\({h_i}\\). The master equation becomes:\n\\[\\frac{dP(h_i,t)}{dt} = \\sum_j [W_{h_j \\to h_i} P(h_j,t) - W_{h_i \\to h_j} P(h_i,t)]\\]\nDetailed balance requires:\n\\[W_{h_j \\to h_i} P^{eq}(h_j) = W_{h_i \\to h_j} P^{eq}(h_i)\\]\nSubstituting the Boltzmann distribution \\(P^{eq}(h) \\propto e^{-\\beta mgh}\\):\n\\[W_{h_j \\to h_i} e^{-\\beta mgh_j} = W_{h_i \\to h_j} e^{-\\beta mgh_i}\\]\nRearranging:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis recovers our previous expression for detailed balance in sedimentation.\n\n\n\nFor active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:\n\\[W_{h_j \\to h_i}^{act} P^{ss}(h_j) \\neq W_{h_i \\to h_j}^{act} P^{ss}(h_i)\\]\nwhere \\(P^ss\\) denotes the non-equilibrium steady state distribution.\n\n\n\n\n\n\n\n\n\nBrownian motion provides a simple yet powerful model for understanding thermal fluctuations. The Langevin equation describes the motion of a Brownian particle:\n\\[m\\frac{d^2x}{dt^2} = -\\gamma\\frac{dx}{dt} - \\frac{dU(x)}{dx} + \\xi(t)\\]\nwhere \\(\\gamma\\) is the friction coefficient, \\(U(x)\\) is the potential energy, and \\(\\xi(t)\\) is Gaussian white noise with:\n\\[\\langle\\xi(t)\\rangle = 0, \\quad \\langle\\xi(t)\\xi(t')\\rangle = 2\\gamma k_B T \\delta(t-t')\\]\nThe noise amplitude is related to the friction coefficient through the fluctuation-dissipation relation, a consequence of thermal equilibrium. This relation embodies a deep physical principle: the same microscopic processes that cause energy dissipation (friction) also generate fluctuations (noise), with temperature determining their relative strength.\nUnderstanding the Langevin equation is crucial as it serves as a conceptual bridge between equilibrium and non-equilibrium physics. When modeling active particles, we extend this framework by adding a self-propulsion term. The simplest model of an active Brownian particle (ABP) incorporates a propulsion force of constant magnitude but with a direction that changes through rotational diffusion:\n\\[\\gamma\\frac{d\\mathbf{r}}{dt} = -\\nabla U(\\mathbf{r}) + \\gamma v_0 \\mathbf{n}(t) + \\boldsymbol{\\xi}(t)\\]\nwhere \\(v_0\\) represents the swimming speed and \\(\\mathbf{n}(t)\\) is a unit vector undergoing rotational diffusion. This seemingly simple modification profoundly transforms the physics, leading to enhanced diffusion, boundary accumulation, and novel collective behaviors unlike anything seen in passive systems.\nIn many situations relevant to colloidal systems and active matter, inertial effects can be neglected, leading to the overdamped limit of the Langevin equation:\n\\[\\gamma\\frac{dx}{dt} = -\\frac{dU(x)}{dx} + \\xi(t)\\]\nThis overdamped approximation accurately describes microscopic active systems such as bacterial suspensions, catalytic Janus particles, and colloidal rollers. In these systems, the Reynolds number is extremely low (typically 10^-5 to 10^-2), meaning viscous forces dominate over inertial forces. Consequently, particles stop moving almost instantaneously when propulsion ceases—a counterintuitive behavior compared to our macroscopic experience where objects continue moving due to inertia.\nThe Langevin framework will serve as our starting point for understanding how active systems systematically violate equilibrium principles. As we explore further, we’ll see that active matter requires expanding our theoretical tools beyond equilibrium statistical mechanics to account for the continuous energy input that drives these fascinating systems far from equilibrium.\n\n\n\nAt its core, the FDT tells us something remarkable: by simply watching how a system naturally fluctuates at equilibrium, we can predict exactly how it will respond when we deliberately perturb it. This powerful connection works because in equilibrium systems, the same thermal processes drive both phenomena.\nImagine tracking the position of a colloidal particle in a harmonic trap. The particle jiggles around due to random collisions with fluid molecules. The FDT tells us that these natural fluctuations contain all the information we need to know how the particle would respond if we were to push it with a small external force.\nMathematically, we describe this using two key functions:\n\nThe correlation function \\(C_{ij}(t-t')\\) measures how fluctuations are related in time:\n\n\\[C_{ij}(t-t') = \\langle x_i(t) x_j(t') \\rangle - \\langle x_i(t) \\rangle \\langle x_j(t') \\rangle\\]\nThis is something we can directly measure in experiments by tracking a system over time and calculating how variables at different times relate to each other.\n\nThe response function \\(\\chi_{ij}(t-t')\\) tells us how the system responds to external forces:\n\n\\[\\chi_{ij}(t-t') = \\frac{\\delta \\langle x_i(t) \\rangle}{\\delta h_j(t')}\\]\nThis represents how much variable \\(x_i\\) changes at time \\(t\\) when we apply a small force \\(h_j\\) at an earlier time \\(t'\\).\nThe fluctuation-dissipation theorem connects these two functions through temperature. For a system at equilibrium:\n\\[\\chi_{ij}(t-t') = -\\frac{1}{k_B T} \\frac{d}{dt} C_{ij}(t-t') \\quad \\text{for } t &gt; t'\\]\nIn experiments, it’s often more convenient to work in the frequency domain (using Fourier transforms):\n\\[\\chi_{ij}''(\\omega) = \\frac{\\omega}{2k_B T} C_{ij}(\\omega)\\]\nHere, \\(\\chi_{ij}''(\\omega)\\) is the imaginary part of the response function (related to energy dissipation) and \\(C_{ij}(\\omega)\\) is the power spectrum of fluctuations at frequency \\(\\omega\\).",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lecture02/lecture02.html#brief-review-of-equilibrium-statistical-mechanics",
    "href": "lecture02/lecture02.html#brief-review-of-equilibrium-statistical-mechanics",
    "title": "Non-equilibrium Statistical Mechanics",
    "section": "",
    "text": "Equilibrium statistical mechanics may seem like a contradictory starting point for understanding fundamentally non-equilibrium phenomena in active matter. However, we begin with these concepts precisely because understanding how and why active systems violate equilibrium principles illuminates their unique properties. In this section, we review key equilibrium concepts that provide a crucial reference frame against which we can measure and characterize the non-equilibrium nature of active systems.\n\n\nFor a system in thermal equilibrium with a heat bath at temperature \\(T\\) not exchanging particles with the environment, the probability of finding the system in a microstate with phase space coordinates \\(\\Gamma = \\{\\mathbf{q}, \\mathbf{p}\\}\\) is given by the Boltzmann distribution:\n\\[P(\\Gamma) = \\frac{1}{Z} e^{-\\beta H(\\Gamma)}\\]\nwhere \\(\\beta = 1/(k_B T)\\), \\(k_B\\) is Boltzmann’s constant, \\(H(\\Gamma)\\) is the Hamiltonian of the system, and \\(Z\\) is the partition function:\n\\[Z = \\int e^{-\\beta H(\\Gamma)} d\\Gamma\\]\nIn physical terms, the Boltzmann distribution reflects how energy is partitioned among the available states at thermal equilibrium. States with lower energy are exponentially more likely to be occupied than states with higher energy. For active matter systems, this distribution is significantly altered because energy is continuously injected at the microscopic level, driving the system away from this equilibrium distribution. Indeed, active systems generally cannot be described by a time-independent Hamiltonian at all, as they involve non-conservative forces.\nThe partition function is central to statistical mechanics as it connects microscopic properties to macroscopic observables. For instance, the average energy is:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\\]\nThis relationship highlights how the partition function serves as a generating function for thermodynamic quantities. When studying active matter, we’ll see that traditional partition functions often cannot be defined because these systems don’t explore phase space according to Boltzmann statistics.\n\n\n\n\n\n\nSedimentation Example\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Perrin’s sedimentation experiments. The exponential decay in the number density of colloidal particles with height directly confirmed the Boltzmann distribution and provided key evidence for the atomic theory of matter.\n\n\n\nA clear demonstration of the Boltzmann distribution’s power can be derived from the canonical partition function using the barometric distribution of particles in a gravitational field. Consider colloidal particles suspended in a fluid in a gravitational field \\(g\\).\nThe Hamiltonian for a particle at height \\(h\\) with momentum \\(p\\) is:\n\\[H(h, p) = \\frac{p^2}{2m} + mgh\\]\nwhere the first term represents the kinetic energy and the second term is the gravitational potential energy. For this system, we can construct the partition function by integrating over all possible heights and momenta:\n\\[Z = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(h,p)} dp dh = \\int_0^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp dh\\]\nThis can be separated into:\n\\[Z = \\int_{-\\infty}^{\\infty} e^{-\\beta\\frac{p^2}{2m}} dp \\cdot \\int_0^{\\infty} e^{-\\beta mgh} dh\\]\nThe momentum integral gives \\(\\sqrt{\\frac{2\\pi m}{\\beta}}\\), while the height integral yields \\(\\frac{1}{\\beta mg}\\), resulting in:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg} = \\sqrt{\\frac{2\\pi m}{\\beta^3 m^2 g^2}}\\]\nThe probability density for finding a particle at height \\(h\\) (integrating over all momenta) is:\n\\[P(h) = \\frac{\\int_{-\\infty}^{\\infty} e^{-\\beta(\\frac{p^2}{2m} + mgh)} dp}{Z} = \\frac{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot e^{-\\beta mgh}}{\\sqrt{\\frac{2\\pi m}{\\beta}} \\cdot \\frac{1}{\\beta mg}} = \\beta mg e^{-\\beta mgh}\\]\nFrom this, we can derive the number density \\(n(h)\\) by multiplying by the total number of particles \\(N\\):\n\\[n(h) = N \\cdot P(h) = N \\beta mg e^{-\\beta mgh}\\]\nIf we define \\(n_0\\) as the density at \\(h=0\\), then \\(n_0 = N \\beta mg\\), and we obtain:\n\\[n(h) = n_0 e^{-\\beta mgh} = n_0 e^{-\\frac{mgh}{k_B T}}\\]\nTaking the logarithm of both sides:\n\\[\\ln\\left(\\frac{n(h)}{n_0}\\right) = -\\beta mgh = -\\frac{mgh}{k_B T}\\]\nThis direct connection between the Hamiltonian, partition function, and the observable barometric distribution provides a compelling experimental verification of statistical mechanics. Jean Perrin used this relationship in 1908 to experimentally determine Avogadro’s number and provide crucial evidence for the atomic theory of matter. Today, similar experiments with colloidal particles serve as textbook demonstrations of statistical mechanics in action.\n\n\n\n\n\n\nHere’s how you could introduce the enthalpic and entropic parts in the free energy expression:\nThe Helmholtz free energy \\(F\\) is related to the partition function by:\n\\[F = -k_B T \\ln Z = -k_B T \\ln \\left(\\int e^{-\\beta H(\\Gamma)} d\\Gamma\\right)\\]\nWe can rewrite this as \\(F = E - TS\\), explicitly showing the competition between the enthalpic (energy) and entropic contributions:\n\\[F = \\langle H \\rangle - TS\\]\nwhere \\(\\langle H \\rangle\\) is the average energy:\n\\[\\langle H \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta} = \\frac{\\int H(\\Gamma) e^{-\\beta H(\\Gamma)} d\\Gamma}{\\int e^{-\\beta H(\\Gamma)} d\\Gamma}\\]\nand \\(S\\) is the entropy:\n\\[S = -\\left(\\frac{\\partial F}{\\partial T}\\right)_V = k_B \\ln Z + \\frac{\\langle H \\rangle}{T}\\]\nAt equilibrium, minimizing the free energy involves a fundamental competition between:\n\nEnergy minimization: The system tends to occupy low-energy states to minimize \\(\\langle H \\rangle\\)\nEntropy maximization: The system tends to spread over many accessible states to maximize \\(S\\)\n\nThe Boltzmann distribution \\(P(\\Gamma) = \\frac{1}{Z}e^{-\\beta H(\\Gamma)}\\) represents the optimal compromise between these competing tendencies. For systems with fixed particle number, volume, and temperature (canonical ensemble), this distribution precisely minimizes the free energy subject to the constraints of the canonical ensemble.\nThe principle of free energy minimization is particularly important for understanding the contrast with active systems. In active matter, free energy is constantly being pumped into the system through microscopic driving mechanisms (e.g., molecular motors in cell cytoskeleton, metabolic processes in bacteria, or artificial propulsion mechanisms in synthetic swimmers). These systems involve non-conservative forces that cannot be derived from a Hamiltonian, so they cannot be described by a minimum free energy principle, which is a fundamental departure from equilibrium thermodynamics.\n\n\n\n\n\n\nHarmonic Oscillator Example\n\n\n\n\n\nThe harmonic oscillator provides another illuminating example of equilibrium statistical mechanics. Consider a Brownian particle in a harmonic potential \\(U(x) = \\frac{1}{2}kx^2\\) provided by some highly focused light beam. Here \\(k\\) is the spring constant.\n\n\n\n\n\n\nFigure 2: Sketch of a colloidal particle trapped in the focus of a microscopy lens due to electromagnetic forces. source\n\n\n\nThe particle experiences both a restoring force and random thermal kicks from the surrounding fluid.\nThe Hamiltonian for this system is:\n\\[H(x,p) = \\frac{p^2}{2m} + \\frac{1}{2}kx^2\\]\nwhere \\(m\\) is the particle mass, \\(x\\) is position, and \\(p\\) is momentum. The partition function is:\n\\[Z = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} e^{-\\beta H(x,p)} dx dp = \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{p^2}{2m}} dp \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{1}{2}kx^2} dx\\]\nEvaluating these Gaussian integrals:\n\\[Z = \\sqrt{\\frac{2\\pi m}{\\beta}} \\sqrt{\\frac{2\\pi}{\\beta k}} = \\frac{2\\pi}{\\beta\\omega_0}\\]\nwhere \\(\\omega_0 = \\sqrt{k/m}\\) is the natural frequency of the oscillator.\nThe probability density for finding the particle at position \\(x\\) is:\n\\[P(x) = \\sqrt{\\frac{\\beta k}{2\\pi}} e^{-\\beta \\frac{1}{2}kx^2}\\]\nThis Gaussian distribution has variance \\(\\sigma^2 = \\frac{1}{\\beta k} = \\frac{k_B T}{k}\\).\nThe equipartition theorem states that each quadratic term in the Hamiltonian contributes \\(\\frac{1}{2}k_B T\\) to the average energy:\n\\[\\left \\langle \\frac{p^2}{2m} \\right \\rangle = \\left \\langle \\frac{1}{2}kx^2 \\right \\rangle = \\frac{1}{2}k_B T\\]\nTherefore, the mean-square displacement of the particle is:\n\\[\\langle x^2 \\rangle = \\frac{k_B T}{k}\\]\nThis simple relation demonstrates how thermal energy causes the particle to explore the potential well, with the stiffness of the spring determining the confinement. Stiffer springs (larger \\(k\\)) lead to smaller position fluctuations.\n\n\n\n\n\n\nA key assumption in equilibrium statistical mechanics is ergodicity—the equivalence between time averages and ensemble averages:\n\\[\\langle A \\rangle_{\\text{time}} = \\lim_{T\\to\\infty} \\frac{1}{T} \\int_0^T A(t) dt = \\langle A \\rangle_{\\text{ensemble}}\\]\nIn practical terms, ergodicity means that if you observe a single system for a sufficiently long time, it will eventually visit all microscopic states consistent with its macroscopic constraints, allowing time averages to equal ensemble averages. Active matter systems often violate ergodicity by persistently exploring only a subset of the available phase space due to their self-propulsion mechanisms. This has profound implications for both experimental measurements and theoretical descriptions of active systems.\nEquilibrium dynamics satisfies detailed balance, a microscopic time-reversal symmetry condition. For transitions between states \\(i\\) and \\(j\\) with rates \\(W_{i\\to j}\\) and \\(W_{j\\to i}\\):\n\\[\\frac{W_{i\\to j}}{W_{j\\to i}} = \\frac{P_j^{\\text{eq}}}{P_i^{\\text{eq}}} = e^{-\\beta(E_j-E_i)}\\]\nDetailed balance ensures that there are no net probability currents in equilibrium.\n\n\nIn the sedimentation example, we can apply detailed balance to particles moving between different heights in a gravitational field. Consider transitions between heights \\(h_i\\) and \\(h_j\\):\n\nThe equilibrium probability to find a particle at height \\(h\\) is \\(P(h) \\propto e^{-\\beta mgh}\\)\nFor a particle moving from height \\(h_i\\) to a higher position \\(h_j\\), the energy difference is \\(\\Delta E = mg(h_j - h_i)\\)\n\nBy detailed balance, the transition rates must satisfy:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis reveals that upward transitions (against gravity) are exponentially suppressed compared to downward transitions. If we observe the system over time, we would see particles moving both up and down, but with precisely balanced rates that maintain the exponential density profile.\nThis balance has profound implications for trajectory reversibility. In equilibrium systems, detailed balance ensures that for any specific trajectory \\(\\gamma\\) a particle takes from height \\(h_i\\) to \\(h_j\\) over a time interval \\([0,t]\\), the time-reversed trajectory \\(\\bar{\\gamma}\\) (the same path followed backward in time) from \\(h_j\\) to \\(h_i\\) occurs with a probability that differs only by the Boltzmann factor:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\]\nThis microscopic reversibility means that if we filmed the motion of an equilibrium system and played the recording backward, the reversed motion would be statistically indistinguishable from the forward motion (when properly weighted by the equilibrium probabilities). For particles in sedimentation, this time-reversal symmetry ensures that no systematic currents exist in the steady state—particles may diffuse up and down, but any apparent “uphill” motion is precisely balanced by “downhill” motion, maintaining the exponential density profile without net circulation in phase space.\n\n\n\n\n\n\nConnecting to Fluctuation Theorems\n\n\n\n\n\nThe relationship between detailed balance, trajectory reversibility, and sedimentation connects directly to fluctuation theorems, which provide a broader framework for understanding non-equilibrium systems:\n\n\nThe trajectory reversibility we described for equilibrium systems (where \\(\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{-\\beta mg(h_j-h_i)}\\)) is actually a special case of more general fluctuation theorems that apply even to non-equilibrium systems. These theorems quantify the probability of observing trajectories that appear to violate the second law of thermodynamics.\nFor the sedimentation example, the key connections are:\n\nCrooks Fluctuation Theorem: This relates the probability of forward and reverse trajectories to the entropy production:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta(W-\\Delta F)} = e^{\\Delta S_{tot}/k_B}\\]\nWhere \\(W\\) is the work done, \\(\\Delta F\\) is the free energy difference, and \\(\\Delta S_{tot}\\) is the total entropy production.\nEquilibrium Special Case: When detailed balance is satisfied (as in passive sedimentation), \\(W = \\Delta F = mg(h_j-h_i)\\) and \\(\\Delta S_{tot} = 0\\), recovering our earlier result.\nActive Systems: For active particles in sedimentation, we have additional work from active forces, leading to:\n\\[\\frac{P[\\gamma]}{P[\\bar{\\gamma}]} = e^{\\beta mg(h_j-h_i) + \\Delta S_{act}/k_B}\\]\nWhere \\(\\Delta S_{act} &gt; 0\\) is the entropy production due to activity.\n\n\n\n\n\n\n\n\n\n\n\nMaster Equation Formulation\n\n\n\n\n\nDetailed balance can be elegantly formulated in terms of a master equation, which provides a powerful framework for understanding the time evolution of probability distributions.The master equation describes how the probability P_i(t) of finding the system in state i evolves over time:\n\\[\\frac{dP_i(t)}{dt} = \\sum_j [W_{j \\to i} P_j(t) - W_{i \\to j} P_i(t)]\\]\nwhere \\(W_{j→i}\\) is the transition rate from state \\(j\\) to state \\(i\\).\nThe first term represents probability flowing into state \\(i\\) from all other states \\(j\\), while the second term represents probability flowing out of state \\(i\\) to all other states \\(j\\).\n\n\nAt steady state, the left-hand side of the master equation equals zero, meaning:\n\\[\\sum_j [W_{j \\to i} P_j - W_{i \\to j} P_i] = 0\\]\nHowever, detailed balance imposes a much stronger condition - that each term in this sum must individually equal zero:\n\\[W_{j \\to i} P_j^{eq} = W_{i \\to j} P_i^{eq} \\quad \\text{for all pairs } i,j\\]\nThis is equivalent to requiring that the net probability current between any two states vanishes at equilibrium.\n\n\n\nFor sedimentation, we can discretize the height into levels \\({h_i}\\). The master equation becomes:\n\\[\\frac{dP(h_i,t)}{dt} = \\sum_j [W_{h_j \\to h_i} P(h_j,t) - W_{h_i \\to h_j} P(h_i,t)]\\]\nDetailed balance requires:\n\\[W_{h_j \\to h_i} P^{eq}(h_j) = W_{h_i \\to h_j} P^{eq}(h_i)\\]\nSubstituting the Boltzmann distribution \\(P^{eq}(h) \\propto e^{-\\beta mgh}\\):\n\\[W_{h_j \\to h_i} e^{-\\beta mgh_j} = W_{h_i \\to h_j} e^{-\\beta mgh_i}\\]\nRearranging:\n\\[\\frac{W_{h_i \\to h_j}}{W_{h_j \\to h_i}} = \\frac{e^{-\\beta mgh_j}}{e^{-\\beta mgh_i}} = e^{-\\beta mg(h_j-h_i)}\\]\nThis recovers our previous expression for detailed balance in sedimentation.\n\n\n\nFor active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:\n\\[W_{h_j \\to h_i}^{act} P^{ss}(h_j) \\neq W_{h_i \\to h_j}^{act} P^{ss}(h_i)\\]\nwhere \\(P^ss\\) denotes the non-equilibrium steady state distribution.\n\n\n\n\n\n\n\n\n\nBrownian motion provides a simple yet powerful model for understanding thermal fluctuations. The Langevin equation describes the motion of a Brownian particle:\n\\[m\\frac{d^2x}{dt^2} = -\\gamma\\frac{dx}{dt} - \\frac{dU(x)}{dx} + \\xi(t)\\]\nwhere \\(\\gamma\\) is the friction coefficient, \\(U(x)\\) is the potential energy, and \\(\\xi(t)\\) is Gaussian white noise with:\n\\[\\langle\\xi(t)\\rangle = 0, \\quad \\langle\\xi(t)\\xi(t')\\rangle = 2\\gamma k_B T \\delta(t-t')\\]\nThe noise amplitude is related to the friction coefficient through the fluctuation-dissipation relation, a consequence of thermal equilibrium. This relation embodies a deep physical principle: the same microscopic processes that cause energy dissipation (friction) also generate fluctuations (noise), with temperature determining their relative strength.\nUnderstanding the Langevin equation is crucial as it serves as a conceptual bridge between equilibrium and non-equilibrium physics. When modeling active particles, we extend this framework by adding a self-propulsion term. The simplest model of an active Brownian particle (ABP) incorporates a propulsion force of constant magnitude but with a direction that changes through rotational diffusion:\n\\[\\gamma\\frac{d\\mathbf{r}}{dt} = -\\nabla U(\\mathbf{r}) + \\gamma v_0 \\mathbf{n}(t) + \\boldsymbol{\\xi}(t)\\]\nwhere \\(v_0\\) represents the swimming speed and \\(\\mathbf{n}(t)\\) is a unit vector undergoing rotational diffusion. This seemingly simple modification profoundly transforms the physics, leading to enhanced diffusion, boundary accumulation, and novel collective behaviors unlike anything seen in passive systems.\nIn many situations relevant to colloidal systems and active matter, inertial effects can be neglected, leading to the overdamped limit of the Langevin equation:\n\\[\\gamma\\frac{dx}{dt} = -\\frac{dU(x)}{dx} + \\xi(t)\\]\nThis overdamped approximation accurately describes microscopic active systems such as bacterial suspensions, catalytic Janus particles, and colloidal rollers. In these systems, the Reynolds number is extremely low (typically 10^-5 to 10^-2), meaning viscous forces dominate over inertial forces. Consequently, particles stop moving almost instantaneously when propulsion ceases—a counterintuitive behavior compared to our macroscopic experience where objects continue moving due to inertia.\nThe Langevin framework will serve as our starting point for understanding how active systems systematically violate equilibrium principles. As we explore further, we’ll see that active matter requires expanding our theoretical tools beyond equilibrium statistical mechanics to account for the continuous energy input that drives these fascinating systems far from equilibrium.\n\n\n\nAt its core, the FDT tells us something remarkable: by simply watching how a system naturally fluctuates at equilibrium, we can predict exactly how it will respond when we deliberately perturb it. This powerful connection works because in equilibrium systems, the same thermal processes drive both phenomena.\nImagine tracking the position of a colloidal particle in a harmonic trap. The particle jiggles around due to random collisions with fluid molecules. The FDT tells us that these natural fluctuations contain all the information we need to know how the particle would respond if we were to push it with a small external force.\nMathematically, we describe this using two key functions:\n\nThe correlation function \\(C_{ij}(t-t')\\) measures how fluctuations are related in time:\n\n\\[C_{ij}(t-t') = \\langle x_i(t) x_j(t') \\rangle - \\langle x_i(t) \\rangle \\langle x_j(t') \\rangle\\]\nThis is something we can directly measure in experiments by tracking a system over time and calculating how variables at different times relate to each other.\n\nThe response function \\(\\chi_{ij}(t-t')\\) tells us how the system responds to external forces:\n\n\\[\\chi_{ij}(t-t') = \\frac{\\delta \\langle x_i(t) \\rangle}{\\delta h_j(t')}\\]\nThis represents how much variable \\(x_i\\) changes at time \\(t\\) when we apply a small force \\(h_j\\) at an earlier time \\(t'\\).\nThe fluctuation-dissipation theorem connects these two functions through temperature. For a system at equilibrium:\n\\[\\chi_{ij}(t-t') = -\\frac{1}{k_B T} \\frac{d}{dt} C_{ij}(t-t') \\quad \\text{for } t &gt; t'\\]\nIn experiments, it’s often more convenient to work in the frequency domain (using Fourier transforms):\n\\[\\chi_{ij}''(\\omega) = \\frac{\\omega}{2k_B T} C_{ij}(\\omega)\\]\nHere, \\(\\chi_{ij}''(\\omega)\\) is the imaginary part of the response function (related to energy dissipation) and \\(C_{ij}(\\omega)\\) is the power spectrum of fluctuations at frequency \\(\\omega\\).",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lecture02/lecture02.html#violation-in-active-systems",
    "href": "lecture02/lecture02.html#violation-in-active-systems",
    "title": "Non-equilibrium Statistical Mechanics",
    "section": "",
    "text": "For active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:\n\\[W_{h_j \\to h_i}^{act} P^{ss}(h_j) \\neq W_{h_i \\to h_j}^{act} P^{ss}(h_i)\\]\nwhere \\(P^ss\\) denotes the non-equilibrium steady state distribution.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "lecture02/lecture02.html#examples",
    "href": "lecture02/lecture02.html#examples",
    "title": "Non-equilibrium Statistical Mechanics",
    "section": "Examples",
    "text": "Examples\n\nTwo Brownian particles with non-uniform temperatures\nTo concretely illustrate how equilibrium concepts apply to coupled systems and how they break down when thermal equilibrium is violated, let’s consider a simple model: two Brownian particles connected by springs, with different temperatures.\nConsider the following system: - Two Brownian particles with positions \\(x_1\\) and \\(x_2\\) - Particle 1 is connected to a fixed wall by a spring with constant \\(k_1\\) - The two particles are connected to each other by a spring with constant \\(k_2\\) - Particle 2 is connected to a fixed wall by a spring with constant \\(k_3\\) - Particle 1 experiences thermal fluctuations at temperature \\(T_1\\) - Particle 2 experiences thermal fluctuations at temperature \\(T_2\\)\nThe Langevin equations for this system are:\n\\[\\gamma_1 \\frac{dx_1}{dt} = -k_1 x_1 - k_2(x_1 - x_2) + \\xi_1(t)\\] \\[\\gamma_2 \\frac{dx_2}{dt} = -k_3 x_2 - k_2(x_2 - x_1) + \\xi_2(t)\\]\nwhere \\(\\gamma_i\\) are the friction coefficients and \\(\\xi_i(t)\\) are Gaussian white noises with:\n\\[\\langle \\xi_i(t) \\rangle = 0, \\quad \\langle \\xi_i(t) \\xi_i(t') \\rangle = 2\\gamma_i k_B T_i \\delta(t-t')\\]\nWhen \\(T_1 = T_2\\), this system is in thermal equilibrium, and the probability distribution for the positions follows the Boltzmann distribution:\n\\[P(x_1, x_2) \\propto \\exp\\left(-\\frac{1}{k_B T}[k_1 x_1^2/2 + k_2(x_1-x_2)^2/2 + k_3 x_2^2/2]\\right)\\]\nHowever, when \\(T_1 \\neq T_2\\), the system is driven out of equilibrium, leading to a non-Boltzmann stationary distribution. The correlation between \\(x_1\\) and \\(x_2\\) encodes information about the non-equilibrium nature of the system.\n\n\n\n\n\n\nFigure 3: Brownian-dynamics simulation of 1D bead-spring model. (A) Model schematic. (B) Time series of the bead positions for T2 = 1.5T1 and equal spring constants. See figs. S4 and S5 for the general case (18). (C and D) Probability distribution (color) and flux map (white arrows) in CGPS spanned by x1 and x2 for the simulation in panel B (C) and for a simulation with T2 = T1 (D). Translucent disks represent a 2s confidence interval for fluxes. source\n\n\n\nIn this non-equilibrium scenario, energy flows from the hotter to the colder particle, driving the system away from equilibrium. The stationary state represents a balance between this energy flow and dissipation, rather than a state of maximum entropy as in equilibrium systems. The detailed balance condition is violated, and the system exhibits persistent probability currents in phase space - a hallmark of non-equilibrium behavior.\n\n\nChlamydomonas Swimming\nThe violation of detailed balance is perhaps the most direct signature of non-equilibrium behavior in active matter. The microalgae Chlamydomonas Reinhardtii provides an exemplary demonstration of this principle.\n\n\n\n\n\n\nFigure 4: Light microscopy image of Chlamydomonas Reinhardtii, a single-celled green alga with two flagella used for swimming and sensing. source\n\n\n\nChlamydomonas Reinhardtii propels itself through fluid by coordinated beating of its two flagella. This motion requires continuous energy consumption, as each flagellum hydrolyzes ATP to power molecular motors that generate rhythmic beating patterns. Unlike passive Brownian particles, where motion arises from random thermal fluctuations, the flagellar beating represents a driven, non-equilibrium process.\nAs shown in the figures below, researchers have characterized this non-equilibrium behavior by analyzing the flagellar dynamics in a coarse-grained phase space (CGPS) constructed from the principal bending modes. The beating patterns can be decomposed into these fundamental modes (similar to Fourier components), allowing quantitative tracking of the flagellar configuration over time.\nThe phase space probability distribution and corresponding flux maps reveal a striking signature of non-equilibrium dynamics: coherent probability currents that form closed loops. These directed cyclic trajectories through configuration space explicitly violate detailed balance, which would require all microscopic transitions to be pairwise-balanced with no net probability flux between states. In an equilibrium system, transitions between any two states would occur with equal frequency in both directions when properly weighted by their equilibrium probabilities.\n\n\n\n\n\n\nFigure 5: Detailed balance and actively beating Chlamydomonas flagella. (A) In thermodynamic equilibrium, transitions between microscopic states are pairwise-balanced, precluding net flux among states. (B) Nonequilibrium steady states can break detailed balance and exhibit flux loops. (C) Snapshots separated by 24 (orange-yellow), 7, and 10 ms in an isolated Chlamydomonas flagellum’s beat cycle (movie S1). Arrows on the central circle indicate the direction of time. Color corresponds to position in (E). (D) The first three bending modes for a freely suspended flexible rod. (E) A three-dimensional (3D) probability flux map of flagellar dynamics in the CGPS spanned by the first three modes.source\n\n\n\nThe flux maps in panels F and G below show clear rotational currents in the phase space of bending modes. These currents represent the flagellum cycling through configurations in a specific sequence rather than randomly exploring available states as would occur in thermal equilibrium. The directed nature of these probability currents directly quantifies the system’s departure from equilibrium.\n\n\n\n\n\n\nFigure 6: (F and G) Probability distribution (color) and flux map (white arrows) of flagellar dynamics in CGPS spanned by first and second modes (F), and first and third modes (G). The white legend indicates the flux scale. source\n\n\n\nThese probability flux loops are fundamental to biological function, enabling directed motion and mechanical work that would be thermodynamically prohibited under equilibrium constraints. Similar non-equilibrium dynamics appear in many biological systems, from molecular motors and cell migration to collective tissue behaviors, where energy consumption drives the system away from equilibrium to perform essential biological functions.\n\n\nPrimary cilia in epithelial cells\nPrimary cilia represent another biological system that exhibits non-equilibrium dynamics, but in a more subtle manner than the flagella of Chlamydomonas. These hairlike organelles project from many eukaryotic cells and transduce mechanical and chemical stimuli into intracellular signals. Unlike flagella, primary cilia often lack the dynein machinery necessary for active beating, causing them to fluctuate in what appears to be a random manner.\nWhen analyzed in the phase space defined by their deflection angle and curvature, primary cilia of MDCK (Madin-Darby canine kidney) epithelial cells reveal clockwise circulation patterns in their probability flux maps. These patterns indicate broken detailed balance, providing direct evidence of non-equilibrium dynamics in these seemingly passive structures. The statistical significance of these flux loops can be quantified, confirming that these cilia indeed operate far from equilibrium despite their apparently random motion.\n\n\n\n\n\n\nFigure 7: Left: Schematic of primary cilium and anchoring of the basal body in the cell cortex with angle q and curvature, k, defined positive as shown. Right: Snapshots of cilium, from differential interference contrast microscopy, taken at time points marked in (B). Scale bar: 2 mm.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Active Matter Physics",
    "section": "",
    "text": "Header",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Active Matter Physics",
    "section": "Course Overview",
    "text": "Course Overview\nThe course will examine both natural and synthetic active matter systems across multiple scales:\n\nBiological active matter: From the cytoskeleton and subcellular structures to bacterial suspensions, cell tissues, and animal groups\nSynthetic active matter: Including artificial microswimmers, active colloids, and engineered systems that mimic biological functionality\n\nStudents will gain a fundamental understanding of how local energy consumption at the individual unit level drives remarkable collective behaviors like self-organization, pattern formation, and spontaneous flows through non-equilibrium processes.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#key-concepts-and-topics",
    "href": "index.html#key-concepts-and-topics",
    "title": "Active Matter Physics",
    "section": "Key Concepts and Topics",
    "text": "Key Concepts and Topics\n\nFoundations of non-equilibrium statistical physics\nMicroscopic and continuum theoretical frameworks\nExperimental techniques and model systems\nSelf-propulsion mechanisms and motility\nPhase transitions specific to active systems\nEmergence of collective motion and flocking\nActive turbulence and topological defects\nMechanical properties of active materials\nBiological applications and biomimetic engineering\n\nThe course will balance theoretical principles with experimental observations, emphasizing the universal physical mechanisms that govern these diverse systems despite their different microscopic details.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Active Matter Physics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nUpon completion, students will be able to: - Identify and analyze active matter systems across disciplines - Apply theoretical models to predict behavior in active systems - Understand the key differences between equilibrium and non-equilibrium phenomena - Connect fundamental physical principles to biological functions - Appreciate the potential applications in materials science, robotics, and biomedicine\nThis course is suitable for advanced undergraduate and graduate students with backgrounds in physics, engineering, biophysics, or related fields.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "lecture02/entropy_and_time_reversal.html",
    "href": "lecture02/entropy_and_time_reversal.html",
    "title": "Entropy and Time Reversal",
    "section": "",
    "text": "Entropy production lies at the heart of non-equilibrium thermodynamics and provides a quantitative measure of how far a system is driven from equilibrium. While equilibrium systems maximize their entropy and remain there, active systems continuously produce entropy, reflecting their persistent consumption of energy to maintain non-equilibrium steady states.\n\n\nThe total entropy production rate can be split into two contributions:\n\\[\\dot{S}_{tot} = \\dot{S}_{sys} + \\dot{S}_{env}\\]\nwhere \\(\\dot{S}_{sys}\\) is the rate of change of the system’s Shannon entropy and \\(\\dot{S}_{env}\\) is the entropy production rate in the environment. In a steady state, \\(\\dot{S}_{sys} = 0\\), so \\(\\dot{S}_{tot} = \\dot{S}_{env} &gt; 0\\).\nFor a system described by a probability distribution \\(P(\\mathbf{x},t)\\) over states \\(\\mathbf{x}\\), the entropy production rate can be expressed as:\n\\[\\dot{S}_{tot} = k_B \\int d\\mathbf{x} \\, J(\\mathbf{x},t) \\cdot F(\\mathbf{x},t) \\geq 0\\]\nwhere \\(J(\\mathbf{x},t)\\) is the probability current and \\(F(\\mathbf{x},t)\\) is the thermodynamic force. This formula reveals a profound insight: entropy production occurs when probability currents flow along thermodynamic forces.\n\n\n\nThe probability currents we observed in our examples—the two Brownian particles with different temperatures and the Chlamydomonas flagella—directly contribute to entropy production. In fact, these circulatory flows in phase space are not just signatures of non-equilibrium behavior; they quantify the system’s entropy production rate.\nFor Brownian dynamics in the overdamped regime, the entropy production rate can be written as:\n\\[\\dot{S}_{tot} = \\frac{k_B}{\\gamma} \\int d\\mathbf{x} \\, \\frac{|J(\\mathbf{x})|^2}{P(\\mathbf{x})}\\]\nThis expression makes a remarkable connection: the entropy production rate is proportional to the squared magnitude of the probability current density normalized by the probability distribution. Systems with stronger circulation in probability space produce entropy at a higher rate.\n\n\n\n\n\n\nFigure 1: Entropy production in a non-equilibrium system. Left: Probability distribution and currents in phase space. Right: The local entropy production rate, showing the highest values where currents flow through regions of low probability. [source: schematic representation]\n\n\n\n\n\n\nHow can we actually measure entropy production in experiment? Several approaches have been developed:\n\nCurrent-based methods: By measuring the probability density and current as in our examples with two Brownian particles and Chlamydomonas, we can directly compute the entropy production using the formula above.\nTrajectory-based methods: For single-particle tracking data, the entropy production can be estimated by:\n\\[\\dot{S}_{est} = \\frac{1}{4\\tau} \\sum_i \\left\\langle \\left( \\frac{p(x_i \\to x_{i+1})}{p(x_{i+1} \\to x_i)} \\right) \\right\\rangle\\]\nwhere \\(p(x_i \\to x_{i+1})\\) represents the transition probability between states observed in the trajectory.\nTime asymmetry methods: By quantifying the statistical irreversibility of trajectories:\n\\[\\dot{S}_{est} = \\frac{k_B}{\\tau} D_{KL}(P[X(t)] || P[\\tilde{X}(t)])\\]\nwhere \\(D_{KL}\\) is the Kullback-Leibler divergence between the probability distributions of forward trajectories \\(X(t)\\) and time-reversed trajectories \\(\\tilde{X}(t)\\).\n\n\n\n\nDifferent active systems show distinctive patterns of entropy production:\n\nSelf-propelled particles: For active Brownian particles with persistent motion, entropy production scales with the square of the active force and inversely with the rotational diffusion coefficient:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B v_0^2}{2D_r}\\]\nwhere \\(v_0\\) is the swimming speed and \\(D_r\\) is the rotational diffusion coefficient.\nMolecular motors: For molecular motors like kinesin or myosin, entropy production is directly linked to ATP hydrolysis:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B \\Delta\\mu}{k_B T} r_{ATP}\\]\nwhere \\(\\Delta\\mu\\) is the chemical potential difference from ATP hydrolysis and \\(r_{ATP}\\) is the ATP consumption rate.\nTissue dynamics: In cellular tissues, entropy production has been linked to cell division, death, and migration processes. Recent studies have used optically-driven phase transitions to quantify entropy production in living tissues.\n\n\n\n\nIn contrast to the maximum entropy principle of equilibrium systems, some non-equilibrium steady states follow a principle of minimum entropy production, where the system adopts the configuration that produces entropy at the minimum rate required to maintain its non-equilibrium state.\nHowever, active matter systems typically operate far from the near-equilibrium regime where this principle applies. Instead, they exist in regimes of strong driving where entropy production can be significant and is often channeled into performing useful functions like motility, transport, or pattern formation."
  },
  {
    "objectID": "lecture02/entropy_and_time_reversal.html#entropy-production-in-active-systems",
    "href": "lecture02/entropy_and_time_reversal.html#entropy-production-in-active-systems",
    "title": "Entropy and Time Reversal",
    "section": "",
    "text": "Entropy production lies at the heart of non-equilibrium thermodynamics and provides a quantitative measure of how far a system is driven from equilibrium. While equilibrium systems maximize their entropy and remain there, active systems continuously produce entropy, reflecting their persistent consumption of energy to maintain non-equilibrium steady states.\n\n\nThe total entropy production rate can be split into two contributions:\n\\[\\dot{S}_{tot} = \\dot{S}_{sys} + \\dot{S}_{env}\\]\nwhere \\(\\dot{S}_{sys}\\) is the rate of change of the system’s Shannon entropy and \\(\\dot{S}_{env}\\) is the entropy production rate in the environment. In a steady state, \\(\\dot{S}_{sys} = 0\\), so \\(\\dot{S}_{tot} = \\dot{S}_{env} &gt; 0\\).\nFor a system described by a probability distribution \\(P(\\mathbf{x},t)\\) over states \\(\\mathbf{x}\\), the entropy production rate can be expressed as:\n\\[\\dot{S}_{tot} = k_B \\int d\\mathbf{x} \\, J(\\mathbf{x},t) \\cdot F(\\mathbf{x},t) \\geq 0\\]\nwhere \\(J(\\mathbf{x},t)\\) is the probability current and \\(F(\\mathbf{x},t)\\) is the thermodynamic force. This formula reveals a profound insight: entropy production occurs when probability currents flow along thermodynamic forces.\n\n\n\nThe probability currents we observed in our examples—the two Brownian particles with different temperatures and the Chlamydomonas flagella—directly contribute to entropy production. In fact, these circulatory flows in phase space are not just signatures of non-equilibrium behavior; they quantify the system’s entropy production rate.\nFor Brownian dynamics in the overdamped regime, the entropy production rate can be written as:\n\\[\\dot{S}_{tot} = \\frac{k_B}{\\gamma} \\int d\\mathbf{x} \\, \\frac{|J(\\mathbf{x})|^2}{P(\\mathbf{x})}\\]\nThis expression makes a remarkable connection: the entropy production rate is proportional to the squared magnitude of the probability current density normalized by the probability distribution. Systems with stronger circulation in probability space produce entropy at a higher rate.\n\n\n\n\n\n\nFigure 1: Entropy production in a non-equilibrium system. Left: Probability distribution and currents in phase space. Right: The local entropy production rate, showing the highest values where currents flow through regions of low probability. [source: schematic representation]\n\n\n\n\n\n\nHow can we actually measure entropy production in experiment? Several approaches have been developed:\n\nCurrent-based methods: By measuring the probability density and current as in our examples with two Brownian particles and Chlamydomonas, we can directly compute the entropy production using the formula above.\nTrajectory-based methods: For single-particle tracking data, the entropy production can be estimated by:\n\\[\\dot{S}_{est} = \\frac{1}{4\\tau} \\sum_i \\left\\langle \\left( \\frac{p(x_i \\to x_{i+1})}{p(x_{i+1} \\to x_i)} \\right) \\right\\rangle\\]\nwhere \\(p(x_i \\to x_{i+1})\\) represents the transition probability between states observed in the trajectory.\nTime asymmetry methods: By quantifying the statistical irreversibility of trajectories:\n\\[\\dot{S}_{est} = \\frac{k_B}{\\tau} D_{KL}(P[X(t)] || P[\\tilde{X}(t)])\\]\nwhere \\(D_{KL}\\) is the Kullback-Leibler divergence between the probability distributions of forward trajectories \\(X(t)\\) and time-reversed trajectories \\(\\tilde{X}(t)\\).\n\n\n\n\nDifferent active systems show distinctive patterns of entropy production:\n\nSelf-propelled particles: For active Brownian particles with persistent motion, entropy production scales with the square of the active force and inversely with the rotational diffusion coefficient:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B v_0^2}{2D_r}\\]\nwhere \\(v_0\\) is the swimming speed and \\(D_r\\) is the rotational diffusion coefficient.\nMolecular motors: For molecular motors like kinesin or myosin, entropy production is directly linked to ATP hydrolysis:\n\\[\\dot{S}_{tot} \\approx \\frac{k_B \\Delta\\mu}{k_B T} r_{ATP}\\]\nwhere \\(\\Delta\\mu\\) is the chemical potential difference from ATP hydrolysis and \\(r_{ATP}\\) is the ATP consumption rate.\nTissue dynamics: In cellular tissues, entropy production has been linked to cell division, death, and migration processes. Recent studies have used optically-driven phase transitions to quantify entropy production in living tissues.\n\n\n\n\nIn contrast to the maximum entropy principle of equilibrium systems, some non-equilibrium steady states follow a principle of minimum entropy production, where the system adopts the configuration that produces entropy at the minimum rate required to maintain its non-equilibrium state.\nHowever, active matter systems typically operate far from the near-equilibrium regime where this principle applies. Instead, they exist in regimes of strong driving where entropy production can be significant and is often channeled into performing useful functions like motility, transport, or pattern formation."
  },
  {
    "objectID": "lecture02/entropy_and_time_reversal.html#time-reversal-symmetry-breaking",
    "href": "lecture02/entropy_and_time_reversal.html#time-reversal-symmetry-breaking",
    "title": "Entropy and Time Reversal",
    "section": "Time-reversal symmetry breaking",
    "text": "Time-reversal symmetry breaking\nTime-reversal symmetry is a fundamental concept describing whether the laws governing a system’s dynamics are invariant under the transformation \\(t \\to -t\\). While microscopic physical laws are largely time-reversal invariant, macroscopic behaviors often show a clear arrow of time due to statistical considerations embodied in the second law of thermodynamics.\n\nFormal definition\nA system has time-reversal symmetry if the probability of observing a trajectory \\(\\Gamma = \\{x(t_0), x(t_1), ..., x(t_N)\\}\\) equals the probability of observing the reversed trajectory \\(\\tilde{\\Gamma} = \\{x(t_N), x(t_{N-1}), ..., x(t_0)\\}\\) when appropriately accounting for the initial conditions:\n\\[P[\\Gamma|x(t_0)] = P[\\tilde{\\Gamma}|x(t_N)]\\]\nIn equilibrium systems, this symmetry is guaranteed by detailed balance. However, active systems break this symmetry, leading to trajectories that look fundamentally different when viewed forward versus backward in time.\n\n\nConnection to detailed balance\nAs we saw earlier, detailed balance requires:\n\\[W_{i \\to j} P_i^{eq} = W_{j \\to i} P_j^{eq}\\]\nThis microscopic reversibility ensures that any net flow between states vanishes at equilibrium. When detailed balance is violated—as in all active systems—we observe:\n\\[W_{i \\to j} P_i^{ss} \\neq W_{j \\to i} P_j^{ss}\\]\nwhere \\(P^{ss}\\) represents the non-equilibrium steady state. This inequality manifests as persistent circulation patterns in the probability currents, which we observed in our examples.\n\n\nQuantifying time-reversal symmetry breaking\nTime-reversal symmetry breaking can be quantified using several approaches:\n\nIrreversibility measure: For a stationary process, the degree of irreversibility can be quantified using the Kullback-Leibler divergence:\n\\[I = D_{KL}(P[\\Gamma] || P[\\tilde{\\Gamma}]) = \\left\\langle \\ln \\frac{P[\\Gamma]}{P[\\tilde{\\Gamma}]} \\right\\rangle_\\Gamma\\]\nThis measure quantifies how distinguishable the forward and time-reversed processes are.\nCycling frequencies: In systems that exhibit cyclic behavior (like the Chlamydomonas flagella), the net cycling frequency in phase space provides a direct measure of time-reversal symmetry breaking:\n\\[\\omega_{cycling} = \\frac{1}{2\\pi} \\oint_C \\frac{\\mathbf{J}(\\mathbf{x})}{P(\\mathbf{x})} \\cdot d\\mathbf{l}\\]\nwhere the integral is taken around a closed loop in phase space.\nArea encircled by probability currents: The area enclosed by probability current loops in phase space directly quantifies the magnitude of time-reversal symmetry breaking.\n\n\n\n\n\n\n\nFigure 2: Illustration of time-reversal symmetry breaking. Top: A trajectory in phase space of an equilibrium system looks statistically the same forward and backward in time. Bottom: In a non-equilibrium system, the backward trajectory is statistically distinguishable from the forward trajectory. [source: schematic representation]\n\n\n\n\n\nObservational consequences\nTime-reversal symmetry breaking manifests in various observable phenomena:\n\nEmergent currents: Persistent macroscopic currents can emerge even without external gradients, as seen in active turbulence or bacterial suspensions.\nOdd elasticity: Active materials can exhibit “odd” or non-reciprocal mechanical responses that would be forbidden in equilibrium systems.\nDirected transport: Active systems can perform directed transport against external gradients without violating the second law, as biological molecular motors demonstrate.\nChirality and ratchet effects: Time-reversal symmetry breaking often leads to preferential motion in one direction, which can be leveraged to design molecular ratchets and motors.\n\n\n\nThe arrow of time in active systems\nIn active systems, the arrow of time manifests not just at the macroscopic level (as it does in passive systems through the second law) but also at the mesoscopic level of individual active agents.\nConsider again our Chlamydomonas example: the flagellar beating cycle has a well-defined sequence that breaks time-reversal symmetry at the scale of the individual cell. Playing a video of the flagellar motion backward would immediately reveal that something is “wrong,” even without statistical analysis.\nThis microscopic breaking of time-reversal symmetry distinguishes active matter from passive non-equilibrium systems, where the arrow of time typically emerges only at macroscopic scales or through statistical averages.\nThe magnitude of time-reversal symmetry breaking in active systems is directly related to their energy consumption rate. More energy input generally leads to stronger breaking of time-reversal symmetry, creating systems that are further from equilibrium and capable of more complex emergent behaviors.\nIn conclusion, time-reversal symmetry breaking provides a fundamental lens through which we can understand active matter. By quantifying this symmetry breaking, we gain insight into the essential non-equilibrium character of active systems and the mechanisms through which they harness energy to perform biological functions or create novel material properties."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is the Active Matter Physics website."
  },
  {
    "objectID": "course-info/resources.html",
    "href": "course-info/resources.html",
    "title": "Resources",
    "section": "",
    "text": "Books on Soft Matter\n\nJacob N. Israelachvili: Intermolecular and Surface Forces: With Applications to Colloidal and Biological Systems (Academic Press)\nRob Phillips, Jane Kondev, Julie Theriot: Physical Biology of the Cell (Garland Science)\nRichard A.L. Jones: Soft Condensed Matter (Oxford University Press)\nMichael Rubinstein, Ralph H. Colby: Polymer Physics (Oxford University Press)\nJonathan Howard: Mechanics of Motor Proteins and the Cytoskeleton (Sinauer Associates)\nM. Doi and S.F. Edwards: The Theory of Polymer Dynamics (Oxford Academic Press)\nP.G. de Gennes and J. Prost: The Physics of Liquid Crystals (Oxford Academic Press)\n\n\n\nThe Active Matter Book\n\nActive Matter Book",
    "crumbs": [
      "Course Info",
      "Resources"
    ]
  },
  {
    "objectID": "course-info/schedule.html",
    "href": "course-info/schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This course is a master course in physics to introduce into the field of active matter. The course is comprising a series of lectures and exercise sessions, which allow students to apply the concepts learned in the lectures to real-world problems.\nThe lectures will take place in person every\nThursday, 9:15 AM SR 224\nstarting April 10th.\nThe seminars will take place in person every\nThursday, 11:00 AM SR 224\nstarting April 1Xth.\nThe exam will be oral and dates witll be provided during the lecture period.",
    "crumbs": [
      "Course Info",
      "Course Schedule"
    ]
  },
  {
    "objectID": "lecture01/lecture01.html",
    "href": "lecture01/lecture01.html",
    "title": "Introduction to Active Matter",
    "section": "",
    "text": "The study of active matter emerged in the late 20th century at the intersection of soft matter physics, biophysics, and statistical mechanics. An important precursor to the field came from computer graphics, where Craig Reynolds developed the Boids simulation in 1986 - an artificial life program that demonstrated how simple rules governing individual agents could produce realistic flocking behaviors in computer animations. Earlier cellular automata models like Conway’s Game of Life had also shown how simple rules could lead to complex emergent behaviors, helping establish some of the conceptual foundations for understanding collective systems.\n\n\n\n\n\n\n\n\n  \n    Reset Simulation\n  \n  \n    Separation: \n    Alignment: \n    Cohesion: \n  \n\n\n\n\n\n\nFigure 1: Interactive simulation of the Boids model, where you can adjust the three key parameters that govern flocking behavior: separation (avoidance of crowding), alignment (steering towards average heading), and cohesion (steering towards center of mass).\n\n\n\n\n\n\n\n\n\nThe Boids Model Explained\n\n\n\n\n\nThe Boids model, developed by Craig Reynolds in 1986, simulates the flocking behavior of birds using three simple rules:\n\nSeparation: Each boid avoids crowding nearby flockmates, steering away when they get too close.\nAlignment: Each boid aligns its direction of flight with nearby flockmates, matching their average velocity.\nCohesion: Each boid moves toward the center of mass of nearby flockmates, creating a tendency to stick together.\n\nThese local interaction rules, when applied to all individuals simultaneously, produce complex global behaviors that remarkably resemble natural flocking patterns. The simulation above demonstrates how adjusting these three parameters affects the emergent collective motion:\n\nHigh separation, low alignment, low cohesion: Dispersed individuals with minimal coordination\nLow separation, high alignment, medium cohesion: Coherent flocking with directional movement\nBalanced parameters: Natural-looking flocking behaviors with dynamic subgroup formation\n\nThis model illustrates a fundamental principle in active matter physics: complex collective behaviors can emerge from simple local rules without centralized control.\n\n\n\nThis computational model later influenced physical approaches to collective motion. Early foundational work by scientists like T. Vicsek in the 1990s established computational models for collective motion, particularly his 1995 paper introducing what is now known as the Vicsek model for self-propelled particles with alignment interactions. Prior to this, early biological observations of collective behaviors in nature, such as bird flocking and fish schooling, had long fascinated scientists but lacked rigorous physical frameworks. The field gained significant momentum in the late 1990swith seminal papers by John Toner and Yuhai Tu, who published their groundbreaking work on flocking theory in 1995, and later Sriram Ramaswamy who developed continuum theories for active nematics.\nThe theoretical foundations were further strengthened by contributions from European researchers like Michael Cates (Edinburgh), Jean-François Joanny (Paris), and Jacques Prost (Paris), who developed the active gel theory to describe cytoskeletal dynamics in the mid-2000s. Simultaneously, M. Cristina Marchetti and her collaborators formulated comprehensive hydrodynamic theories for active systems across various symmetry classes. Sriram Ramaswamy made fundamental contributions through his work on active liquid crystals and the development of generic hydrodynamic theories for active matter. The pioneering work of John Toner and Yuhai Tu established the theoretical framework for understanding the emergence of long-range order in flocking systems, demonstrating how activity can stabilize orientational order even in two dimensions. Julia Yeomans (Oxford) advanced our understanding of active turbulence and topological defects in active nematics through innovative computational approaches, while Hartmut Löwen (Düsseldorf) developed influential theories for the collective behavior of active Brownian particles and motility-induced phase separation. These theoretical advances were complemented by experimental breakthroughs, notably Howard Berg’s groundbreaking work in the 1970s at Harvard on bacterial chemotaxis and motility, where he developed the tracking microscope to follow individual E. coli bacteria and discovered their run-and-tumble motion patterns. Additional experimental contributions came from Raymond Goldstein (Cambridge) and others who established quantitative measurements of collective motion in bacterial systems.\nExperimental breakthroughs with bacterial suspensions (notably work by Igor Aranson and Raymond Goldstein on Bacillus subtilis), cell tissues (including Xavier Trepat’s research at IBEC in Barcelona on epithelial cell sheets), and synthetic active colloids (pioneered by European researchers like Jérémie Palacci (Lyon/San Diego), Julien Perrin (Paris), and Clemens Bechinger (Konstanz/Stuttgart) with light-activated Janus particles) further propelled the field forward. The development of artificial microswimmers by international collaborations involving European teams led by Roberto Di Leonardo (Rome), Ramin Golestanian (Oxford/Göttingen), and Frank Cichos (Leipzig), alongside US-based researchers like Steve Granick and Ayusman Sen, opened new avenues for creating controllable active systems outside biological contexts.\nBy the 2010s, active matter had developed into a distinct discipline with dedicated conferences and research groups worldwide. The establishment of specialized research centers across Europe such as the Max Planck Institute for Dynamics and Self-Organization in Göttingen, the Physics of Living Matter Group at Cambridge, the Biological Physics and Morphogenesis groups at MPIPKS Dresden, alongside the Syracuse Soft and Living Matter Program, the Center for the Physics of Biological Function at Princeton, and the Active Matter Lab at MIT reflected the field’s growing importance. Major milestones included the observation of motility-induced phase separation by Michael Cates (Edinburgh) and Julien Tailleur (Paris) (2013), the discovery of topological defect motility in active nematics by Zvonimir Dogic and collaborators (2014), and the creation of the first autonomous active material capable of performing work by Daniela Wilson’s group (Nijmegen) (2019). The field continues to expand with increasing interdisciplinary collaborations between physicists, biologists, materials scientists, and engineers, addressing fundamental questions in non-equilibrium physics while developing applications in biomedicine, soft robotics, and smart materials.\n\n\n\nUnderstanding how active matter systems differ from equilibrium systems is crucial for developing new theoretical frameworks and experimental approaches. The continuous energy input and self-driven nature of active matter leads to behaviors that challenge our traditional physics understanding. Consider the following key distinctions between equilibrium and active matter systems:\n\n\n\n\n\n\n\n\nFeature\nEquilibrium Systems\nActive Matter Systems\n\n\n\n\nDetailed Balance\nForward and reverse processes occur at equal rates\nContinuously broken through energy consumption, driving the system away from equilibrium\n\n\nFluctuation-Dissipation Theorem\nValid relationship between spontaneous fluctuations and response to external perturbations\nBreaks down as fluctuations can be driven by internal activity\n\n\nParticle Motion\nRandom Brownian motion\nPersistent directional motion over certain timescales\n\n\nStatistical Distributions\nFollow Boltzmann statistics\nNon-Boltzmann statistics, making standard thermodynamic tools inapplicable\n\n\nMacroscopic Currents\nAbsent in steady states\nCan sustain macroscopic currents and flux cycles even in steady states\n\n\nPhase Behavior\nWell-established equilibrium phases\nUnique phase transitions with no equilibrium counterparts (e.g., motility-induced phase separation, active turbulence)\n\n\nMechanical Pressure\nIndependent of boundary properties\nCan depend on properties of confining walls, violating equilibrium equations of state\n\n\nEnergy and Entropy\nMinimize free energy, maximize entropy\nContinuously dissipate energy and produce entropy even in steady states\n\n\nTime-Reversal Symmetry\nDynamics appear similar when played forward or backward\nDynamics look distinctly different when played forward versus backward\n\n\nForce Characteristics\nDerivable from a potential energy function\nCannot generally be derived from a potential energy function\n\n\n\n\n\n\nActive matter encompasses a diverse range of systems, from biological organisms to synthetic particles, that share the common feature of continuously converting energy into systematic motion. These systems can be organized into several categories based on their energy sources, symmetries, and the nature of their interactions, providing a framework for understanding their distinct behaviors and properties.\n\n\n\n\n\n\nFigure 2: Overview of active matter systems at different scales and domains. The field spans from microscopic biological systems like cellular components to macroscopic collective behaviors and engineered synthetic systems. (source)\n\n\n\nActive matter systems can be categorized based on several key characteristics:\n\nEnergy conversion mechanismSymmetry of motionMedium and interactionsStructural arrangementLength scale and dimensionality\n\n\n\nBiological active matter: Systems that convert chemical energy (ATP, nutrients) into mechanical work (e.g., bacteria, cells, tissues). These systems span multiple scales, from molecular motors like kinesin and myosin that transport cargo along cytoskeletal filaments, to cellular components such as the dynamic cytoskeleton that enables cell shape changes and migration. At multicellular scales, coordinated activity enables tissue morphogenesis during development, wound healing, and collective cell migration. The energy conversion typically involves ATP hydrolysis, which provides approximately 20 kT of energy per molecule, enabling these systems to perform work against thermal fluctuations. Unlike their synthetic counterparts, biological active matter often exhibits adaptive behaviors, feedback regulation, and hierarchical organization that enhances functionality and robustness.\n\n\n\n\n\n\n\n\n\nATP hydrolysis is the primary energy source in most cellular processes\n\n\n\n\n\n\n\nBacteria like E. coli use flagella powered by molecular motors\n\n\n\n\n\n\nFigure 3: ATP hydrolysis and bacterial motility represent key examples of chemical energy conversion in biological active matter\n\n\n\n\nSynthetic active matter: Engineered systems powered by external fields, chemical reactions, or light (e.g., Janus particles, active colloids). These artificial systems represent human-designed analogs to biological active matter, with scientists having precise control over their properties and behaviors. Synthetic active particles typically feature asymmetric structures or surface properties that enable self-propulsion. Common examples include Janus particles with catalyst-coated hemispheres that decompose hydrogen peroxide to create propulsion, light-activated particles that convert photonic energy into motion, and magnetically-actuated microswimmers that respond to oscillating external fields. Unlike biological systems, synthetic active matter can be designed with specific functionalities, such as targeted drug delivery, environmental remediation, or self-assembly into complex structures. Recent advances have produced programmable behaviors through responsive materials, feedback mechanisms, and even rudimentary “communication” between synthetic active agents.\n\n\n\n\n\n\n\nFigure 4: Synthetic active particles can be designed with asymmetric properties to enable self-propulsion through various mechanisms\n\n\n\n\n\n\nPolar active matter: Entities with defined front-back asymmetry and directional motion (e.g., birds, fish). These systems are characterized by particles or organisms that have a clear direction of motion and can align their movement with neighbors. For example, fish schools demonstrate this through their streamlined body shape that defines a clear swimming direction, while their lateral line system helps them align with neighboring fish. Similarly, migratory birds show polar order through their aerodynamic body structure and visual alignment with flock-mates during flight. At the microscopic scale, many bacteria like E. coli exhibit polar motion through their flagellar propulsion system that creates directed swimming. The polar nature of these systems often leads to unique collective phenomena like the emergence of large-scale coherent motion and the formation of traveling bands or density waves.\n\n\n\n\n\n\n\n\n\nFish schools demonstrate collective motion through simple alignment rules\n\n\n\n\n\n\n\nBird flocks exhibit emergent order through local interactions\n\n\n\n\n\n\nFigure 5: Examples of polar active matter: fish schools (source) and bird flocks (source)\n\n\n\n\nApolar active matter: Systems generating motion without a defined direction (e.g., melanocytes, active nematics). These systems exhibit interesting collective behaviors despite lacking a preferred direction of motion at the individual level. For example, melanocytes, the cells responsible for skin pigmentation, extend and retract protrusions in multiple directions as they move and distribute melanin. Similarly, active nematics, such as dense suspensions of microtubules and molecular motors, generate complex flows and defect dynamics without any preferred direction of motion for individual components. The apolar nature of these systems often leads to unique phenomena like the spontaneous formation and annihilation of topological defects, and the emergence of active turbulence in confined geometries.\n\n\n\n\n\n\n\n\n\nMelanocyte cells showing apolar migration patterns\n\n\n\n\n\n\n\nActive nematic liquid crystals with defect patterns\n\n\n\n\n\n\nFigure 6: Examples of apolar active matter: melanocytes (source) and active nematics (source)\n\n\n\n\nChiral active matter: Systems with inherent rotational motion or handedness. These systems exhibit systematic rotational motion in addition to translational movement, often due to structural asymmetry or biased force generation. Examples include bacterial flagella that rotate to create propulsion, sperm cells that swim with helical trajectories, and synthetic microswimmers with chiral shapes that spin as they move through fluid. The interplay between rotational and translational motion in these systems can lead to unique collective behaviors, such as the formation of rotating clusters or vortex arrays. At the microscopic scale, molecular motors like the bacterial flagellar motor demonstrate how nature utilizes chirality to generate motion, while at larger scales, schools of fish can form rotating vortex patterns through their collective swimming behavior.\n\n\n\n\nDry active matter: Systems where momentum dissipates to a substrate (e.g., cells on surfaces). In these systems, the primary interaction between particles occurs through direct contact or short-range forces, as the substrate quickly dampens any long-range hydrodynamic effects. A classic example is cells crawling on a surface, where the friction with the substrate dominates the dynamics. Another example is vibrated granular layers, where energy input causes particle motion but momentum is quickly dissipated through collisions with the base plate and between particles.\nWet active matter: Systems embedded in a fluid where hydrodynamic interactions dominate (e.g., bacterial suspensions). These systems exhibit complex long-range interactions mediated by the fluid, as the motion of each active particle creates flow fields that affect distant particles. Examples include swimming microorganisms in water, where the fluid flows generated by one organism can influence the motion of others several body lengths away. Active colloids in suspension also demonstrate these effects, where the chemical activity or motion of particles creates fluid flows that lead to collective behaviors and pattern formation.\n\n\n\n\nActive crystals: Ordered lattice-like arrangements with activity. These systems maintain crystalline order while individual units remain active, such as in bacterial colonies that form regular spatial patterns while each bacterium continues to move and metabolize. A key example is the formation of living crystals from light-activated colloidal particles, where the particles self-organize into a crystalline lattice while maintaining their individual motility.\nActive glasses: Disordered, jammed configurations with activity. Unlike traditional glasses, these systems combine structural disorder with persistent local motion, leading to unique dynamical behaviors. Examples include dense bacterial suspensions at high concentrations where cells become trapped in disordered configurations but continue to exert active forces on their neighbors, or crowded solutions of motor proteins and filaments where steric constraints create glassy dynamics despite ongoing ATP-driven activity.\nActive fluids/gases: Flowing systems with active components. These systems exhibit fluid-like behavior but with constituents that continuously inject energy at the microscopic scale. Examples range from dilute bacterial suspensions that show enhanced diffusion and collective motion, to dense active liquid crystals where the interplay between flow and orientational order creates complex dynamical patterns like active turbulence. In the gas-like regime, systems like midge swarms demonstrate how active particles can maintain cohesion while exhibiting fluid-like properties.\n\n\n\n\nMicroscopic: Cellular and subcellular systems (cytoskeleton, bacterial colonies). At this scale, active matter emerges from molecular motors like kinesin and dynein walking along cytoskeletal filaments, or the collective motion of bacterial cells in colonies. The cytoskeleton itself is a fascinating example where networks of actin filaments and microtubules, driven by ATP-powered molecular motors, create complex dynamics essential for cell function and division.\nMesoscopic: Tissue and organ-level organizations. At the tissue level, collective cell behavior leads to emergent phenomena like wound healing and morphogenesis during development. Epithelial tissues demonstrate active matter dynamics through coordinated cell migration and mechanical force transmission between neighboring cells. These intermediate scales bridge individual cell behavior with organ-level function.\n\n\n\n\n\n\n\nFigure 7: Time-lapse microscopy of Drosophila embryo development showing gastrulation and tissue folding - a striking example of how active matter principles govern morphogenesis. The coordinated cell shape changes and movements create complex three-dimensional structures from an initially simple tissue sheet. source\n\n\n\n\nMacroscopic: Animal groups, human crowds. Large-scale collective behaviors emerge in systems like bird flocks, fish schools, and human crowds in urban environments. These systems demonstrate how simple interaction rules between individuals can create complex, coordinated motion patterns that span hundreds or thousands of times the size of individual agents. Traffic flow and pedestrian dynamics are particularly relevant examples for urban planning and crowd safety.\nQuasi-2D vs. 3D systems: Systems confined to surfaces vs. fully three-dimensional systems. Many active matter systems are effectively two-dimensional, like bacterial colonies growing on agar plates or cells migrating on substrates. These confined geometries often simplify both experimental observation and theoretical analysis. In contrast, true three-dimensional systems like bacterial suspensions in fluid or cell movement in tissue matrices exhibit additional complexities due to hydrodynamic interactions and the full range of possible motion directions.\n\n\n\n\n\n\n\nThe theoretical description of active matter draws from and extends multiple branches of physics:\n\nKinetic theoriesContinuum field theoriesAgent-based and particle models\n\n\n\nBoltzmann-like approaches: Describing probability distributions of particle positions and orientations in active systems. For example, in bacterial suspensions, this approach tracks how the probability of finding bacteria with specific positions and swimming directions evolves over time. The key difference from classical Boltzmann equations is the inclusion of self-propulsion forces and alignment interactions. These equations have been particularly successful in describing the transition from disordered to ordered states in active systems like bird flocks and fish schools.\nFokker-Planck equations: Capturing the evolution of probability densities in phase space by incorporating both deterministic and stochastic effects. In active matter, these equations describe how probability distributions change due to systematic forces (like self-propulsion), random fluctuations (thermal or active noise), and interactions between particles. For instance, they can model how Janus particles move under the influence of chemical gradients while experiencing rotational diffusion, or how swimming bacteria respond to chemical attractants while subject to tumbling events.\nSmoluchowski equations: Modeling overdamped dynamics common in biological active systems where inertial effects are negligible compared to viscous forces. These equations are particularly relevant for microscopic swimmers like bacteria or colloidal particles where the Reynolds number is very small. They have been successfully applied to describe phenomena like bacterial chemotaxis, the collective motion of cell populations, and the dynamics of motor proteins along cytoskeletal filaments. A classic example is modeling E. coli’s run-and-tumble motion, where the Smoluchowski equation – the overdamped limit of the Fokker-Planck equation – captures the interplay between directed swimming and random reorientations.\n\n\n\n\nToner-Tu theory: A hydrodynamic framework that describes collective motion in flocking systems by incorporating broken continuous symmetry. This theory is particularly powerful for analyzing large systems, where it predicts true long-range order can exist even in two dimensions, in contrast to equilibrium systems. While real flocks are finite, the theory provides insights into large-scale behaviors like the scale-free correlations observed in starling murmurations, where thousands of birds maintain coherent motion despite environmental perturbations.\nActive gel theories: These theories extend traditional liquid crystal physics by incorporating force-generating active stresses. They are particularly successful in describing biological materials like the cell cytoskeleton, where molecular motors generate internal forces. A key example is explaining the spontaneous flows observed in actomyosin networks, where myosin motors walking along actin filaments create large-scale coherent motion.\nActive nematics: Field theories that describe systems with orientational order but no polar direction, driven out of equilibrium by active stresses. These theories have been instrumental in understanding phenomena like the chaotic dynamics of microtubule-kinesin mixtures, where energy input from molecular motors leads to the continuous creation, motion, and annihilation of topological defects, resulting in active turbulence.\nPhase field models: Mathematical frameworks that track the evolution of interfaces and boundaries in active systems without explicitly tracking individual particles. These models have been successfully applied to describe phenomena like cell membrane deformation during motility, tissue morphogenesis, and the dynamics of active droplets. For instance, they can capture how a crawling cell changes shape and moves by coupling chemical signals to mechanical deformations of the cell membrane.\n\n\n\n\nVicsek model: The foundational model for collective motion where particles move at constant speed and align their direction with neighbors within a certain radius, subject to noise. For example, in simulating bird flocks, each bird adjusts its direction to match the average flight direction of nearby birds, plus some random variation. This simple rule produces rich collective behaviors like the transition from disordered motion at high noise to coordinated flocking at low noise.\nActive Brownian particles: Self-propelled particles that maintain constant speed but undergo rotational diffusion, leading to persistent random walks. A classic example is light-activated Janus colloids - microscopic particles with one hemisphere coated in a light-responsive material. Under illumination, these particles swim in a directed manner but gradually change direction due to thermal fluctuations, resulting in motion that is ballistic at short times but diffusive at long times.\nRun-and-tumble models: These models capture the motion pattern of bacteria like E. coli, which alternate between straight “runs” and random “tumbles.” During runs, the bacteria swim in nearly straight lines using their flagella. Tumbles occur when the flagella bundle comes apart, causing the cell to randomly reorient. This mechanism allows bacteria to effectively explore their environment and respond to chemical gradients through biased random walks.\nActive Ornstein-Uhlenbeck particles: A model incorporating temporal correlations in the active propulsion force, leading to more realistic descriptions of biological swimmers. For instance, in modeling the motion of algae like Chlamydomonas, the swimming force isn’t purely random but shows correlations over the time scale of the flagellar beat cycle. This correlation produces more accurate predictions of diffusion and clustering behaviors compared to simpler active particle models.\n\n\n\n\n\n\n\nThe scientific study of active matter presents several key theoretical and experimental challenges that continue to motivate research and technological innovation in the field:\n\nExperimental challengesTheoretical challenges\n\n\n\nDiversity in propulsion mechanisms and functionality: Creating synthetic active particles with diverse propulsion strategies and functional capabilities remains challenging. Current systems are largely limited to chemical catalysis, light activation, or magnetic actuation. Beyond propulsion, developing particles capable of force generation, information processing, and programmable behaviors through compartmentalization and feedback control is crucial. This includes systems that can adapt their behavior based on environmental cues or machine learning algorithms.\nMulti-component systems: Developing heterogeneous active matter systems with different types of particles that can interact and coordinate. For example, combining light-activated and chemically-powered particles, or integrating passive and active components to create hierarchical structures with emergent behaviors.\nMeasurement techniques: Developing methods to track fast dynamics across multiple scales. Active matter systems often exhibit complex spatiotemporal dynamics that require simultaneous tracking of individual particles and collective behaviors. High-speed imaging, particle tracking, and flow visualization techniques must be adapted to capture both the rapid motion of individual active units and the slower evolution of large-scale patterns.\nSystem preparation: Creating synthetic particles with programmable behaviors and functions. The synthesis of active colloids requires careful control over particle size, shape, surface chemistry, and catalyst distribution, as well as the integration of responsive elements that enable specific functionalities. For instance, incorporating multiple catalytic or stimuli-responsive domains to create particles capable of complex tasks remains technically challenging.\nBoundary conditions: Controlling and characterizing interactions with surfaces. Active matter systems are highly sensitive to boundary conditions, which can significantly influence their behavior. Creating well-defined boundaries while maintaining activity and avoiding unwanted surface effects requires careful experimental design and characterization.\nEnergy input: Maintaining steady, uniform activation across synthetic systems. Whether through chemical fuel concentration, light intensity, magnetic fields, or electric fields, ensuring uniform activation throughout the sample volume is crucial. Challenges include maintaining constant H2O2 concentration for catalytic swimmers or uniform illumination for light-activated particles.\nTime limitations: Managing fuel depletion and particle degradation while maintaining function. Synthetic active systems face challenges like catalyst poisoning, fuel consumption, and photobleaching that can impair their ability to perform desired tasks. For chemical swimmers, local fuel depletion can create concentration gradients that affect particle behavior, while light-activated systems may suffer from photodamage over time.\nImaging limitations: Balancing spatial and temporal resolution with field of view. Active matter often requires both high-resolution imaging to track individual particles and wide-field observation to capture collective effects. This creates technical challenges in microscopy and imaging systems, particularly for three-dimensional systems.\nParameter space: Exploring vast parameter spaces with limited resources. Synthetic active matter systems have many tunable parameters including particle size, shape, surface chemistry, fuel concentration, and external field strengths. Systematically exploring these parameters while maintaining experimental consistency requires significant time and resources.\nSystem integration: Incorporating active matter into functional devices or materials while maintaining desired behaviors. Synthetic active matter experiments require careful integration with other components while preserving activity and function. Creating stable, reliable systems that can operate under real-world conditions presents significant engineering challenges.\n\n\n\n\nBridging scales: Connecting microscopic mechanisms to macroscopic behaviors. Active matter systems often exhibit behaviors across many orders of magnitude in length and time scales, making it challenging to track how molecular-level processes give rise to large-scale collective phenomena. For example, in bacterial colonies, individual cell motility and interactions must be connected to population-level dynamics and pattern formation, requiring sophisticated multi-scale modeling approaches.\nNon-equilibrium statistical mechanics: Developing systematic frameworks beyond equilibrium concepts. Traditional statistical mechanics relies heavily on concepts like detailed balance and the fluctuation-dissipation theorem, which break down in active systems due to continuous energy input. The lack of an energy minimum principle or equivalent organizing framework makes it difficult to develop general theories for non-equilibrium steady states.\nTopological effects: Understanding defect nucleation, motion, and interactions. In active systems, topological defects can spontaneously nucleate, move, and interact in ways fundamentally different from their equilibrium counterparts due to the continuous energy input. The coupling between defect dynamics and active stresses creates complex feedback loops that are challenging to describe theoretically.\nCapturing boundary effects: Modeling how boundaries and confinement influence active dynamics. Active matter systems exhibit unique responses to boundaries that can qualitatively change their behavior, such as accumulation at walls or spontaneous circulation in confined geometries. These boundary effects often depend non-trivially on microscopic details of both the active particles and the confining surfaces.\nIncorporating disorder and heterogeneity: Addressing realistic imperfections in theoretical frameworks. Real active matter systems invariably contain disorder and heterogeneity in particle properties, interactions, and environmental conditions. Incorporating these imperfections while maintaining theoretical tractability requires careful balance between complexity and analytical feasibility.\nCoupling to external fields: Describing responses to gradients, flows, and applied fields. Active matter systems show complex and often counterintuitive responses to external fields, such as negative mobility or upstream swimming in flows. The interplay between internal activity and external forcing creates rich dynamics that challenge our theoretical understanding.\nInformation flow: Quantifying information processing in active biological systems. Biological active matter systems process and respond to information in sophisticated ways, from bacterial chemotaxis to collective decision making in animal groups. Developing theoretical frameworks to quantify and model this information processing remains a major challenge.\nPerception-reaction delays: Biological active matter processes information at rates significantly slower than modern computers due to the inherent limitations of biochemical signaling pathways. These delays between perception and response manifest in various active systems, from human driving behavior in daily traffic to collective animal movement patterns. Such temporal gaps between stimulus detection and behavioral adjustment critically influence numerous dynamical states in active matter. To compensate for this inherent slowness, biological systems have evolved predictive mechanisms that anticipate future states and allow for more effective responses despite processing limitations. Dealing with such delays is a considerable challenge for theoretical modelling.\nPredictive power: Developing theories with quantitative predictive capabilities for experiments. The complexity and non-equilibrium nature of active matter systems often leads to theories that are qualitative rather than quantitative in nature. Making precise, testable predictions requires better understanding of the relevant control parameters and their relationships to observable phenomena.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lecture01/lecture01.html#lecture-1",
    "href": "lecture01/lecture01.html#lecture-1",
    "title": "Introduction to Active Matter",
    "section": "",
    "text": "The study of active matter emerged in the late 20th century at the intersection of soft matter physics, biophysics, and statistical mechanics. An important precursor to the field came from computer graphics, where Craig Reynolds developed the Boids simulation in 1986 - an artificial life program that demonstrated how simple rules governing individual agents could produce realistic flocking behaviors in computer animations. Earlier cellular automata models like Conway’s Game of Life had also shown how simple rules could lead to complex emergent behaviors, helping establish some of the conceptual foundations for understanding collective systems.\n\n\n\n\n\n\n\n\n  \n    Reset Simulation\n  \n  \n    Separation: \n    Alignment: \n    Cohesion: \n  \n\n\n\n\n\n\nFigure 1: Interactive simulation of the Boids model, where you can adjust the three key parameters that govern flocking behavior: separation (avoidance of crowding), alignment (steering towards average heading), and cohesion (steering towards center of mass).\n\n\n\n\n\n\n\n\n\nThe Boids Model Explained\n\n\n\n\n\nThe Boids model, developed by Craig Reynolds in 1986, simulates the flocking behavior of birds using three simple rules:\n\nSeparation: Each boid avoids crowding nearby flockmates, steering away when they get too close.\nAlignment: Each boid aligns its direction of flight with nearby flockmates, matching their average velocity.\nCohesion: Each boid moves toward the center of mass of nearby flockmates, creating a tendency to stick together.\n\nThese local interaction rules, when applied to all individuals simultaneously, produce complex global behaviors that remarkably resemble natural flocking patterns. The simulation above demonstrates how adjusting these three parameters affects the emergent collective motion:\n\nHigh separation, low alignment, low cohesion: Dispersed individuals with minimal coordination\nLow separation, high alignment, medium cohesion: Coherent flocking with directional movement\nBalanced parameters: Natural-looking flocking behaviors with dynamic subgroup formation\n\nThis model illustrates a fundamental principle in active matter physics: complex collective behaviors can emerge from simple local rules without centralized control.\n\n\n\nThis computational model later influenced physical approaches to collective motion. Early foundational work by scientists like T. Vicsek in the 1990s established computational models for collective motion, particularly his 1995 paper introducing what is now known as the Vicsek model for self-propelled particles with alignment interactions. Prior to this, early biological observations of collective behaviors in nature, such as bird flocking and fish schooling, had long fascinated scientists but lacked rigorous physical frameworks. The field gained significant momentum in the late 1990swith seminal papers by John Toner and Yuhai Tu, who published their groundbreaking work on flocking theory in 1995, and later Sriram Ramaswamy who developed continuum theories for active nematics.\nThe theoretical foundations were further strengthened by contributions from European researchers like Michael Cates (Edinburgh), Jean-François Joanny (Paris), and Jacques Prost (Paris), who developed the active gel theory to describe cytoskeletal dynamics in the mid-2000s. Simultaneously, M. Cristina Marchetti and her collaborators formulated comprehensive hydrodynamic theories for active systems across various symmetry classes. Sriram Ramaswamy made fundamental contributions through his work on active liquid crystals and the development of generic hydrodynamic theories for active matter. The pioneering work of John Toner and Yuhai Tu established the theoretical framework for understanding the emergence of long-range order in flocking systems, demonstrating how activity can stabilize orientational order even in two dimensions. Julia Yeomans (Oxford) advanced our understanding of active turbulence and topological defects in active nematics through innovative computational approaches, while Hartmut Löwen (Düsseldorf) developed influential theories for the collective behavior of active Brownian particles and motility-induced phase separation. These theoretical advances were complemented by experimental breakthroughs, notably Howard Berg’s groundbreaking work in the 1970s at Harvard on bacterial chemotaxis and motility, where he developed the tracking microscope to follow individual E. coli bacteria and discovered their run-and-tumble motion patterns. Additional experimental contributions came from Raymond Goldstein (Cambridge) and others who established quantitative measurements of collective motion in bacterial systems.\nExperimental breakthroughs with bacterial suspensions (notably work by Igor Aranson and Raymond Goldstein on Bacillus subtilis), cell tissues (including Xavier Trepat’s research at IBEC in Barcelona on epithelial cell sheets), and synthetic active colloids (pioneered by European researchers like Jérémie Palacci (Lyon/San Diego), Julien Perrin (Paris), and Clemens Bechinger (Konstanz/Stuttgart) with light-activated Janus particles) further propelled the field forward. The development of artificial microswimmers by international collaborations involving European teams led by Roberto Di Leonardo (Rome), Ramin Golestanian (Oxford/Göttingen), and Frank Cichos (Leipzig), alongside US-based researchers like Steve Granick and Ayusman Sen, opened new avenues for creating controllable active systems outside biological contexts.\nBy the 2010s, active matter had developed into a distinct discipline with dedicated conferences and research groups worldwide. The establishment of specialized research centers across Europe such as the Max Planck Institute for Dynamics and Self-Organization in Göttingen, the Physics of Living Matter Group at Cambridge, the Biological Physics and Morphogenesis groups at MPIPKS Dresden, alongside the Syracuse Soft and Living Matter Program, the Center for the Physics of Biological Function at Princeton, and the Active Matter Lab at MIT reflected the field’s growing importance. Major milestones included the observation of motility-induced phase separation by Michael Cates (Edinburgh) and Julien Tailleur (Paris) (2013), the discovery of topological defect motility in active nematics by Zvonimir Dogic and collaborators (2014), and the creation of the first autonomous active material capable of performing work by Daniela Wilson’s group (Nijmegen) (2019). The field continues to expand with increasing interdisciplinary collaborations between physicists, biologists, materials scientists, and engineers, addressing fundamental questions in non-equilibrium physics while developing applications in biomedicine, soft robotics, and smart materials.\n\n\n\nUnderstanding how active matter systems differ from equilibrium systems is crucial for developing new theoretical frameworks and experimental approaches. The continuous energy input and self-driven nature of active matter leads to behaviors that challenge our traditional physics understanding. Consider the following key distinctions between equilibrium and active matter systems:\n\n\n\n\n\n\n\n\nFeature\nEquilibrium Systems\nActive Matter Systems\n\n\n\n\nDetailed Balance\nForward and reverse processes occur at equal rates\nContinuously broken through energy consumption, driving the system away from equilibrium\n\n\nFluctuation-Dissipation Theorem\nValid relationship between spontaneous fluctuations and response to external perturbations\nBreaks down as fluctuations can be driven by internal activity\n\n\nParticle Motion\nRandom Brownian motion\nPersistent directional motion over certain timescales\n\n\nStatistical Distributions\nFollow Boltzmann statistics\nNon-Boltzmann statistics, making standard thermodynamic tools inapplicable\n\n\nMacroscopic Currents\nAbsent in steady states\nCan sustain macroscopic currents and flux cycles even in steady states\n\n\nPhase Behavior\nWell-established equilibrium phases\nUnique phase transitions with no equilibrium counterparts (e.g., motility-induced phase separation, active turbulence)\n\n\nMechanical Pressure\nIndependent of boundary properties\nCan depend on properties of confining walls, violating equilibrium equations of state\n\n\nEnergy and Entropy\nMinimize free energy, maximize entropy\nContinuously dissipate energy and produce entropy even in steady states\n\n\nTime-Reversal Symmetry\nDynamics appear similar when played forward or backward\nDynamics look distinctly different when played forward versus backward\n\n\nForce Characteristics\nDerivable from a potential energy function\nCannot generally be derived from a potential energy function\n\n\n\n\n\n\nActive matter encompasses a diverse range of systems, from biological organisms to synthetic particles, that share the common feature of continuously converting energy into systematic motion. These systems can be organized into several categories based on their energy sources, symmetries, and the nature of their interactions, providing a framework for understanding their distinct behaviors and properties.\n\n\n\n\n\n\nFigure 2: Overview of active matter systems at different scales and domains. The field spans from microscopic biological systems like cellular components to macroscopic collective behaviors and engineered synthetic systems. (source)\n\n\n\nActive matter systems can be categorized based on several key characteristics:\n\nEnergy conversion mechanismSymmetry of motionMedium and interactionsStructural arrangementLength scale and dimensionality\n\n\n\nBiological active matter: Systems that convert chemical energy (ATP, nutrients) into mechanical work (e.g., bacteria, cells, tissues). These systems span multiple scales, from molecular motors like kinesin and myosin that transport cargo along cytoskeletal filaments, to cellular components such as the dynamic cytoskeleton that enables cell shape changes and migration. At multicellular scales, coordinated activity enables tissue morphogenesis during development, wound healing, and collective cell migration. The energy conversion typically involves ATP hydrolysis, which provides approximately 20 kT of energy per molecule, enabling these systems to perform work against thermal fluctuations. Unlike their synthetic counterparts, biological active matter often exhibits adaptive behaviors, feedback regulation, and hierarchical organization that enhances functionality and robustness.\n\n\n\n\n\n\n\n\n\nATP hydrolysis is the primary energy source in most cellular processes\n\n\n\n\n\n\n\nBacteria like E. coli use flagella powered by molecular motors\n\n\n\n\n\n\nFigure 3: ATP hydrolysis and bacterial motility represent key examples of chemical energy conversion in biological active matter\n\n\n\n\nSynthetic active matter: Engineered systems powered by external fields, chemical reactions, or light (e.g., Janus particles, active colloids). These artificial systems represent human-designed analogs to biological active matter, with scientists having precise control over their properties and behaviors. Synthetic active particles typically feature asymmetric structures or surface properties that enable self-propulsion. Common examples include Janus particles with catalyst-coated hemispheres that decompose hydrogen peroxide to create propulsion, light-activated particles that convert photonic energy into motion, and magnetically-actuated microswimmers that respond to oscillating external fields. Unlike biological systems, synthetic active matter can be designed with specific functionalities, such as targeted drug delivery, environmental remediation, or self-assembly into complex structures. Recent advances have produced programmable behaviors through responsive materials, feedback mechanisms, and even rudimentary “communication” between synthetic active agents.\n\n\n\n\n\n\n\nFigure 4: Synthetic active particles can be designed with asymmetric properties to enable self-propulsion through various mechanisms\n\n\n\n\n\n\nPolar active matter: Entities with defined front-back asymmetry and directional motion (e.g., birds, fish). These systems are characterized by particles or organisms that have a clear direction of motion and can align their movement with neighbors. For example, fish schools demonstrate this through their streamlined body shape that defines a clear swimming direction, while their lateral line system helps them align with neighboring fish. Similarly, migratory birds show polar order through their aerodynamic body structure and visual alignment with flock-mates during flight. At the microscopic scale, many bacteria like E. coli exhibit polar motion through their flagellar propulsion system that creates directed swimming. The polar nature of these systems often leads to unique collective phenomena like the emergence of large-scale coherent motion and the formation of traveling bands or density waves.\n\n\n\n\n\n\n\n\n\nFish schools demonstrate collective motion through simple alignment rules\n\n\n\n\n\n\n\nBird flocks exhibit emergent order through local interactions\n\n\n\n\n\n\nFigure 5: Examples of polar active matter: fish schools (source) and bird flocks (source)\n\n\n\n\nApolar active matter: Systems generating motion without a defined direction (e.g., melanocytes, active nematics). These systems exhibit interesting collective behaviors despite lacking a preferred direction of motion at the individual level. For example, melanocytes, the cells responsible for skin pigmentation, extend and retract protrusions in multiple directions as they move and distribute melanin. Similarly, active nematics, such as dense suspensions of microtubules and molecular motors, generate complex flows and defect dynamics without any preferred direction of motion for individual components. The apolar nature of these systems often leads to unique phenomena like the spontaneous formation and annihilation of topological defects, and the emergence of active turbulence in confined geometries.\n\n\n\n\n\n\n\n\n\nMelanocyte cells showing apolar migration patterns\n\n\n\n\n\n\n\nActive nematic liquid crystals with defect patterns\n\n\n\n\n\n\nFigure 6: Examples of apolar active matter: melanocytes (source) and active nematics (source)\n\n\n\n\nChiral active matter: Systems with inherent rotational motion or handedness. These systems exhibit systematic rotational motion in addition to translational movement, often due to structural asymmetry or biased force generation. Examples include bacterial flagella that rotate to create propulsion, sperm cells that swim with helical trajectories, and synthetic microswimmers with chiral shapes that spin as they move through fluid. The interplay between rotational and translational motion in these systems can lead to unique collective behaviors, such as the formation of rotating clusters or vortex arrays. At the microscopic scale, molecular motors like the bacterial flagellar motor demonstrate how nature utilizes chirality to generate motion, while at larger scales, schools of fish can form rotating vortex patterns through their collective swimming behavior.\n\n\n\n\nDry active matter: Systems where momentum dissipates to a substrate (e.g., cells on surfaces). In these systems, the primary interaction between particles occurs through direct contact or short-range forces, as the substrate quickly dampens any long-range hydrodynamic effects. A classic example is cells crawling on a surface, where the friction with the substrate dominates the dynamics. Another example is vibrated granular layers, where energy input causes particle motion but momentum is quickly dissipated through collisions with the base plate and between particles.\nWet active matter: Systems embedded in a fluid where hydrodynamic interactions dominate (e.g., bacterial suspensions). These systems exhibit complex long-range interactions mediated by the fluid, as the motion of each active particle creates flow fields that affect distant particles. Examples include swimming microorganisms in water, where the fluid flows generated by one organism can influence the motion of others several body lengths away. Active colloids in suspension also demonstrate these effects, where the chemical activity or motion of particles creates fluid flows that lead to collective behaviors and pattern formation.\n\n\n\n\nActive crystals: Ordered lattice-like arrangements with activity. These systems maintain crystalline order while individual units remain active, such as in bacterial colonies that form regular spatial patterns while each bacterium continues to move and metabolize. A key example is the formation of living crystals from light-activated colloidal particles, where the particles self-organize into a crystalline lattice while maintaining their individual motility.\nActive glasses: Disordered, jammed configurations with activity. Unlike traditional glasses, these systems combine structural disorder with persistent local motion, leading to unique dynamical behaviors. Examples include dense bacterial suspensions at high concentrations where cells become trapped in disordered configurations but continue to exert active forces on their neighbors, or crowded solutions of motor proteins and filaments where steric constraints create glassy dynamics despite ongoing ATP-driven activity.\nActive fluids/gases: Flowing systems with active components. These systems exhibit fluid-like behavior but with constituents that continuously inject energy at the microscopic scale. Examples range from dilute bacterial suspensions that show enhanced diffusion and collective motion, to dense active liquid crystals where the interplay between flow and orientational order creates complex dynamical patterns like active turbulence. In the gas-like regime, systems like midge swarms demonstrate how active particles can maintain cohesion while exhibiting fluid-like properties.\n\n\n\n\nMicroscopic: Cellular and subcellular systems (cytoskeleton, bacterial colonies). At this scale, active matter emerges from molecular motors like kinesin and dynein walking along cytoskeletal filaments, or the collective motion of bacterial cells in colonies. The cytoskeleton itself is a fascinating example where networks of actin filaments and microtubules, driven by ATP-powered molecular motors, create complex dynamics essential for cell function and division.\nMesoscopic: Tissue and organ-level organizations. At the tissue level, collective cell behavior leads to emergent phenomena like wound healing and morphogenesis during development. Epithelial tissues demonstrate active matter dynamics through coordinated cell migration and mechanical force transmission between neighboring cells. These intermediate scales bridge individual cell behavior with organ-level function.\n\n\n\n\n\n\n\nFigure 7: Time-lapse microscopy of Drosophila embryo development showing gastrulation and tissue folding - a striking example of how active matter principles govern morphogenesis. The coordinated cell shape changes and movements create complex three-dimensional structures from an initially simple tissue sheet. source\n\n\n\n\nMacroscopic: Animal groups, human crowds. Large-scale collective behaviors emerge in systems like bird flocks, fish schools, and human crowds in urban environments. These systems demonstrate how simple interaction rules between individuals can create complex, coordinated motion patterns that span hundreds or thousands of times the size of individual agents. Traffic flow and pedestrian dynamics are particularly relevant examples for urban planning and crowd safety.\nQuasi-2D vs. 3D systems: Systems confined to surfaces vs. fully three-dimensional systems. Many active matter systems are effectively two-dimensional, like bacterial colonies growing on agar plates or cells migrating on substrates. These confined geometries often simplify both experimental observation and theoretical analysis. In contrast, true three-dimensional systems like bacterial suspensions in fluid or cell movement in tissue matrices exhibit additional complexities due to hydrodynamic interactions and the full range of possible motion directions.\n\n\n\n\n\n\n\nThe theoretical description of active matter draws from and extends multiple branches of physics:\n\nKinetic theoriesContinuum field theoriesAgent-based and particle models\n\n\n\nBoltzmann-like approaches: Describing probability distributions of particle positions and orientations in active systems. For example, in bacterial suspensions, this approach tracks how the probability of finding bacteria with specific positions and swimming directions evolves over time. The key difference from classical Boltzmann equations is the inclusion of self-propulsion forces and alignment interactions. These equations have been particularly successful in describing the transition from disordered to ordered states in active systems like bird flocks and fish schools.\nFokker-Planck equations: Capturing the evolution of probability densities in phase space by incorporating both deterministic and stochastic effects. In active matter, these equations describe how probability distributions change due to systematic forces (like self-propulsion), random fluctuations (thermal or active noise), and interactions between particles. For instance, they can model how Janus particles move under the influence of chemical gradients while experiencing rotational diffusion, or how swimming bacteria respond to chemical attractants while subject to tumbling events.\nSmoluchowski equations: Modeling overdamped dynamics common in biological active systems where inertial effects are negligible compared to viscous forces. These equations are particularly relevant for microscopic swimmers like bacteria or colloidal particles where the Reynolds number is very small. They have been successfully applied to describe phenomena like bacterial chemotaxis, the collective motion of cell populations, and the dynamics of motor proteins along cytoskeletal filaments. A classic example is modeling E. coli’s run-and-tumble motion, where the Smoluchowski equation – the overdamped limit of the Fokker-Planck equation – captures the interplay between directed swimming and random reorientations.\n\n\n\n\nToner-Tu theory: A hydrodynamic framework that describes collective motion in flocking systems by incorporating broken continuous symmetry. This theory is particularly powerful for analyzing large systems, where it predicts true long-range order can exist even in two dimensions, in contrast to equilibrium systems. While real flocks are finite, the theory provides insights into large-scale behaviors like the scale-free correlations observed in starling murmurations, where thousands of birds maintain coherent motion despite environmental perturbations.\nActive gel theories: These theories extend traditional liquid crystal physics by incorporating force-generating active stresses. They are particularly successful in describing biological materials like the cell cytoskeleton, where molecular motors generate internal forces. A key example is explaining the spontaneous flows observed in actomyosin networks, where myosin motors walking along actin filaments create large-scale coherent motion.\nActive nematics: Field theories that describe systems with orientational order but no polar direction, driven out of equilibrium by active stresses. These theories have been instrumental in understanding phenomena like the chaotic dynamics of microtubule-kinesin mixtures, where energy input from molecular motors leads to the continuous creation, motion, and annihilation of topological defects, resulting in active turbulence.\nPhase field models: Mathematical frameworks that track the evolution of interfaces and boundaries in active systems without explicitly tracking individual particles. These models have been successfully applied to describe phenomena like cell membrane deformation during motility, tissue morphogenesis, and the dynamics of active droplets. For instance, they can capture how a crawling cell changes shape and moves by coupling chemical signals to mechanical deformations of the cell membrane.\n\n\n\n\nVicsek model: The foundational model for collective motion where particles move at constant speed and align their direction with neighbors within a certain radius, subject to noise. For example, in simulating bird flocks, each bird adjusts its direction to match the average flight direction of nearby birds, plus some random variation. This simple rule produces rich collective behaviors like the transition from disordered motion at high noise to coordinated flocking at low noise.\nActive Brownian particles: Self-propelled particles that maintain constant speed but undergo rotational diffusion, leading to persistent random walks. A classic example is light-activated Janus colloids - microscopic particles with one hemisphere coated in a light-responsive material. Under illumination, these particles swim in a directed manner but gradually change direction due to thermal fluctuations, resulting in motion that is ballistic at short times but diffusive at long times.\nRun-and-tumble models: These models capture the motion pattern of bacteria like E. coli, which alternate between straight “runs” and random “tumbles.” During runs, the bacteria swim in nearly straight lines using their flagella. Tumbles occur when the flagella bundle comes apart, causing the cell to randomly reorient. This mechanism allows bacteria to effectively explore their environment and respond to chemical gradients through biased random walks.\nActive Ornstein-Uhlenbeck particles: A model incorporating temporal correlations in the active propulsion force, leading to more realistic descriptions of biological swimmers. For instance, in modeling the motion of algae like Chlamydomonas, the swimming force isn’t purely random but shows correlations over the time scale of the flagellar beat cycle. This correlation produces more accurate predictions of diffusion and clustering behaviors compared to simpler active particle models.\n\n\n\n\n\n\n\nThe scientific study of active matter presents several key theoretical and experimental challenges that continue to motivate research and technological innovation in the field:\n\nExperimental challengesTheoretical challenges\n\n\n\nDiversity in propulsion mechanisms and functionality: Creating synthetic active particles with diverse propulsion strategies and functional capabilities remains challenging. Current systems are largely limited to chemical catalysis, light activation, or magnetic actuation. Beyond propulsion, developing particles capable of force generation, information processing, and programmable behaviors through compartmentalization and feedback control is crucial. This includes systems that can adapt their behavior based on environmental cues or machine learning algorithms.\nMulti-component systems: Developing heterogeneous active matter systems with different types of particles that can interact and coordinate. For example, combining light-activated and chemically-powered particles, or integrating passive and active components to create hierarchical structures with emergent behaviors.\nMeasurement techniques: Developing methods to track fast dynamics across multiple scales. Active matter systems often exhibit complex spatiotemporal dynamics that require simultaneous tracking of individual particles and collective behaviors. High-speed imaging, particle tracking, and flow visualization techniques must be adapted to capture both the rapid motion of individual active units and the slower evolution of large-scale patterns.\nSystem preparation: Creating synthetic particles with programmable behaviors and functions. The synthesis of active colloids requires careful control over particle size, shape, surface chemistry, and catalyst distribution, as well as the integration of responsive elements that enable specific functionalities. For instance, incorporating multiple catalytic or stimuli-responsive domains to create particles capable of complex tasks remains technically challenging.\nBoundary conditions: Controlling and characterizing interactions with surfaces. Active matter systems are highly sensitive to boundary conditions, which can significantly influence their behavior. Creating well-defined boundaries while maintaining activity and avoiding unwanted surface effects requires careful experimental design and characterization.\nEnergy input: Maintaining steady, uniform activation across synthetic systems. Whether through chemical fuel concentration, light intensity, magnetic fields, or electric fields, ensuring uniform activation throughout the sample volume is crucial. Challenges include maintaining constant H2O2 concentration for catalytic swimmers or uniform illumination for light-activated particles.\nTime limitations: Managing fuel depletion and particle degradation while maintaining function. Synthetic active systems face challenges like catalyst poisoning, fuel consumption, and photobleaching that can impair their ability to perform desired tasks. For chemical swimmers, local fuel depletion can create concentration gradients that affect particle behavior, while light-activated systems may suffer from photodamage over time.\nImaging limitations: Balancing spatial and temporal resolution with field of view. Active matter often requires both high-resolution imaging to track individual particles and wide-field observation to capture collective effects. This creates technical challenges in microscopy and imaging systems, particularly for three-dimensional systems.\nParameter space: Exploring vast parameter spaces with limited resources. Synthetic active matter systems have many tunable parameters including particle size, shape, surface chemistry, fuel concentration, and external field strengths. Systematically exploring these parameters while maintaining experimental consistency requires significant time and resources.\nSystem integration: Incorporating active matter into functional devices or materials while maintaining desired behaviors. Synthetic active matter experiments require careful integration with other components while preserving activity and function. Creating stable, reliable systems that can operate under real-world conditions presents significant engineering challenges.\n\n\n\n\nBridging scales: Connecting microscopic mechanisms to macroscopic behaviors. Active matter systems often exhibit behaviors across many orders of magnitude in length and time scales, making it challenging to track how molecular-level processes give rise to large-scale collective phenomena. For example, in bacterial colonies, individual cell motility and interactions must be connected to population-level dynamics and pattern formation, requiring sophisticated multi-scale modeling approaches.\nNon-equilibrium statistical mechanics: Developing systematic frameworks beyond equilibrium concepts. Traditional statistical mechanics relies heavily on concepts like detailed balance and the fluctuation-dissipation theorem, which break down in active systems due to continuous energy input. The lack of an energy minimum principle or equivalent organizing framework makes it difficult to develop general theories for non-equilibrium steady states.\nTopological effects: Understanding defect nucleation, motion, and interactions. In active systems, topological defects can spontaneously nucleate, move, and interact in ways fundamentally different from their equilibrium counterparts due to the continuous energy input. The coupling between defect dynamics and active stresses creates complex feedback loops that are challenging to describe theoretically.\nCapturing boundary effects: Modeling how boundaries and confinement influence active dynamics. Active matter systems exhibit unique responses to boundaries that can qualitatively change their behavior, such as accumulation at walls or spontaneous circulation in confined geometries. These boundary effects often depend non-trivially on microscopic details of both the active particles and the confining surfaces.\nIncorporating disorder and heterogeneity: Addressing realistic imperfections in theoretical frameworks. Real active matter systems invariably contain disorder and heterogeneity in particle properties, interactions, and environmental conditions. Incorporating these imperfections while maintaining theoretical tractability requires careful balance between complexity and analytical feasibility.\nCoupling to external fields: Describing responses to gradients, flows, and applied fields. Active matter systems show complex and often counterintuitive responses to external fields, such as negative mobility or upstream swimming in flows. The interplay between internal activity and external forcing creates rich dynamics that challenge our theoretical understanding.\nInformation flow: Quantifying information processing in active biological systems. Biological active matter systems process and respond to information in sophisticated ways, from bacterial chemotaxis to collective decision making in animal groups. Developing theoretical frameworks to quantify and model this information processing remains a major challenge.\nPerception-reaction delays: Biological active matter processes information at rates significantly slower than modern computers due to the inherent limitations of biochemical signaling pathways. These delays between perception and response manifest in various active systems, from human driving behavior in daily traffic to collective animal movement patterns. Such temporal gaps between stimulus detection and behavioral adjustment critically influence numerous dynamical states in active matter. To compensate for this inherent slowness, biological systems have evolved predictive mechanisms that anticipate future states and allow for more effective responses despite processing limitations. Dealing with such delays is a considerable challenge for theoretical modelling.\nPredictive power: Developing theories with quantitative predictive capabilities for experiments. The complexity and non-equilibrium nature of active matter systems often leads to theories that are qualitative rather than quantitative in nature. Making precise, testable predictions requires better understanding of the relevant control parameters and their relationships to observable phenomena.",
    "crumbs": [
      "Introduction to Active Matter",
      "Lecture 1"
    ]
  },
  {
    "objectID": "lecture04/lecture04.html",
    "href": "lecture04/lecture04.html",
    "title": "Microscopic Models of Self-propulsion",
    "section": "",
    "text": "Lecture 4: Continuum Theories\n\nHydrodynamic theories and coarse-graining\nActive liquid crystals\nToner-Tu model for flocking\nActive field theories\nLinear stability analysis in active systems"
  }
]