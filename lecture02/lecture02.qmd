---
title: "Non-equilibrium Statistical Mechanics"
format:
  html:
    toc: true
    toc-location: right
---


<!--
### Lecture 2: Non-equilibrium Statistical Mechanics
- Brief review of equilibrium statistical physics
- Fluctuation-dissipation theorem and its breakdown
- Entropy production in active systems
- Stochastic thermodynamics approach
- Time-reversal symmetry breaking
-->

## Brief review of equilibrium statistical mechanics

Equilibrium statistical mechanics may seem like a contradictory starting point for understanding fundamentally non-equilibrium phenomena in active matter. However, we begin with these concepts precisely because understanding how and why active systems violate equilibrium principles illuminates their unique properties. In this section, we review key equilibrium concepts that provide a crucial reference frame against which we can measure and characterize the non-equilibrium nature of active systems.

### Canonical ensemble and partition function

For a system in thermal equilibrium with a heat bath at temperature $T$ not exchanging particles with the environment, the probability of finding the system in a microstate with phase space coordinates $\Gamma = \{\mathbf{q}, \mathbf{p}\}$ is given by the Boltzmann distribution:

$$P(\Gamma) = \frac{1}{Z} e^{-\beta H(\Gamma)}$$

where $\beta = 1/(k_B T)$, $k_B$ is Boltzmann's constant, $H(\Gamma)$ is the Hamiltonian of the system, and $Z$ is the partition function:

$$Z = \int e^{-\beta H(\Gamma)} d\Gamma$$

In physical terms, the Boltzmann distribution reflects how energy is partitioned among the available states at thermal equilibrium. States with lower energy are exponentially more likely to be occupied than states with higher energy. For active matter systems, this distribution is significantly altered because energy is continuously injected at the microscopic level, driving the system away from this equilibrium distribution. Indeed, active systems generally cannot be described by a time-independent Hamiltonian at all, as they involve non-conservative forces.

The partition function is central to statistical mechanics as it connects microscopic properties to macroscopic observables. For instance, the average energy is:

$$\langle H \rangle = -\frac{\partial \ln Z}{\partial \beta}$$

This relationship highlights how the partition function serves as a generating function for thermodynamic quantities. When studying active matter, we'll see that traditional partition functions often cannot be defined because these systems don't explore phase space according to Boltzmann statistics.


::: {.callout-note collapse="true"}
## Sedimentation Example


::: {#fig-perrin-sedimentation }

![](/assets/images/lecture02/sedimentation_perrin.png){width=50%}

Perrin's sedimentation experiments. The exponential decay in the number density of colloidal particles with height directly confirmed the Boltzmann distribution and provided key evidence for the atomic theory of matter.
:::

A clear demonstration of the Boltzmann distribution's power can be derived from the canonical partition function using the barometric distribution of particles in a gravitational field. Consider colloidal particles suspended in a fluid in a gravitational field $g$.

The Hamiltonian for a particle at height $h$ with momentum $p$ is:

$$H(h, p) = \frac{p^2}{2m} + mgh$$

where the first term represents the kinetic energy and the second term is the gravitational potential energy. For this system, we can construct the partition function by integrating over all possible heights and momenta:

$$Z = \int_0^{\infty} \int_{-\infty}^{\infty} e^{-\beta H(h,p)} dp dh = \int_0^{\infty} \int_{-\infty}^{\infty} e^{-\beta(\frac{p^2}{2m} + mgh)} dp dh$$

This can be separated into:

$$Z = \int_{-\infty}^{\infty} e^{-\beta\frac{p^2}{2m}} dp \cdot \int_0^{\infty} e^{-\beta mgh} dh$$

The momentum integral gives $\sqrt{\frac{2\pi m}{\beta}}$, while the height integral yields $\frac{1}{\beta mg}$, resulting in:

$$Z = \sqrt{\frac{2\pi m}{\beta}} \cdot \frac{1}{\beta mg} = \sqrt{\frac{2\pi m}{\beta^3 m^2 g^2}}$$

The probability density for finding a particle at height $h$ (integrating over all momenta) is:

$$P(h) = \frac{\int_{-\infty}^{\infty} e^{-\beta(\frac{p^2}{2m} + mgh)} dp}{Z} = \frac{\sqrt{\frac{2\pi m}{\beta}} \cdot e^{-\beta mgh}}{\sqrt{\frac{2\pi m}{\beta}} \cdot \frac{1}{\beta mg}} = \beta mg e^{-\beta mgh}$$

From this, we can derive the number density $n(h)$ by multiplying by the total number of particles $N$:

$$n(h) = N \cdot P(h) = N \beta mg e^{-\beta mgh}$$

If we define $n_0$ as the density at $h=0$, then $n_0 = N \beta mg$, and we obtain:

$$n(h) = n_0 e^{-\beta mgh} = n_0 e^{-\frac{mgh}{k_B T}}$$

Taking the logarithm of both sides:

$$\ln\left(\frac{n(h)}{n_0}\right) = -\beta mgh = -\frac{mgh}{k_B T}$$

This direct connection between the Hamiltonian, partition function, and the observable barometric distribution provides a compelling experimental verification of statistical mechanics. Jean Perrin used this relationship in 1908 to experimentally determine Avogadro's number and provide crucial evidence for the atomic theory of matter. Today, similar experiments with colloidal particles serve as textbook demonstrations of statistical mechanics in action.
:::


### Free energy and thermodynamic potentials

### Free energy and thermodynamic potentials

The Helmholtz free energy is a thermodynamic potential that determines the maximum useful work obtainable from a closed system at constant temperature and volume. Named after German physicist Hermann von Helmholtz, it represents the amount of energy available to do non-expansion work. The Helmholtz free energy is particularly relevant in statistical mechanics because it serves as the fundamental bridge between microscopic properties (encoded in the partition function) and macroscopic thermodynamic behavior. For systems in the canonical ensemble—where the number of particles, volume, and temperature are fixed—the Helmholtz free energy provides the appropriate thermodynamic potential whose minimum determines the equilibrium state.

The Helmholtz free energy $F$ is related to the partition function by:

$$F = -k_B T \ln Z = -k_B T \ln \left(\int e^{-\beta H(\Gamma)} d\Gamma\right)$$

We can rewrite this as $F = E - TS$, explicitly showing the competition between the enthalpic (energy) and entropic contributions:

$$F = \langle H \rangle - TS$$

where $\langle H \rangle$ is the average energy:

$$\langle H \rangle = -\frac{\partial \ln Z}{\partial \beta} = \frac{\int H(\Gamma) e^{-\beta H(\Gamma)} d\Gamma}{\int e^{-\beta H(\Gamma)} d\Gamma}$$

and $S$ is the entropy:

$$S = -\left(\frac{\partial F}{\partial T}\right)_V = k_B \ln Z + \frac{\langle H \rangle}{T}$$

At equilibrium, minimizing the free energy involves a fundamental competition between:

1. **Energy minimization**: The system tends to occupy low-energy states to minimize $\langle H \rangle$
2. **Entropy maximization**: The system tends to spread over many accessible states to maximize $S$

The Boltzmann distribution $P(\Gamma) = \frac{1}{Z}e^{-\beta H(\Gamma)}$ represents the optimal compromise between these competing tendencies. For systems with fixed particle number, volume, and temperature (canonical ensemble), this distribution precisely minimizes the free energy subject to the constraints of the canonical ensemble.

The principle of free energy minimization is particularly important for understanding the contrast with active systems. In active matter, free energy is constantly being pumped into the system through microscopic driving mechanisms (e.g., molecular motors in cell cytoskeleton, metabolic processes in bacteria, or artificial propulsion mechanisms in synthetic swimmers). These systems involve non-conservative forces that cannot be derived from a Hamiltonian, so they cannot be described by a minimum free energy principle, which is a fundamental departure from equilibrium thermodynamics.


::: {.callout-note collapse="true"}
## Harmonic Oscillator Example

The harmonic oscillator provides another illuminating example of equilibrium statistical mechanics. Consider a Brownian particle in a harmonic potential $U(x) = \frac{1}{2}kx^2$ provided by some highly focused light beam. Here $k$ is the spring constant.

::: {#fig-harmonic-oscillator}

![](/assets/images/lecture02/tweezer.png){width=50%}

Sketch of a colloidal particle trapped in the focus of a microscopy lens due to electromagnetic forces. [source](https://physics.nyu.edu/grierlab/nreview2c/)
:::

The particle experiences both a restoring force and random thermal kicks from the surrounding fluid.

The Hamiltonian for this system is:

$$H(x,p) = \frac{p^2}{2m} + \frac{1}{2}kx^2$$

where $m$ is the particle mass, $x$ is position, and $p$ is momentum. The partition function is:

$$Z = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-\beta H(x,p)} dx dp = \int_{-\infty}^{\infty} e^{-\beta \frac{p^2}{2m}} dp \int_{-\infty}^{\infty} e^{-\beta \frac{1}{2}kx^2} dx$$

Evaluating these Gaussian integrals:

$$Z = \sqrt{\frac{2\pi m}{\beta}} \sqrt{\frac{2\pi}{\beta k}} = \frac{2\pi}{\beta\omega_0}$$

where $\omega_0 = \sqrt{k/m}$ is the natural frequency of the oscillator.

The probability density for finding the particle at position $x$ is:

$$P(x) = \sqrt{\frac{\beta k}{2\pi}} e^{-\beta \frac{1}{2}kx^2}$$

This Gaussian distribution has variance $\sigma^2 = \frac{1}{\beta k} = \frac{k_B T}{k}$.

The equipartition theorem states that each quadratic term in the Hamiltonian contributes $\frac{1}{2}k_B T$ to the average energy:

$$\left \langle \frac{p^2}{2m} \right \rangle = \left \langle \frac{1}{2}kx^2 \right \rangle = \frac{1}{2}k_B T$$

Therefore, the mean-square displacement of the particle is:

$$\langle x^2 \rangle = \frac{k_B T}{k}$$

This simple relation demonstrates how thermal energy causes the particle to explore the potential well, with the stiffness of the spring determining the confinement. Stiffer springs (larger $k$) lead to smaller position fluctuations.
:::



### Ergodicity and detailed balance

A key assumption in equilibrium statistical mechanics is ergodicity—the equivalence between time averages and ensemble averages:

$$\langle A \rangle_{\text{time}} = \lim_{T\to\infty} \frac{1}{T} \int_0^T A(t) dt = \langle A \rangle_{\text{ensemble}}$$

In practical terms, ergodicity means that if you observe a single system for a sufficiently long time, it will eventually visit all microscopic states consistent with its macroscopic constraints, allowing time averages to equal ensemble averages. Active matter systems often violate ergodicity by persistently exploring only a subset of the available phase space due to their self-propulsion mechanisms. This has profound implications for both experimental measurements and theoretical descriptions of active systems.

Equilibrium dynamics satisfies detailed balance, a microscopic time-reversal symmetry condition. For transitions between states $i$ and $j$ with rates $W_{i\to j}$ and $W_{j\to i}$:

$$\frac{W_{i\to j}}{W_{j\to i}} = \frac{P_j^{\text{eq}}}{P_i^{\text{eq}}} = e^{-\beta(E_j-E_i)}$$

Detailed balance ensures that there are no net probability currents in equilibrium.

#### Application to Sedimentation

In the sedimentation example, we can apply detailed balance to particles moving between different heights in a gravitational field. Consider transitions between heights $h_i$ and $h_j$:

- The equilibrium probability to find a particle at height $h$ is $P(h) \propto e^{-\beta mgh}$
- For a particle moving from height $h_i$ to a higher position $h_j$, the energy difference is $\Delta E = mg(h_j - h_i)$

By detailed balance, the transition rates must satisfy:

$$\frac{W_{h_i \to h_j}}{W_{h_j \to h_i}} = \frac{e^{-\beta mgh_j}}{e^{-\beta mgh_i}} = e^{-\beta mg(h_j-h_i)}$$

This reveals that upward transitions (against gravity) are exponentially suppressed compared to downward transitions. If we observe the system over time, we would see particles moving both up and down, but with precisely balanced rates that maintain the exponential density profile.

This balance has profound implications for trajectory reversibility. In equilibrium systems, detailed balance ensures that for any specific trajectory $\gamma$ a particle takes from height $h_i$ to $h_j$ over a time interval $[0,t]$, the time-reversed trajectory $\bar{\gamma}$ (the same path followed backward in time) from $h_j$ to $h_i$ occurs with a probability that differs only by the Boltzmann factor:

$$\frac{P[\gamma]}{P[\bar{\gamma}]} = e^{-\beta mg(h_j-h_i)}$$

This microscopic reversibility means that if we filmed the motion of an equilibrium system and played the recording backward, the reversed motion would be statistically indistinguishable from the forward motion (when properly weighted by the equilibrium probabilities). For particles in sedimentation, this time-reversal symmetry ensures that no systematic currents exist in the steady state—particles may diffuse up and down, but any apparent "uphill" motion is precisely balanced by "downhill" motion, maintaining the exponential density profile without net circulation in phase space.



::: {.callout-note collapse=true}
### Connecting to Fluctuation Theorems

The relationship between detailed balance, trajectory reversibility, and sedimentation connects directly to fluctuation theorems, which provide a broader framework for understanding non-equilibrium systems:

#### Connection to Fluctuation Theorems

The trajectory reversibility we described for equilibrium systems (where $\frac{P[\gamma]}{P[\bar{\gamma}]} = e^{-\beta mg(h_j-h_i)}$) is actually a special case of more general fluctuation theorems that apply even to non-equilibrium systems. These theorems quantify the probability of observing trajectories that appear to violate the second law of thermodynamics.

For the sedimentation example, the key connections are:

1. **Crooks Fluctuation Theorem**: This relates the probability of forward and reverse trajectories to the entropy production:

   $$\frac{P[\gamma]}{P[\bar{\gamma}]} = e^{\beta(W-\Delta F)} = e^{\Delta S_{tot}/k_B}$$

   Where $W$ is the work done, $\Delta F$ is the free energy difference, and $\Delta S_{tot}$ is the total entropy production.

2. **Equilibrium Special Case**: When detailed balance is satisfied (as in passive sedimentation), $W = \Delta F = mg(h_j-h_i)$ and $\Delta S_{tot} = 0$, recovering our earlier result.

3. **Active Systems**: For active particles in sedimentation, we have additional work from active forces, leading to:

   $$\frac{P[\gamma]}{P[\bar{\gamma}]} = e^{\beta mg(h_j-h_i) + \Delta S_{act}/k_B}$$

   Where $\Delta S_{act} > 0$ is the entropy production due to activity.
:::



:::{.callout-note collapse=true}
### Master Equation Formulation
Detailed balance can be elegantly formulated in terms of a master equation, which provides a powerful framework for understanding the time evolution of probability distributions.The master equation describes how the probability P_i(t) of finding the system in state i evolves over time:

$$\frac{dP_i(t)}{dt} = \sum_j [W_{j \to i} P_j(t) - W_{i \to j} P_i(t)]$$

where $W_{j→i}$ is the transition rate from state $j$ to state $i$.

The first term represents probability flowing into state $i$ from all other states $j$, while the second term represents probability flowing out of state $i$ to all other states $j$.

#### Detailed Balance as a Stronger Condition

At steady state, the left-hand side of the master equation equals zero, meaning:

$$\sum_j [W_{j \to i} P_j - W_{i \to j} P_i] = 0$$

However, detailed balance imposes a much stronger condition - that each term in this sum must individually equal zero:

$$W_{j \to i} P_j^{eq} = W_{i \to j} P_i^{eq} \quad \text{for all pairs } i,j$$

This is equivalent to requiring that the net probability current between any two states vanishes at equilibrium.

#### Application to Sedimentation

For sedimentation, we can discretize the height into levels ${h_i}$. The master equation becomes:

$$\frac{dP(h_i,t)}{dt} = \sum_j [W_{h_j \to h_i} P(h_j,t) - W_{h_i \to h_j} P(h_i,t)]$$

Detailed balance requires:

$$W_{h_j \to h_i} P^{eq}(h_j) = W_{h_i \to h_j} P^{eq}(h_i)$$

Substituting the Boltzmann distribution $P^{eq}(h) \propto e^{-\beta mgh}$:

$$W_{h_j \to h_i} e^{-\beta mgh_j} = W_{h_i \to h_j} e^{-\beta mgh_i}$$

Rearranging:

$$\frac{W_{h_i \to h_j}}{W_{h_j \to h_i}} = \frac{e^{-\beta mgh_j}}{e^{-\beta mgh_i}} = e^{-\beta mg(h_j-h_i)}$$

This recovers our previous expression for detailed balance in sedimentation.

## Violation in Active Systems

For active particles, we would have additional terms in the master equation representing the active motion. The condition above would no longer be satisfied, and instead, we would find:

$$W_{h_j \to h_i}^{act} P^{ss}(h_j) \neq W_{h_i \to h_j}^{act} P^{ss}(h_i)$$

where $P^ss$ denotes the non-equilibrium steady state distribution.

:::


<!--
### Phase space and Liouville's theorem

For classical systems with positions $\mathbf{q}$ and momenta $\mathbf{p}$, the phase space distribution function $\rho(\mathbf{q},\mathbf{p},t)$ evolves according to Liouville's equation:

$$\frac{\partial \rho}{\partial t} = -\{\rho, H\}$$

where $\{\cdot,\cdot\}$ denotes the Poisson bracket and $H$ is the Hamiltonian. At equilibrium, $\rho$ is time-independent and given by:

$$\rho_{\text{eq}}(\mathbf{q},\mathbf{p}) = \frac{1}{Z} e^{-\beta H(\mathbf{q},\mathbf{p})}$$

Liouville's theorem states that the phase space density behaves like an incompressible fluid - it cannot be created or destroyed, only redistributed. In active systems, this fundamental conservation law is violated because the microscopic dynamics cannot be derived from a Hamiltonian. Instead, active systems require modified descriptions that account for energy injection and dissipation at the particle level.

From a practical perspective, this means that we need to extend our theoretical frameworks beyond Hamiltonian mechanics when studying active matter. Statistical field theories, stochastic thermodynamics, and kinetic theories have all been adapted and extended to describe the phase space evolution of active systems.
-->

### Brownian motion and the Langevin equation


Brownian motion provides a simple yet powerful model for understanding thermal fluctuations. The Langevin equation describes the motion of a Brownian particle:

$$m\frac{d^2x}{dt^2} = -\gamma\frac{dx}{dt} - \frac{dU(x)}{dx} + \xi(t)$$

where $\gamma$ is the friction coefficient, $U(x)$ is the potential energy, and $\xi(t)$ is Gaussian white noise with:

$$\langle\xi(t)\rangle = 0, \quad \langle\xi(t)\xi(t')\rangle = 2\gamma k_B T \delta(t-t')$$

The noise amplitude is related to the friction coefficient through the fluctuation-dissipation relation, a consequence of thermal equilibrium. This relation embodies a deep physical principle: the same microscopic processes that cause energy dissipation (friction) also generate fluctuations (noise), with temperature determining their relative strength.

Understanding the Langevin equation is crucial as it serves as a conceptual bridge between equilibrium and non-equilibrium physics. When modeling active particles, we extend this framework by adding a self-propulsion term. The simplest model of an active Brownian particle (ABP) incorporates a propulsion force of constant magnitude but with a direction that changes through rotational diffusion:

$$\gamma\frac{d\mathbf{r}}{dt} = -\nabla U(\mathbf{r}) + \gamma v_0 \mathbf{n}(t) + \boldsymbol{\xi}(t)$$

where $v_0$ represents the swimming speed and $\mathbf{n}(t)$ is a unit vector undergoing rotational diffusion. This seemingly simple modification profoundly transforms the physics, leading to enhanced diffusion, boundary accumulation, and novel collective behaviors unlike anything seen in passive systems.

In many situations relevant to colloidal systems and active matter, inertial effects can be neglected, leading to the overdamped limit of the Langevin equation:

$$\gamma\frac{dx}{dt} = -\frac{dU(x)}{dx} + \xi(t)$$

This overdamped approximation accurately describes microscopic active systems such as bacterial suspensions, catalytic Janus particles, and colloidal rollers. In these systems, the Reynolds number is extremely low (typically 10^-5 to 10^-2), meaning viscous forces dominate over inertial forces. Consequently, particles stop moving almost instantaneously when propulsion ceases—a counterintuitive behavior compared to our macroscopic experience where objects continue moving due to inertia.

The Langevin framework will serve as our starting point for understanding how active systems systematically violate equilibrium principles. As we explore further, we'll see that active matter requires expanding our theoretical tools beyond equilibrium statistical mechanics to account for the continuous energy input that drives these fascinating systems far from equilibrium.


### Fluctuation dissipation relation (FDT)

At its core, the FDT tells us something remarkable: by simply watching how a system naturally fluctuates at equilibrium, we can predict exactly how it will respond when we deliberately perturb it. This powerful connection works because in equilibrium systems, the same thermal processes drive both phenomena.

Imagine tracking the position of a colloidal particle in a harmonic trap. The particle jiggles around due to random collisions with fluid molecules. The FDT tells us that these natural fluctuations contain all the information we need to know how the particle would respond if we were to push it with a small external force.

Mathematically, we describe this using two key functions:

1. The **correlation function** $C_{ij}(t-t')$ measures how fluctuations are related in time:

$$C_{ij}(t-t') = \langle x_i(t) x_j(t') \rangle - \langle x_i(t) \rangle \langle x_j(t') \rangle$$

The indices $i$ and $j$ here are crucial - they represent different components or degrees of freedom in the system. For example:

- In a system with multiple particles, $i$ and $j$ might label different particles (e.g., $x_1$ is the position of particle 1, $x_2$ is for particle 2)
- For a single particle moving in three dimensions, $i$ and $j$ could indicate different spatial coordinates ($i=x$, $j=y$, or $j=z$)
- In a more complex system, these indices might represent entirely different physical quantities (e.g., $i$ could be position while $j$ could be orientation)
- When $i=j$, we're examining auto-correlations (how a variable correlates with itself at different times)
- When $i≠j$, we're measuring cross-correlations (how different variables influence each other)

This function is directly measurable in experiments by tracking system variables over time and calculating their statistical correlations.

2. The **response function** $\chi_{ij}(t-t')$ tells us how the system responds to external forces:

$$\chi_{ij}(t-t') = \frac{\delta \langle x_i(t) \rangle}{\delta h_j(t')}$$

Here, the indices have a directional meaning: $\chi_{ij}$ measures how component $i$ of the system responds when we apply a perturbation to component $j$. Specifically, it quantifies how much variable $x_i$ changes at time $t$ when we apply a small force $h_j$ at an earlier time $t'$. The indices allow us to characterize both direct responses (when $i=j$) and coupled responses (when $i≠j$). A good exaample for the response function is the electrical susceptibility of a material which is the factor that connects the perturbation $E_j$ with the response which is the polarization:

$$P_i = \varepsilon_0 \sum_j \chi_{ij} E_j$$


The fluctuation-dissipation theorem connects these two functions through temperature. For a system at equilibrium:

$$\chi_{ij}(t-t') = -\frac{1}{k_B T} \frac{d}{dt} C_{ij}(t-t') \quad \text{for } t > t'$$

In experiments, it's often more convenient to work in the frequency domain (using Fourier transforms):

$$\chi_{ij}''(\omega) = \frac{\omega}{2k_B T} C_{ij}(\omega)$$

Here, $\chi_{ij}''(\omega)$ is the imaginary part of the response function (related to energy dissipation) and $C_{ij}(\omega)$ is the power spectrum of fluctuations at frequency $\omega$. The indices maintain their meaning in the frequency domain, allowing us to analyze how different components respond to perturbations at specific frequencies.

## Examples

### Two Brownian particles with non-uniform temperatures

To concretely illustrate how equilibrium concepts apply to coupled systems and how they break down when thermal equilibrium is violated, let's consider a simple model: two Brownian particles connected by springs, with different temperatures.

Consider the following system:
- Two Brownian particles with positions $x_1$ and $x_2$
- Particle 1 is connected to a fixed wall by a spring with constant $k_1$
- The two particles are connected to each other by a spring with constant $k_2$
- Particle 2 is connected to a fixed wall by a spring with constant $k_3$
- Particle 1 experiences thermal fluctuations at temperature $T_1$
- Particle 2 experiences thermal fluctuations at temperature $T_2$

The Langevin equations for this system are:

$$\gamma_1 \frac{dx_1}{dt} = -k_1 x_1 - k_2(x_1 - x_2) + \xi_1(t)$$
$$\gamma_2 \frac{dx_2}{dt} = -k_3 x_2 - k_2(x_2 - x_1) + \xi_2(t)$$

where $\gamma_i$ are the friction coefficients and $\xi_i(t)$ are Gaussian white noises with:

$$\langle \xi_i(t) \rangle = 0, \quad \langle \xi_i(t) \xi_i(t') \rangle = 2\gamma_i k_B T_i \delta(t-t')$$

When $T_1 = T_2$, this system is in thermal equilibrium, and the probability distribution for the positions follows the Boltzmann distribution:

$$P(x_1, x_2) \propto \exp\left(-\frac{1}{k_B T}[k_1 x_1^2/2 + k_2(x_1-x_2)^2/2 + k_3 x_2^2/2]\right)$$

However, when $T_1 \neq T_2$, the system is driven out of equilibrium, leading to a non-Boltzmann stationary distribution. The correlation between $x_1$ and $x_2$ encodes information about the non-equilibrium nature of the system.

::: {#fig-heat-transfer}
![](/assets/images/lecture02/heat_transfer.png)

Brownian-dynamics simulation of 1D bead-spring model. (A) Model schematic. (B) Time series of the bead positions for T2 = 1.5T1 and equal spring constants. See figs. S4 and S5 for the general case (18). (C and D) Probability distribution (color) and flux map (white arrows) in CGPS spanned by x1 and x2 for the simulation in panel B (C) and for a simulation with T2 = T1 (D). Translucent disks represent a 2s confidence interval for fluxes. [source](https://www.science.org/doi/epdf/10.1126/science.aac8167)
:::


In this non-equilibrium scenario, energy flows from the hotter to the colder particle, driving the system away from equilibrium. The stationary state represents a balance between this energy flow and dissipation, rather than a state of maximum entropy as in equilibrium systems. The detailed balance condition is violated, and the system exhibits persistent probability currents in phase space - a hallmark of non-equilibrium behavior.


### Chlamydomonas Swimming

The violation of detailed balance is perhaps the most direct signature of non-equilibrium behavior in active matter. The microalgae Chlamydomonas Reinhardtii provides an exemplary demonstration of this principle.

::: {#fig-chlamydomonas}
![](/assets/images/lecture02/clamy_image.png)

Light microscopy image of Chlamydomonas Reinhardtii, a single-celled green alga with two flagella used for swimming and sensing. [source](https://en.wikipedia.org/wiki/Chlamydomonas)
:::

Chlamydomonas Reinhardtii propels itself through fluid by coordinated beating of its two flagella. This motion requires continuous energy consumption, as each flagellum hydrolyzes ATP to power molecular motors that generate rhythmic beating patterns. Unlike passive Brownian particles, where motion arises from random thermal fluctuations, the flagellar beating represents a driven, non-equilibrium process.

As shown in the figures below, researchers have characterized this non-equilibrium behavior by analyzing the flagellar dynamics in a coarse-grained phase space (CGPS) constructed from the principal bending modes. The beating patterns can be decomposed into these fundamental modes (similar to Fourier components), allowing quantitative tracking of the flagellar configuration over time.

The phase space probability distribution and corresponding flux maps reveal a striking signature of non-equilibrium dynamics: coherent probability currents that form closed loops. These directed cyclic trajectories through configuration space explicitly violate detailed balance, which would require all microscopic transitions to be pairwise-balanced with no net probability flux between states. In an equilibrium system, transitions between any two states would occur with equal frequency in both directions when properly weighted by their equilibrium probabilities.

::: {#fig-clamy2}
![](/assets/images/lecture02/clamy.png)

Detailed balance and actively beating Chlamydomonas flagella. (A) In thermodynamic equilibrium, transitions between microscopic states are pairwise-balanced, precluding net flux among states. (B) Nonequilibrium steady states can break detailed balance and exhibit flux loops. (C) Snapshots separated by 24 (orange-yellow), 7, and 10 ms in an isolated Chlamydomonas flagellum's beat cycle (movie S1). Arrows on the central circle indicate the direction of time. Color corresponds to position in (E). (D) The first three bending modes for a freely suspended flexible rod. (E) A three-dimensional (3D) probability flux map of flagellar dynamics in the CGPS spanned by the first three modes.[source](https://www.science.org/doi/epdf/10.1126/science.aac8167)
:::

The flux maps in panels F and G below show clear rotational currents in the phase space of bending modes. These currents represent the flagellum cycling through configurations in a specific sequence rather than randomly exploring available states as would occur in thermal equilibrium. The directed nature of these probability currents directly quantifies the system's departure from equilibrium.

::: {#fig-clamy3}
![](/assets/images/lecture02/clamy_flow.png)

(F and G) Probability distribution (color) and flux map (white arrows) of flagellar dynamics in CGPS spanned by first and second modes (F), and first and third modes (G). The white legend indicates the flux scale. [source](https://www.science.org/doi/epdf/10.1126/science.aac8167)
:::

These probability flux loops are fundamental to biological function, enabling directed motion and mechanical work that would be thermodynamically prohibited under equilibrium constraints. Similar non-equilibrium dynamics appear in many biological systems, from molecular motors and cell migration to collective tissue behaviors, where energy consumption drives the system away from equilibrium to perform essential biological functions.



### Primary cilia in epithelial cells

Primary cilia represent another biological system that exhibits non-equilibrium dynamics, but in a more subtle manner than the flagella of Chlamydomonas. These hairlike organelles project from many eukaryotic cells and transduce mechanical and chemical stimuli into intracellular signals. Unlike flagella, primary cilia often lack the dynein machinery necessary for active beating, causing them to fluctuate in what appears to be a random manner.

When analyzed in the phase space defined by their deflection angle and curvature, primary cilia of MDCK (Madin-Darby canine kidney) epithelial cells reveal clockwise circulation patterns in their probability flux maps. These patterns indicate broken detailed balance, providing direct evidence of non-equilibrium dynamics in these seemingly passive structures. The statistical significance of these flux loops can be quantified, confirming that these cilia indeed operate far from equilibrium despite their apparently random motion.

::: {#fig-mdck-cilia}
![](/assets/images/lecture02/MDCK_cilia.png){width=50%}

Left: Schematic of primary cilium and anchoring of the
basal body in the cell cortex with angle q and curvature, k, defined
positive as shown. Right: Snapshots of cilium, from differential
interference contrast microscopy, taken at time points marked
in (B). Scale bar: 2 mm.
:::
